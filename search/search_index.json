{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"csvtk - A cross-platform, efficient and practical CSV/TSV toolkit Documents: http://bioinf.shenwei.me/csvtk ( Usage and Tutorial ). \u4e2d\u6587\u4ecb\u7ecd Source code: https://github.com/shenwei356/csvtk Latest version: Introduction Similar to FASTA/Q format in field of Bioinformatics, CSV/TSV formats are basic and ubiquitous file formats in both Bioinformatics and data sicence. People usually use spreadsheet softwares like MS Excel to do process table data. However it's all by clicking and typing, which is not automatically and time-consuming to repeat , especially when we want to apply similar operations with different datasets or purposes. You can also accomplish some CSV/TSV manipulations using shell commands, but more codes are needed to handle the header line. Shell commands do not support selecting columns with column names either. csvtk is convenient for rapid data investigation and also easy to be integrated into analysis pipelines . It could save you much time of writing Python/R scripts. Table of Contents Features Subcommands Installation Bash-completion Compared to csvkit Examples Acknowledgements Contact License Features Cross-platform (Linux/Windows/Mac OS X/OpenBSD/FreeBSD) Light weight and out-of-the-box, no dependencies, no compilation, no configuration Fast , multiple-CPUs supported (some commands) Practical functions provided by N subcommands Support STDIN and gziped input/output file, easy being used in pipe Most of the subcommands support unselecting fields and fuzzy fields , e.g. -f \"-id,-name\" for all fields except \"id\" and \"name\", -F -f \"a.*\" for all fields with prefix \"a.\". Support some common plots (see usage ) Seamlessly support for data with meta line (e.g., sep=, ) of separator declaration used by MS Excel Subcommands 39 subcommands in total. Information headers : prints headers dim : dimensions of CSV file summary : summary statistics of selected digital fields (groupby group fields) watch : online monitoring and histogram of selected field corr : calculate Pearson correlation between numeric columns Format conversion pretty : converts CSV to readable aligned table csv2tab : converts CSV to tabular format tab2csv : converts tabular format to CSV space2tab : converts space delimited format to CSV transpose : transposes CSV data csv2md : converts CSV to markdown format csv2json : converts CSV to JSON format xlsx2csv : converts XLSX to CSV format Set operations head : prints first N records concat : concatenates CSV/TSV files by rows sample : sampling by proportion cut : selects parts of fields grep : greps data by selected fields with patterns/regular expressions uniq : unique data without sorting freq : frequencies of selected fields inter : intersection of multiple files filter : filters rows by values of selected fields with arithmetic expression filter2 : filters rows by awk-like arithmetic/string expressions join : joins multiple CSV files by selected fields split splits CSV/TSV into multiple files according to column values splitxlsx : splits XLSX sheet into multiple sheets according to column values collapse : collapses one field with selected fields as keys Edit add-header : add column names del-header : delete column names rename : renames column names rename2 : renames column names by regular expression replace : replaces data of selected fields by regular expression mutate : creates new columns from selected fields by regular expression mutate2 : creates new column from selected fields by awk-like arithmetic/string expressions gather : gathers columns into key-value pairs Ordering sort : sorts by selected fields Ploting plot see usage plot hist histogram plot box boxplot plot line line plot and scatter plot Misc cat stream file and report progress version print version information and check for update genautocomplete generate shell autocompletion script Installation Download Page csvtk is implemented in Go programming language, executable binary files for most popular operating systems are freely available in release page. Method 1: Download binaries (latest stable/dev version) Just download compressed executable file of your operating system, and decompress it with tar -zxvf *.tar.gz command or other tools. And then: For Linux-like systems If you have root privilege simply copy it to /usr/local/bin : sudo cp csvtk /usr/local/bin/ Or copy to anywhere in the environment variable PATH : mkdir -p $HOME/bin/; cp csvtk $HOME/bin/ For windows , just copy csvtk.exe to C:\\WINDOWS\\system32 . Method 2: Install via conda (latest stable version) conda install -c bioconda csvtk Method 3: For Go developer (latest stable/dev version) go get -u github.com/shenwei356/csvtk/csvtk Method 4: For ArchLinux AUR users (may be not the latest) yaourt -S csvtk Bash-completion Note: The current version supports Bash only. This should work for *nix systems with Bash installed. Howto: run: csvtk genautocomplete create and edit ~/.bash_completion file if you don't have it. nano ~/.bash_completion add the following: for bcfile in ~/.bash_completion.d/* ; do . $bcfile done Compared to csvkit csvkit , attention: this table wasn't updated for 2 years. Features csvtk csvkit Note Read Gzip Yes Yes read gzip files Fields ranges Yes Yes e.g. -f 1-4,6 Unselect fileds Yes -- e.g. -1 for excluding first column Fuzzy fields Yes -- e.g. ab* for columns with name prefix \"ab\" Reorder fields Yes Yes it means -f 1,2 is different from -f 2,1 Rename columns Yes -- rename with new name(s) or from existed names Sort by multiple keys Yes Yes bash sort like operations Sort by number Yes -- e.g. -k 1:n Multiple sort Yes -- e.g. -k 2:r -k 1:nr Pretty output Yes Yes convert CSV to readable aligned table Unique data Yes -- unique data of selected fields frequency Yes -- frequencies of selected fields Sampling Yes -- sampling by proportion Mutate fields Yes -- create new columns from selected fields Repalce Yes -- replace data of selected fields Similar tools: csvkit - A suite of utilities for converting to and working with CSV, the king of tabular file formats. http://csvkit.rtfd.org/ xsv - A fast CSV toolkit written in Rust. miller - Miller is like sed, awk, cut, join, and sort for name-indexed data such as CSV and tabular JSON http://johnkerl.org/miller tsv-utils - Command line utilities for tab-separated value files written in the D programming language. Examples More examples and tutorial . Attention The CSV parser requires all the lines have same number of fields/columns. Even lines with spaces will cause error. Use '-I/--ignore-illegal-row' to skip these lines if neccessary. By default, csvtk thinks your files have header row, if not, switch flag -H on. Column names better be unique. By default, lines starting with # will be ignored, if the header row starts with # , please assign flag -C another rare symbol, e.g. '$' . By default, csvtk handles CSV files, use flag -t for tab-delimited files. If \" exists in tab-delimited files, use flag -l . Do not mix use digital fields and column names. Examples Pretty result $ csvtk pretty names.csv id first_name last_name username 11 Rob Pike rob 2 Ken Thompson ken 4 Robert Griesemer gri 1 Robert Thompson abc NA Robert Abel 123 Summary of selected digital fields, supporting \"group-by\" $ cat testdata/digitals2.csv \\ | csvtk summary --ignore-non-digits --fields f4:sum,f5:sum --groups f1,f2 \\ | csvtk pretty f1 f2 f4:sum f5:sum bar xyz 7.00 106.00 bar xyz2 4.00 4.00 foo bar 6.00 3.00 foo bar2 4.50 5.00 Select fields/columns ( cut ) By index: csvtk cut -f 1,2 By names: csvtk cut -f first_name,username Unselect : csvtk cut -f -1,-2 or csvtk cut -f -first_name Fuzzy fields : csvtk cut -F -f \"*_name,username\" Field ranges: csvtk cut -f 2-4 for column 2,3,4 or csvtk cut -f -3--1 for discarding column 1,2,3 All fields: csvtk cut -F -f \"*\" Search by selected fields ( grep ) (matched parts will be highlighted as red) By exactly matching: csvtk grep -f first_name -p Robert -p Rob By regular expression: csvtk grep -f first_name -r -p Rob By pattern list: csvtk grep -f first_name -P name_list.txt Remore rows containing missing data (NA): csvtk grep -F -f \"*\" -r -p \"^$\" -v Rename column names ( rename and rename2 ) Setting new names: csvtk rename -f A,B -n a,b or csvtk rename -f 1-3 -n a,b,c Replacing with original names by regular express: cat ../testdata/c.csv | ./csvtk rename2 -F -f \"*\" -p \"(.*)\" -r 'prefix_$1' for adding prefix to all column names. Edit data with regular expression ( replace ) Remove Chinese charactors: csvtk replace -F -f \"*_name\" -p \"\\p{Han}+\" -r \"\" Create new column from selected fields by regular expression ( mutate ) In default, copy a column: csvtk mutate -f id Extract prefix of data as group name (get \"A\" from \"A.1\" as group name): csvtk mutate -f sample -n group -p \"^(.+?)\\.\" Sort by multiple keys ( sort ) By single column : csvtk sort -k 1 or csvtk sort -k last_name By multiple columns: csvtk sort -k 1,2 or csvtk sort -k 1 -k 2 or csvtk sort -k last_name,age Sort by number: csvtk sort -k 1:n or csvtk sort -k 1:nr for reverse number Complex sort: csvtk sort -k region -k age:n -k id:nr In natural order: csvtk sort -k chr:N Join multiple files by keys ( join ) All files have same key column: csvtk join -f id file1.csv file2.csv Files have different key columns: csvtk join -f \"username;username;name\" names.csv phone.csv adress.csv -k Filter by numbers ( filter ) Single field: csvtk filter -f \"id>0\" Multiple fields : csvtk filter -f \"1-3>0\" Using --any to print record if any of the field satisfy the condition: csvtk filter -f \"1-3>0\" --any fuzzy fields : csvtk filter -F -f \"A*!=0\" Filter rows by awk-like arithmetic/string expressions ( filter2 ) Using field index: csvtk filter2 -f '$3>0' Using column names: csvtk filter2 -f '$id > 0' Both arithmetic and string expressions: csvtk filter2 -f '$id > 3 || $username==\"ken\"' More complicated: csvtk filter2 -H -t -f '$1 > 2 && $2 % 2 == 0' Ploting plot histogram with data of the second column: csvtk -t plot hist testdata/grouped_data.tsv.gz -f 2 | display plot boxplot with data of the \"GC Content\" (third) column, group information is the \"Group\" column. csvtk -t plot box testdata/grouped_data.tsv.gz -g \"Group\" \\ -f \"GC Content\" --width 3 | display plot horiz boxplot with data of the \"Length\" (second) column, group information is the \"Group\" column. csvtk -t plot box testdata/grouped_data.tsv.gz -g \"Group\" -f \"Length\" \\ --height 3 --width 5 --horiz --title \"Horiz box plot\" | display plot line plot with X-Y data csvtk -t plot line testdata/xy.tsv -x X -y Y -g Group | display plot scatter plot with X-Y data csvtk -t plot line testdata/xy.tsv -x X -y Y -g Group --scatter | display Acknowledgements We are grateful to Zhiluo Deng and Li Peng for suggesting features and reporting bugs. Thanks Albert Vilella for features suggestion, which makes csvtk feature-rich\u3002 Contact Create an issue to report bugs, propose new functions or ask for help. Or leave a comment . License MIT License","title":"Home"},{"location":"#csvtk-a-cross-platform-efficient-and-practical-csvtsv-toolkit","text":"Documents: http://bioinf.shenwei.me/csvtk ( Usage and Tutorial ). \u4e2d\u6587\u4ecb\u7ecd Source code: https://github.com/shenwei356/csvtk Latest version:","title":"csvtk - A cross-platform, efficient and practical CSV/TSV toolkit"},{"location":"#introduction","text":"Similar to FASTA/Q format in field of Bioinformatics, CSV/TSV formats are basic and ubiquitous file formats in both Bioinformatics and data sicence. People usually use spreadsheet softwares like MS Excel to do process table data. However it's all by clicking and typing, which is not automatically and time-consuming to repeat , especially when we want to apply similar operations with different datasets or purposes. You can also accomplish some CSV/TSV manipulations using shell commands, but more codes are needed to handle the header line. Shell commands do not support selecting columns with column names either. csvtk is convenient for rapid data investigation and also easy to be integrated into analysis pipelines . It could save you much time of writing Python/R scripts.","title":"Introduction"},{"location":"#table-of-contents","text":"Features Subcommands Installation Bash-completion Compared to csvkit Examples Acknowledgements Contact License","title":"Table of Contents"},{"location":"#features","text":"Cross-platform (Linux/Windows/Mac OS X/OpenBSD/FreeBSD) Light weight and out-of-the-box, no dependencies, no compilation, no configuration Fast , multiple-CPUs supported (some commands) Practical functions provided by N subcommands Support STDIN and gziped input/output file, easy being used in pipe Most of the subcommands support unselecting fields and fuzzy fields , e.g. -f \"-id,-name\" for all fields except \"id\" and \"name\", -F -f \"a.*\" for all fields with prefix \"a.\". Support some common plots (see usage ) Seamlessly support for data with meta line (e.g., sep=, ) of separator declaration used by MS Excel","title":"Features"},{"location":"#subcommands","text":"39 subcommands in total. Information headers : prints headers dim : dimensions of CSV file summary : summary statistics of selected digital fields (groupby group fields) watch : online monitoring and histogram of selected field corr : calculate Pearson correlation between numeric columns Format conversion pretty : converts CSV to readable aligned table csv2tab : converts CSV to tabular format tab2csv : converts tabular format to CSV space2tab : converts space delimited format to CSV transpose : transposes CSV data csv2md : converts CSV to markdown format csv2json : converts CSV to JSON format xlsx2csv : converts XLSX to CSV format Set operations head : prints first N records concat : concatenates CSV/TSV files by rows sample : sampling by proportion cut : selects parts of fields grep : greps data by selected fields with patterns/regular expressions uniq : unique data without sorting freq : frequencies of selected fields inter : intersection of multiple files filter : filters rows by values of selected fields with arithmetic expression filter2 : filters rows by awk-like arithmetic/string expressions join : joins multiple CSV files by selected fields split splits CSV/TSV into multiple files according to column values splitxlsx : splits XLSX sheet into multiple sheets according to column values collapse : collapses one field with selected fields as keys Edit add-header : add column names del-header : delete column names rename : renames column names rename2 : renames column names by regular expression replace : replaces data of selected fields by regular expression mutate : creates new columns from selected fields by regular expression mutate2 : creates new column from selected fields by awk-like arithmetic/string expressions gather : gathers columns into key-value pairs Ordering sort : sorts by selected fields Ploting plot see usage plot hist histogram plot box boxplot plot line line plot and scatter plot Misc cat stream file and report progress version print version information and check for update genautocomplete generate shell autocompletion script","title":"Subcommands"},{"location":"#installation","text":"Download Page csvtk is implemented in Go programming language, executable binary files for most popular operating systems are freely available in release page.","title":"Installation"},{"location":"#method-1-download-binaries-latest-stabledev-version","text":"Just download compressed executable file of your operating system, and decompress it with tar -zxvf *.tar.gz command or other tools. And then: For Linux-like systems If you have root privilege simply copy it to /usr/local/bin : sudo cp csvtk /usr/local/bin/ Or copy to anywhere in the environment variable PATH : mkdir -p $HOME/bin/; cp csvtk $HOME/bin/ For windows , just copy csvtk.exe to C:\\WINDOWS\\system32 .","title":"Method 1: Download binaries (latest stable/dev version)"},{"location":"#method-2-install-via-conda-latest-stable-version","text":"conda install -c bioconda csvtk","title":"Method 2: Install via conda (latest stable version)"},{"location":"#method-3-for-go-developer-latest-stabledev-version","text":"go get -u github.com/shenwei356/csvtk/csvtk","title":"Method 3: For Go developer (latest stable/dev version)"},{"location":"#method-4-for-archlinux-aur-users-may-be-not-the-latest","text":"yaourt -S csvtk","title":"Method 4: For ArchLinux AUR users (may be not the latest)"},{"location":"#bash-completion","text":"Note: The current version supports Bash only. This should work for *nix systems with Bash installed. Howto: run: csvtk genautocomplete create and edit ~/.bash_completion file if you don't have it. nano ~/.bash_completion add the following: for bcfile in ~/.bash_completion.d/* ; do . $bcfile done","title":"Bash-completion"},{"location":"#compared-to-csvkit","text":"csvkit , attention: this table wasn't updated for 2 years. Features csvtk csvkit Note Read Gzip Yes Yes read gzip files Fields ranges Yes Yes e.g. -f 1-4,6 Unselect fileds Yes -- e.g. -1 for excluding first column Fuzzy fields Yes -- e.g. ab* for columns with name prefix \"ab\" Reorder fields Yes Yes it means -f 1,2 is different from -f 2,1 Rename columns Yes -- rename with new name(s) or from existed names Sort by multiple keys Yes Yes bash sort like operations Sort by number Yes -- e.g. -k 1:n Multiple sort Yes -- e.g. -k 2:r -k 1:nr Pretty output Yes Yes convert CSV to readable aligned table Unique data Yes -- unique data of selected fields frequency Yes -- frequencies of selected fields Sampling Yes -- sampling by proportion Mutate fields Yes -- create new columns from selected fields Repalce Yes -- replace data of selected fields Similar tools: csvkit - A suite of utilities for converting to and working with CSV, the king of tabular file formats. http://csvkit.rtfd.org/ xsv - A fast CSV toolkit written in Rust. miller - Miller is like sed, awk, cut, join, and sort for name-indexed data such as CSV and tabular JSON http://johnkerl.org/miller tsv-utils - Command line utilities for tab-separated value files written in the D programming language.","title":"Compared to csvkit"},{"location":"#examples","text":"More examples and tutorial . Attention The CSV parser requires all the lines have same number of fields/columns. Even lines with spaces will cause error. Use '-I/--ignore-illegal-row' to skip these lines if neccessary. By default, csvtk thinks your files have header row, if not, switch flag -H on. Column names better be unique. By default, lines starting with # will be ignored, if the header row starts with # , please assign flag -C another rare symbol, e.g. '$' . By default, csvtk handles CSV files, use flag -t for tab-delimited files. If \" exists in tab-delimited files, use flag -l . Do not mix use digital fields and column names. Examples Pretty result $ csvtk pretty names.csv id first_name last_name username 11 Rob Pike rob 2 Ken Thompson ken 4 Robert Griesemer gri 1 Robert Thompson abc NA Robert Abel 123 Summary of selected digital fields, supporting \"group-by\" $ cat testdata/digitals2.csv \\ | csvtk summary --ignore-non-digits --fields f4:sum,f5:sum --groups f1,f2 \\ | csvtk pretty f1 f2 f4:sum f5:sum bar xyz 7.00 106.00 bar xyz2 4.00 4.00 foo bar 6.00 3.00 foo bar2 4.50 5.00 Select fields/columns ( cut ) By index: csvtk cut -f 1,2 By names: csvtk cut -f first_name,username Unselect : csvtk cut -f -1,-2 or csvtk cut -f -first_name Fuzzy fields : csvtk cut -F -f \"*_name,username\" Field ranges: csvtk cut -f 2-4 for column 2,3,4 or csvtk cut -f -3--1 for discarding column 1,2,3 All fields: csvtk cut -F -f \"*\" Search by selected fields ( grep ) (matched parts will be highlighted as red) By exactly matching: csvtk grep -f first_name -p Robert -p Rob By regular expression: csvtk grep -f first_name -r -p Rob By pattern list: csvtk grep -f first_name -P name_list.txt Remore rows containing missing data (NA): csvtk grep -F -f \"*\" -r -p \"^$\" -v Rename column names ( rename and rename2 ) Setting new names: csvtk rename -f A,B -n a,b or csvtk rename -f 1-3 -n a,b,c Replacing with original names by regular express: cat ../testdata/c.csv | ./csvtk rename2 -F -f \"*\" -p \"(.*)\" -r 'prefix_$1' for adding prefix to all column names. Edit data with regular expression ( replace ) Remove Chinese charactors: csvtk replace -F -f \"*_name\" -p \"\\p{Han}+\" -r \"\" Create new column from selected fields by regular expression ( mutate ) In default, copy a column: csvtk mutate -f id Extract prefix of data as group name (get \"A\" from \"A.1\" as group name): csvtk mutate -f sample -n group -p \"^(.+?)\\.\" Sort by multiple keys ( sort ) By single column : csvtk sort -k 1 or csvtk sort -k last_name By multiple columns: csvtk sort -k 1,2 or csvtk sort -k 1 -k 2 or csvtk sort -k last_name,age Sort by number: csvtk sort -k 1:n or csvtk sort -k 1:nr for reverse number Complex sort: csvtk sort -k region -k age:n -k id:nr In natural order: csvtk sort -k chr:N Join multiple files by keys ( join ) All files have same key column: csvtk join -f id file1.csv file2.csv Files have different key columns: csvtk join -f \"username;username;name\" names.csv phone.csv adress.csv -k Filter by numbers ( filter ) Single field: csvtk filter -f \"id>0\" Multiple fields : csvtk filter -f \"1-3>0\" Using --any to print record if any of the field satisfy the condition: csvtk filter -f \"1-3>0\" --any fuzzy fields : csvtk filter -F -f \"A*!=0\" Filter rows by awk-like arithmetic/string expressions ( filter2 ) Using field index: csvtk filter2 -f '$3>0' Using column names: csvtk filter2 -f '$id > 0' Both arithmetic and string expressions: csvtk filter2 -f '$id > 3 || $username==\"ken\"' More complicated: csvtk filter2 -H -t -f '$1 > 2 && $2 % 2 == 0' Ploting plot histogram with data of the second column: csvtk -t plot hist testdata/grouped_data.tsv.gz -f 2 | display plot boxplot with data of the \"GC Content\" (third) column, group information is the \"Group\" column. csvtk -t plot box testdata/grouped_data.tsv.gz -g \"Group\" \\ -f \"GC Content\" --width 3 | display plot horiz boxplot with data of the \"Length\" (second) column, group information is the \"Group\" column. csvtk -t plot box testdata/grouped_data.tsv.gz -g \"Group\" -f \"Length\" \\ --height 3 --width 5 --horiz --title \"Horiz box plot\" | display plot line plot with X-Y data csvtk -t plot line testdata/xy.tsv -x X -y Y -g Group | display plot scatter plot with X-Y data csvtk -t plot line testdata/xy.tsv -x X -y Y -g Group --scatter | display","title":"Examples"},{"location":"#acknowledgements","text":"We are grateful to Zhiluo Deng and Li Peng for suggesting features and reporting bugs. Thanks Albert Vilella for features suggestion, which makes csvtk feature-rich\u3002","title":"Acknowledgements"},{"location":"#contact","text":"Create an issue to report bugs, propose new functions or ask for help. Or leave a comment .","title":"Contact"},{"location":"#license","text":"MIT License","title":"License"},{"location":"bioinf/","text":"","title":"Bioinf"},{"location":"chinese/","text":"\u5982\u540c\u751f\u7269\u4fe1\u606f\u9886\u57df\u4e2d\u7684FASTA/Q\u683c\u5f0f\u4e00\u6837\uff0cCSV/TSV\u4f5c\u4e3a\u8ba1\u7b97\u673a\u3001\u6570\u636e\u79d1\u5b66\u548c\u751f\u7269\u4fe1\u606f\u7684\u57fa\u672c\u683c\u5f0f\uff0c\u5e94\u7528\u975e\u5e38\u5e7f\u6cdb\u3002\u5e38\u7528\u7684\u5904\u7406\u8f6f\u4ef6\u5305\u62ec\uff1a \u4ee5\u5fae\u8f6fExcel\u4e3a\u4ee3\u8868\u7684\u7535\u5b50\u8868\u683c\u8f6f\u4ef6 Notepad++/SublimeText\u7b49\u6587\u672c\u7f16\u8f91\u5668 sed/awk/cut\u7b49Shell\u547d\u4ee4 \u5404\u79cd\u7f16\u7a0b\u8bed\u8a00\u7684\u6570\u636e\u5904\u7406\u5e93\u3002 \u7136\u800c\uff0c\u7535\u5b50\u8868\u683c\u8f6f\u4ef6\u548c\u6587\u672c\u7f16\u8f91\u5668\u56fa\u7136\u5f3a\u5927\uff0c\u4f46\u4f9d\u8d56\u9f20\u6807\u64cd\u4f5c\uff0c\u4e0d\u9002\u5408\u6279\u91cf\u5904\u7406\uff1b sed/awk/cut\u7b49Shell\u547d\u4ee4\u4e3b\u8981\u7528\u4e8e\u901a\u7528\u7684\u8868\u683c\u6570\u636e\uff0c\u4e0d\u9002\u5408\u542b\u6709\u6807\u9898\u884c\u7684CSV\u683c\u5f0f \uff1b \u4e3a\u4e86\u4e00\u4e2a\u5c0f\u64cd\u4f5c\u5199Python/R\u811a\u672c\u4e5f\u6709\u70b9\u5c0f\u9898\u5927\u4f5c\uff0c\u4e14\u96be\u4ee5\u590d\u7528 \u3002 \u5f00\u53d1csvtk\u524d\u73b0\u6709\u7684\u5de5\u5177\u4e3b\u8981\u662fPython\u5199\u7684csvkit\uff0cRust\u5199\u7684xsv\uff0cC\u8bed\u8a00\u5199\u7684miller\uff0c\u90fd\u5404\u6709\u4f18\u52a3\u3002\u5f53\u65f6\u6211\u521a\u5f00\u53d1\u5b8cseqkit\uff0c\u6295\u6587\u7ae0\u8fc7\u7a0b\u4e2d\u65f6\u95f4\u5145\u8db3\uff0c\u4fbf\u60f3\u8d81\u70ed\u518d\u9020\u4e00\u4e2a\u8f6e\u5b50\u3002 \u6240\u4ee5\u6211\u51b3\u5b9a\u5199\u4e00\u4e2a\u547d\u4ee4\u884c\u5de5\u5177\u6765\u6ee1\u8db3CSV/TSV\u683c\u5f0f\u7684\u5e38\u89c1\u64cd\u4f5c\uff0c\u8fd9\u5c31\u662fcsvtk\u4e86\u3002 \u4ecb\u7ecd \u57fa\u672c\u4fe1\u606f \u5de5\u5177\u7c7b\u578b: \u547d\u4ee4\u884c\u5de5\u5177\uff0c\u5b50\u547d\u4ee4\u7ed3\u6784 \u652f\u6301\u683c\u5f0f: CSV/TSV, plain/gzip-compressed \u7f16\u7a0b\u8bed\u8a00: Go \u652f\u6301\u5e73\u53f0: Linux, OS X\uff0c Windows \u7b49 \u53d1\u5e03\u65b9\u5f0f: \u5355\u4e00\u53ef\u6267\u884c\u4e8c\u8fdb\u5236\u6587\u4ef6\uff0c\u4e0b\u8f7d\u5373\u7528 \u53d1\u5e03\u5e73\u53f0: Github, Bioconda \u9879\u76ee\u4e3b\u9875: http://bioinf.shenwei.me/csvtk/ \u5f00\u6e90\u5730\u5740: https://github.com/shenwei356/csvtk \u7279\u6027 \u8de8\u5e73\u53f0 \u8f7b\u91cf\uff0c\u65e0\u4efb\u4f55\u4f9d\u8d56\uff0c\u65e0\u9700\u7f16\u8bd1\u3001\u914d\u7f6e\uff0c\u4e0b\u8f7d\u5373\u7528 \u5feb\u901f \u652f\u6301stdin\u548cgzip\u538b\u7f29\u7684\u8f93\u5165\u548c\u8f93\u51fa\u6587\u4ef6\uff0c\u4fbf\u4e8e\u6d41\u5904\u7406 27\u4e2a\u5b50\u547d\u4ee4\u63d0\u4f9b\u591a\u79cd\u5b9e\u7528\u7684\u529f\u80fd\uff0c\u4e14\u80fd\u901a\u8fc7\u547d\u4ee4\u884c\u7ba1\u9053\u7ec4\u5408 \u652f\u6301Bash\u81ea\u52a8\u8865\u5168 \u652f\u6301\u7b80\u5355\u7684\u7ed8\u56fe \u529f\u80fd \u5728\u5f00\u53d1csvtk\u4e4b\u524d\u7684\u4e24\u4e09\u5e74\u95f4\uff0c\u6211\u5df2\u7ecf\u5199\u4e86\u51e0\u4e2a\u53ef\u4ee5\u590d\u7528\u7684Python/Perl\u811a\u672c\uff08https://github.com/shenwei356/datakit\uff09 \uff0c\u5305\u62eccsv2tab\u3001csvtk_grep\u3001csv_join\u3001csv_melt\uff0cintersection\uff0cunique\u3002\u6240\u4ee5\u6211\u7684\u8ba1\u5212\u662f\u9996\u5148\u96c6\u6210\u8fd9\u4e9b\u5df2\u6709\u7684\u529f\u80fd\uff0c\u968f\u540e\u6839\u636e\u9700\u6c42\u8fdb\u884c\u6269\u5c55\u3002 \u5230\u76ee\u524d\u4e3a\u6b62\uff0ccsvtk\u5df2\u670927\u4e2a\u5b50\u547d\u4ee4\uff0c\u5206\u4e3a\u4ee5\u4e0b\u51e0\u5927\u7c7b\uff1a \u4fe1\u606f headers \u76f4\u89c2\u6253\u5370\u6807\u9898\u884c\uff08 \u64cd\u4f5c\u5217\u6570\u8f83\u591a\u7684CSV\u524d\u4f7f\u7528\u6700\u4f73 \uff09 stats \u57fa\u672c\u7edf\u8ba1 stats2 \u5bf9\u9009\u5b9a\u7684\u6570\u503c\u5217\u8fdb\u884c\u57fa\u672c\u7edf\u8ba1 \u683c\u5f0f\u8f6c\u5316 pretty \u8f6c\u4e3a\u7f8e\u89c2\u3001\u53ef\u8bfb\u6027\u5f3a\u7684\u683c\u5f0f\uff08 \u6700\u5e38\u7528\u547d\u4ee4\u4e4b\u4e00 \uff09 csv2tab \u8f6cCSV\u4e3a\u5236\u8868\u7b26\u5206\u5272\u683c\u5f0f\uff08TSV\uff09 tab2csv \u8f6cTSV\u4e3aCSV space2tab \u8f6c\u7a7a\u683c\u5206\u5272\u683c\u5f0f\u4e3aTSV transpose \u8f6c\u7f6eCSV/TSV csv2md \u8f6cCSV/TSV\u4e3amakrdown\u683c\u5f0f\uff08 \u5199\u6587\u6863\u5e38\u7528 \uff09 \u96c6\u5408\u64cd\u4f5c head \u6253\u5370\u524dN\u6761\u8bb0\u5f55 sample \u6309\u6bd4\u4f8b\u968f\u673a\u91c7\u6837 cut \u9009\u62e9\u7279\u5b9a\u5217\uff0c\u652f\u6301 \u6309\u5217\u6216\u5217\u540d\u8fdb\u884c\u57fa\u672c\u9009\u62e9\u3001\u8303\u56f4\u9009\u62e9\u3001\u6a21\u7cca\u9009\u62e9\u3001\u8d1f\u5411\u9009\u62e9 \uff08 \u6700\u5e38\u7528\u547d\u4ee4\u4e4b\u4e00\uff0c\u975e\u5e38\u5f3a\u5927 \uff09 uniq \u65e0\u987b\u6392\u5e8f\uff0c\u8fd4\u56de\u6309\u6307\u5b9a\uff08\u591a\uff09\u5217\u4f5c\u4e3akey\u7684\u552f\u4e00\u8bb0\u5f55\uff08\u597d\u7ed5\u3002\u3002\uff09 freq \u6309\u6307\u5b9a\uff08\u591a\uff09\u5217\u8fdb\u884c\u8ba1\u6570\uff08 \u5e38\u7528 \uff09 inter \u591a\u4e2a\u6587\u4ef6\u95f4\u7684\u4ea4\u96c6 grep \u6307\u5b9a\uff08\u591a\uff09\u5217\u4e3aKey\u8fdb\u884c\u641c\u7d22\uff08 \u6700\u5e38\u7528\u547d\u4ee4\u4e4b\u4e00\uff0c\u53ef\u6309\u6307\u5b9a\u5217\u641c\u7d22 \uff09 filter \u6309\u6307\u5b9a\uff08\u591a\uff09\u5217\u7684\u6570\u503c\u8fdb\u884c\u8fc7\u6ee4 filter2 \u7528\u7c7b\u4f3cawk\u7684\u6570\u503c/\u8868\u8fbe\u5f0f\uff0c\u6309\u6307\u5b9a\uff08\u591a\uff09\u5217\u7684\u6570\u503c\u8fdb\u884c\u8fc7\u6ee4 join \u5408\u5e76\u591a\u4e2a\u6587\u4ef6\uff08 \u5e38\u7528 \uff09 \u7f16\u8f91 rename \u76f4\u63a5\u91cd\u547d\u540d\u6307\u5b9a\uff08\u591a\uff09\u5217\u540d\uff08 \u7b80\u5355\u800c\u5b9e\u7528 \uff09 rename2 \u4ee5\u6b63\u5219\u8868\u8fbe\u5f0f\u91cd\u547d\u540d\u6307\u5b9a\uff08\u591a\uff09\u5217\u540d\uff08 \u7b80\u5355\u800c\u5b9e\u7528 \uff09 replace \u4ee5\u6b63\u5219\u8868\u8fbe\u5f0f\u5bf9\u6307\u5b9a\uff08\u591a\uff09\u5217\u8fdb\u884c\u66ff\u6362\u7f16\u8f91\uff08 \u6700\u5e38\u7528\u547d\u4ee4\u4e4b\u4e00\uff0c\u53ef\u6309\u6307\u5b9a\u5217\u7f16\u8f91 \uff09 mutate \u4ee5\u6b63\u5219\u8868\u8fbe\u5f0f\u57fa\u4e8e\u5df2\u6709\u5217\u521b\u5efa\u65b0\u7684\u4e00\u5217\uff08 \u5e38\u7528\u4e8e\u751f\u6210\u591a\u5217\u6d4b\u8bd5\u6570\u636e \uff09 mutate2 \u7528\u7c7b\u4f3cawk\u7684\u6570\u503c/\u8868\u8fbe\u5f0f\uff0c\u4ee5\u6b63\u5219\u8868\u8fbe\u5f0f\u57fa\u4e8e\u5df2\u6709\uff08\u591a\uff09\u5217\u521b\u5efa\u65b0\u7684\u4e00\u5217\uff08 \u5e38\u7528 \uff09 gather \u7c7b\u4f3c\u4e8eR\u91cc\u9762tidyr\u5305\u7684gather\u65b9\u6cd5 \u6392\u5e8f sort \u6309\u6307\u5b9a\uff08\u591a\uff09\u5217\u8fdb\u884c\u6392\u5e8f \u7ed8\u56fe plot \u57fa\u672c\u7ed8\u56fe plot hist histogram plot box boxplot plot line line plot and scatter plot \u5176\u5b83 version \u7248\u672c\u4fe1\u606f\u548c\u68c0\u67e5\u65b0\u7248\u672c genautocomplete \u751f\u6210\u652f\u6301Bash\u81ea\u52a8\u8865\u5168\u7684\u914d\u7f6e\u6587\u4ef6\uff0c\u91cd\u542fTerminal\u751f\u6548\u3002 \u4f7f\u7528 \u8f93\u5165\u6570\u636e\u8981\u6c42\u6bcf\u884c\u7684\u5217\u6570\u4e00\u81f4\uff0c\u7a7a\u884c\u4e5f\u4f1a\u62a5\u9519 csvtk\u9ed8\u8ba4\u8f93\u5165\u6570\u636e\u542b\u6709\u6807\u9898\u884c\uff0c\u5982\u6ca1\u6709\u8bf7\u5f00\u542f\u5168\u5c40\u53c2\u6570 -H csvtk\u9ed8\u8ba4\u8f93\u5165\u6570\u636e\u4e3aCSV\u683c\u5f0f\uff0c\u5982\u4e3aTSV\u8bf7\u5f00\u542f\u5168\u5c40\u53c2\u6570 -t \u8f93\u5165\u6570\u636e\u5217\u540d\u6700\u597d\u552f\u4e00\u65e0\u91cd\u590d \u5982\u679cTSV\u4e2d\u5b58\u5728\u53cc\u5f15\u53f7 \"\" \uff0c\u8bf7\u5f00\u542f\u5168\u5c40\u53c2\u6570 -l csvtk\u9ed8\u8ba4\u4ee5 # \u5f00\u59cb\u7684\u4e3a\u6ce8\u91ca\u884c\uff0c\u82e5\u6807\u9898\u884c\u542b # \uff0c\u8bf7\u7ed9\u5168\u5c40\u53c2\u6570 -C \u6307\u5b9a\u53e6\u4e00\u4e2a\u4e0d\u5e38\u89c1\u7684\u5b57\u7b26\uff08\u5982 $ \uff09 \u4f8b\u5b50 \u4ec5\u63d0\u4f9b\u5c11\u91cf\u4f8b\u5b50\uff0c\u66f4\u591a\u4f8b\u5b50\u8bf7\u770b\u4f7f\u7528\u624b\u518c http://bioinf.shenwei.me/csvtk/usage/ \u3002 \u793a\u4f8b\u6570\u636e $ cat names.csv id,first_name,last_name,username 11,\"Rob\",\"Pike\",rob 2,Ken,Thompson,ken 4,\"Robert\",\"Griesemer\",\"gri\" 1,\"Robert\",\"Thompson\",\"abc\" NA,\"Robert\",\"Abel\",\"123\" \u589e\u5f3a\u53ef\u8bfb\u6027 $ cat names.csv | csvtk pretty id first_name last_name username 11 Rob Pike rob 2 Ken Thompson ken 4 Robert Griesemer gri 1 Robert Thompson abc NA Robert Abel 123 \u8f6c\u4e3amarkdown $ cat names.csv | csvtk csv2md id |first_name|last_name|username :--|:---------|:--------|:------- 11 |Rob |Pike |rob 2 |Ken |Thompson |ken 4 |Robert |Griesemer|gri 1 |Robert |Thompson |abc NA |Robert |Abel |123 \u6548\u679c id first_name last_name username 11 Rob Pike rob 2 Ken Thompson ken 4 Robert Griesemer gri 1 Robert Thompson abc NA Robert Abel 123 \u7528\u5217\u6216\u5217\u540d\u6765\u9009\u62e9\u6307\u5b9a\u5217\uff0c\u53ef\u6539\u53d8\u5217\u7684\u987a\u5e8f $ cat names.csv | csvtk cut -f 3,1 | csvtk pretty $ cat names.csv | csvtk cut -f last_name,id | csvtk pretty last_name id Pike 11 Thompson 2 Griesemer 4 Thompson 1 Abel NA \u7528\u901a\u914d\u7b26\u9009\u62e9\u591a\u5217 $ cat names.csv | csvtk cut -F -f '*name,id' | csvtk pretty first_name last_name username id Rob Pike rob 11 Ken Thompson ken 2 Robert Griesemer gri 4 Robert Thompson abc 1 Robert Abel 123 NA \u5220\u9664\u7b2c2\uff0c3\u5217\uff08 \u4e0b\u5217\u7b2c\u4e8c\u79cd\u65b9\u6cd5\u662f\u9009\u5b9a\u8303\u56f4\uff0c\u4f46-3\u5728\u524d,-2\u5728\u540e \uff09 $ cat names.csv | csvtk cut -f -2,-3 | csvtk pretty $ cat names.csv | csvtk cut -f -3--2 | csvtk pretty $ cat names.csv | csvtk cut -f -first_name,-last_name | csvtk pretty id username 11 rob 2 ken 4 gri 1 abc NA 123 \u6309\u6307\u5b9a\u5217\u641c\u7d22\uff0c \u9ed8\u8ba4\u7cbe\u786e\u5339\u914d $ cat names.csv | csvtk grep -f id -p 1 | csvtk pretty id first_name last_name username 1 Robert Thompson abc \u6a21\u7cca\u641c\u7d22\uff08\u6b63\u5219\u8868\u8fbe\u5f0f\uff09 $ cat names.csv | csvtk grep -f id -p 1 -r | csvtk pretty id first_name last_name username 11 Rob Pike rob 1 Robert Thompson abc \u7528\u6587\u4ef6\u4f5c\u4e3a\u6a21\u5f0f\u6765\u6e90 $ cat names.csv | csvtk grep -f id -P id-files.txt \u5bf9\u6307\u5b9a\u5217\u505a\u7b80\u5355\u66ff\u6362 $ cat names.csv | csvtk replace -f id -p '(\\d+)' -r 'ID: $1' \\ | csvtk pretty id first_name last_name username ID: 11 Rob Pike rob ID: 2 Ken Thompson ken ID: 4 Robert Griesemer gri ID: 1 Robert Thompson abc NA Robert Abel 123 \u7528key-value\u6587\u4ef6\u6765\u66ff\u6362\uff08seqkit\u548cbrename\u90fd\u652f\u6301\u7c7b\u4f3c\u64cd\u4f5c\uff09 $ cat data.tsv name id A ID001 B ID002 C ID004 $ cat alias.tsv 001 Tom 002 Bob 003 Jim $ csvtk replace -t -f 2 -p \"ID(.+)\" -r \"N: {nr}, alias: {kv}\" -k \\ alias.tsv data.tsv name id A N: 1, alias: Tom B N: 2, alias: Bob C N: 3, alias: 004 \u5408\u5e76\u8868\u683c\uff0c\u9700\u8981\u5206\u522b\u6307\u5b9a\u5404\u6587\u4ef6\u4e2d\u7684key\u5217\uff1a\u9ed8\u8ba4\u5747\u4e3a\u7b2c\u4e00\u5217\uff1b\u82e5\u5217\uff08\u540d\uff09\u76f8\u540c\u63d0\u4f9b\u4e00\u4e2a\uff1b\u82e5\u4e0d\u540c\u7528\u5206\u53f7\u5206\u5272 $ cat testdata/phones.csv username,phone gri,11111 rob,12345 ken,22222 shenwei,999999 $ csvtk join -f 'username;username' --keep-unmatched names.csv phones.csv \\ | csvtk pretty id first_name last_name username phone 11 Rob Pike rob 12345 2 Ken Thompson ken 22222 4 Robert Griesemer gri 11111 1 Robert Thompson abc NA Robert Abel 123","title":"\u4e2d\u6587\u4ecb\u7ecd"},{"location":"chinese/#_1","text":"\u57fa\u672c\u4fe1\u606f \u5de5\u5177\u7c7b\u578b: \u547d\u4ee4\u884c\u5de5\u5177\uff0c\u5b50\u547d\u4ee4\u7ed3\u6784 \u652f\u6301\u683c\u5f0f: CSV/TSV, plain/gzip-compressed \u7f16\u7a0b\u8bed\u8a00: Go \u652f\u6301\u5e73\u53f0: Linux, OS X\uff0c Windows \u7b49 \u53d1\u5e03\u65b9\u5f0f: \u5355\u4e00\u53ef\u6267\u884c\u4e8c\u8fdb\u5236\u6587\u4ef6\uff0c\u4e0b\u8f7d\u5373\u7528 \u53d1\u5e03\u5e73\u53f0: Github, Bioconda \u9879\u76ee\u4e3b\u9875: http://bioinf.shenwei.me/csvtk/ \u5f00\u6e90\u5730\u5740: https://github.com/shenwei356/csvtk \u7279\u6027 \u8de8\u5e73\u53f0 \u8f7b\u91cf\uff0c\u65e0\u4efb\u4f55\u4f9d\u8d56\uff0c\u65e0\u9700\u7f16\u8bd1\u3001\u914d\u7f6e\uff0c\u4e0b\u8f7d\u5373\u7528 \u5feb\u901f \u652f\u6301stdin\u548cgzip\u538b\u7f29\u7684\u8f93\u5165\u548c\u8f93\u51fa\u6587\u4ef6\uff0c\u4fbf\u4e8e\u6d41\u5904\u7406 27\u4e2a\u5b50\u547d\u4ee4\u63d0\u4f9b\u591a\u79cd\u5b9e\u7528\u7684\u529f\u80fd\uff0c\u4e14\u80fd\u901a\u8fc7\u547d\u4ee4\u884c\u7ba1\u9053\u7ec4\u5408 \u652f\u6301Bash\u81ea\u52a8\u8865\u5168 \u652f\u6301\u7b80\u5355\u7684\u7ed8\u56fe","title":"\u4ecb\u7ecd"},{"location":"chinese/#_2","text":"\u5728\u5f00\u53d1csvtk\u4e4b\u524d\u7684\u4e24\u4e09\u5e74\u95f4\uff0c\u6211\u5df2\u7ecf\u5199\u4e86\u51e0\u4e2a\u53ef\u4ee5\u590d\u7528\u7684Python/Perl\u811a\u672c\uff08https://github.com/shenwei356/datakit\uff09 \uff0c\u5305\u62eccsv2tab\u3001csvtk_grep\u3001csv_join\u3001csv_melt\uff0cintersection\uff0cunique\u3002\u6240\u4ee5\u6211\u7684\u8ba1\u5212\u662f\u9996\u5148\u96c6\u6210\u8fd9\u4e9b\u5df2\u6709\u7684\u529f\u80fd\uff0c\u968f\u540e\u6839\u636e\u9700\u6c42\u8fdb\u884c\u6269\u5c55\u3002 \u5230\u76ee\u524d\u4e3a\u6b62\uff0ccsvtk\u5df2\u670927\u4e2a\u5b50\u547d\u4ee4\uff0c\u5206\u4e3a\u4ee5\u4e0b\u51e0\u5927\u7c7b\uff1a \u4fe1\u606f headers \u76f4\u89c2\u6253\u5370\u6807\u9898\u884c\uff08 \u64cd\u4f5c\u5217\u6570\u8f83\u591a\u7684CSV\u524d\u4f7f\u7528\u6700\u4f73 \uff09 stats \u57fa\u672c\u7edf\u8ba1 stats2 \u5bf9\u9009\u5b9a\u7684\u6570\u503c\u5217\u8fdb\u884c\u57fa\u672c\u7edf\u8ba1 \u683c\u5f0f\u8f6c\u5316 pretty \u8f6c\u4e3a\u7f8e\u89c2\u3001\u53ef\u8bfb\u6027\u5f3a\u7684\u683c\u5f0f\uff08 \u6700\u5e38\u7528\u547d\u4ee4\u4e4b\u4e00 \uff09 csv2tab \u8f6cCSV\u4e3a\u5236\u8868\u7b26\u5206\u5272\u683c\u5f0f\uff08TSV\uff09 tab2csv \u8f6cTSV\u4e3aCSV space2tab \u8f6c\u7a7a\u683c\u5206\u5272\u683c\u5f0f\u4e3aTSV transpose \u8f6c\u7f6eCSV/TSV csv2md \u8f6cCSV/TSV\u4e3amakrdown\u683c\u5f0f\uff08 \u5199\u6587\u6863\u5e38\u7528 \uff09 \u96c6\u5408\u64cd\u4f5c head \u6253\u5370\u524dN\u6761\u8bb0\u5f55 sample \u6309\u6bd4\u4f8b\u968f\u673a\u91c7\u6837 cut \u9009\u62e9\u7279\u5b9a\u5217\uff0c\u652f\u6301 \u6309\u5217\u6216\u5217\u540d\u8fdb\u884c\u57fa\u672c\u9009\u62e9\u3001\u8303\u56f4\u9009\u62e9\u3001\u6a21\u7cca\u9009\u62e9\u3001\u8d1f\u5411\u9009\u62e9 \uff08 \u6700\u5e38\u7528\u547d\u4ee4\u4e4b\u4e00\uff0c\u975e\u5e38\u5f3a\u5927 \uff09 uniq \u65e0\u987b\u6392\u5e8f\uff0c\u8fd4\u56de\u6309\u6307\u5b9a\uff08\u591a\uff09\u5217\u4f5c\u4e3akey\u7684\u552f\u4e00\u8bb0\u5f55\uff08\u597d\u7ed5\u3002\u3002\uff09 freq \u6309\u6307\u5b9a\uff08\u591a\uff09\u5217\u8fdb\u884c\u8ba1\u6570\uff08 \u5e38\u7528 \uff09 inter \u591a\u4e2a\u6587\u4ef6\u95f4\u7684\u4ea4\u96c6 grep \u6307\u5b9a\uff08\u591a\uff09\u5217\u4e3aKey\u8fdb\u884c\u641c\u7d22\uff08 \u6700\u5e38\u7528\u547d\u4ee4\u4e4b\u4e00\uff0c\u53ef\u6309\u6307\u5b9a\u5217\u641c\u7d22 \uff09 filter \u6309\u6307\u5b9a\uff08\u591a\uff09\u5217\u7684\u6570\u503c\u8fdb\u884c\u8fc7\u6ee4 filter2 \u7528\u7c7b\u4f3cawk\u7684\u6570\u503c/\u8868\u8fbe\u5f0f\uff0c\u6309\u6307\u5b9a\uff08\u591a\uff09\u5217\u7684\u6570\u503c\u8fdb\u884c\u8fc7\u6ee4 join \u5408\u5e76\u591a\u4e2a\u6587\u4ef6\uff08 \u5e38\u7528 \uff09 \u7f16\u8f91 rename \u76f4\u63a5\u91cd\u547d\u540d\u6307\u5b9a\uff08\u591a\uff09\u5217\u540d\uff08 \u7b80\u5355\u800c\u5b9e\u7528 \uff09 rename2 \u4ee5\u6b63\u5219\u8868\u8fbe\u5f0f\u91cd\u547d\u540d\u6307\u5b9a\uff08\u591a\uff09\u5217\u540d\uff08 \u7b80\u5355\u800c\u5b9e\u7528 \uff09 replace \u4ee5\u6b63\u5219\u8868\u8fbe\u5f0f\u5bf9\u6307\u5b9a\uff08\u591a\uff09\u5217\u8fdb\u884c\u66ff\u6362\u7f16\u8f91\uff08 \u6700\u5e38\u7528\u547d\u4ee4\u4e4b\u4e00\uff0c\u53ef\u6309\u6307\u5b9a\u5217\u7f16\u8f91 \uff09 mutate \u4ee5\u6b63\u5219\u8868\u8fbe\u5f0f\u57fa\u4e8e\u5df2\u6709\u5217\u521b\u5efa\u65b0\u7684\u4e00\u5217\uff08 \u5e38\u7528\u4e8e\u751f\u6210\u591a\u5217\u6d4b\u8bd5\u6570\u636e \uff09 mutate2 \u7528\u7c7b\u4f3cawk\u7684\u6570\u503c/\u8868\u8fbe\u5f0f\uff0c\u4ee5\u6b63\u5219\u8868\u8fbe\u5f0f\u57fa\u4e8e\u5df2\u6709\uff08\u591a\uff09\u5217\u521b\u5efa\u65b0\u7684\u4e00\u5217\uff08 \u5e38\u7528 \uff09 gather \u7c7b\u4f3c\u4e8eR\u91cc\u9762tidyr\u5305\u7684gather\u65b9\u6cd5 \u6392\u5e8f sort \u6309\u6307\u5b9a\uff08\u591a\uff09\u5217\u8fdb\u884c\u6392\u5e8f \u7ed8\u56fe plot \u57fa\u672c\u7ed8\u56fe plot hist histogram plot box boxplot plot line line plot and scatter plot \u5176\u5b83 version \u7248\u672c\u4fe1\u606f\u548c\u68c0\u67e5\u65b0\u7248\u672c genautocomplete \u751f\u6210\u652f\u6301Bash\u81ea\u52a8\u8865\u5168\u7684\u914d\u7f6e\u6587\u4ef6\uff0c\u91cd\u542fTerminal\u751f\u6548\u3002","title":"\u529f\u80fd"},{"location":"chinese/#_3","text":"\u8f93\u5165\u6570\u636e\u8981\u6c42\u6bcf\u884c\u7684\u5217\u6570\u4e00\u81f4\uff0c\u7a7a\u884c\u4e5f\u4f1a\u62a5\u9519 csvtk\u9ed8\u8ba4\u8f93\u5165\u6570\u636e\u542b\u6709\u6807\u9898\u884c\uff0c\u5982\u6ca1\u6709\u8bf7\u5f00\u542f\u5168\u5c40\u53c2\u6570 -H csvtk\u9ed8\u8ba4\u8f93\u5165\u6570\u636e\u4e3aCSV\u683c\u5f0f\uff0c\u5982\u4e3aTSV\u8bf7\u5f00\u542f\u5168\u5c40\u53c2\u6570 -t \u8f93\u5165\u6570\u636e\u5217\u540d\u6700\u597d\u552f\u4e00\u65e0\u91cd\u590d \u5982\u679cTSV\u4e2d\u5b58\u5728\u53cc\u5f15\u53f7 \"\" \uff0c\u8bf7\u5f00\u542f\u5168\u5c40\u53c2\u6570 -l csvtk\u9ed8\u8ba4\u4ee5 # \u5f00\u59cb\u7684\u4e3a\u6ce8\u91ca\u884c\uff0c\u82e5\u6807\u9898\u884c\u542b # \uff0c\u8bf7\u7ed9\u5168\u5c40\u53c2\u6570 -C \u6307\u5b9a\u53e6\u4e00\u4e2a\u4e0d\u5e38\u89c1\u7684\u5b57\u7b26\uff08\u5982 $ \uff09","title":"\u4f7f\u7528"},{"location":"chinese/#_4","text":"\u4ec5\u63d0\u4f9b\u5c11\u91cf\u4f8b\u5b50\uff0c\u66f4\u591a\u4f8b\u5b50\u8bf7\u770b\u4f7f\u7528\u624b\u518c http://bioinf.shenwei.me/csvtk/usage/ \u3002 \u793a\u4f8b\u6570\u636e $ cat names.csv id,first_name,last_name,username 11,\"Rob\",\"Pike\",rob 2,Ken,Thompson,ken 4,\"Robert\",\"Griesemer\",\"gri\" 1,\"Robert\",\"Thompson\",\"abc\" NA,\"Robert\",\"Abel\",\"123\" \u589e\u5f3a\u53ef\u8bfb\u6027 $ cat names.csv | csvtk pretty id first_name last_name username 11 Rob Pike rob 2 Ken Thompson ken 4 Robert Griesemer gri 1 Robert Thompson abc NA Robert Abel 123 \u8f6c\u4e3amarkdown $ cat names.csv | csvtk csv2md id |first_name|last_name|username :--|:---------|:--------|:------- 11 |Rob |Pike |rob 2 |Ken |Thompson |ken 4 |Robert |Griesemer|gri 1 |Robert |Thompson |abc NA |Robert |Abel |123 \u6548\u679c id first_name last_name username 11 Rob Pike rob 2 Ken Thompson ken 4 Robert Griesemer gri 1 Robert Thompson abc NA Robert Abel 123 \u7528\u5217\u6216\u5217\u540d\u6765\u9009\u62e9\u6307\u5b9a\u5217\uff0c\u53ef\u6539\u53d8\u5217\u7684\u987a\u5e8f $ cat names.csv | csvtk cut -f 3,1 | csvtk pretty $ cat names.csv | csvtk cut -f last_name,id | csvtk pretty last_name id Pike 11 Thompson 2 Griesemer 4 Thompson 1 Abel NA \u7528\u901a\u914d\u7b26\u9009\u62e9\u591a\u5217 $ cat names.csv | csvtk cut -F -f '*name,id' | csvtk pretty first_name last_name username id Rob Pike rob 11 Ken Thompson ken 2 Robert Griesemer gri 4 Robert Thompson abc 1 Robert Abel 123 NA \u5220\u9664\u7b2c2\uff0c3\u5217\uff08 \u4e0b\u5217\u7b2c\u4e8c\u79cd\u65b9\u6cd5\u662f\u9009\u5b9a\u8303\u56f4\uff0c\u4f46-3\u5728\u524d,-2\u5728\u540e \uff09 $ cat names.csv | csvtk cut -f -2,-3 | csvtk pretty $ cat names.csv | csvtk cut -f -3--2 | csvtk pretty $ cat names.csv | csvtk cut -f -first_name,-last_name | csvtk pretty id username 11 rob 2 ken 4 gri 1 abc NA 123 \u6309\u6307\u5b9a\u5217\u641c\u7d22\uff0c \u9ed8\u8ba4\u7cbe\u786e\u5339\u914d $ cat names.csv | csvtk grep -f id -p 1 | csvtk pretty id first_name last_name username 1 Robert Thompson abc \u6a21\u7cca\u641c\u7d22\uff08\u6b63\u5219\u8868\u8fbe\u5f0f\uff09 $ cat names.csv | csvtk grep -f id -p 1 -r | csvtk pretty id first_name last_name username 11 Rob Pike rob 1 Robert Thompson abc \u7528\u6587\u4ef6\u4f5c\u4e3a\u6a21\u5f0f\u6765\u6e90 $ cat names.csv | csvtk grep -f id -P id-files.txt \u5bf9\u6307\u5b9a\u5217\u505a\u7b80\u5355\u66ff\u6362 $ cat names.csv | csvtk replace -f id -p '(\\d+)' -r 'ID: $1' \\ | csvtk pretty id first_name last_name username ID: 11 Rob Pike rob ID: 2 Ken Thompson ken ID: 4 Robert Griesemer gri ID: 1 Robert Thompson abc NA Robert Abel 123 \u7528key-value\u6587\u4ef6\u6765\u66ff\u6362\uff08seqkit\u548cbrename\u90fd\u652f\u6301\u7c7b\u4f3c\u64cd\u4f5c\uff09 $ cat data.tsv name id A ID001 B ID002 C ID004 $ cat alias.tsv 001 Tom 002 Bob 003 Jim $ csvtk replace -t -f 2 -p \"ID(.+)\" -r \"N: {nr}, alias: {kv}\" -k \\ alias.tsv data.tsv name id A N: 1, alias: Tom B N: 2, alias: Bob C N: 3, alias: 004 \u5408\u5e76\u8868\u683c\uff0c\u9700\u8981\u5206\u522b\u6307\u5b9a\u5404\u6587\u4ef6\u4e2d\u7684key\u5217\uff1a\u9ed8\u8ba4\u5747\u4e3a\u7b2c\u4e00\u5217\uff1b\u82e5\u5217\uff08\u540d\uff09\u76f8\u540c\u63d0\u4f9b\u4e00\u4e2a\uff1b\u82e5\u4e0d\u540c\u7528\u5206\u53f7\u5206\u5272 $ cat testdata/phones.csv username,phone gri,11111 rob,12345 ken,22222 shenwei,999999 $ csvtk join -f 'username;username' --keep-unmatched names.csv phones.csv \\ | csvtk pretty id first_name last_name username phone 11 Rob Pike rob 12345 2 Ken Thompson ken 22222 4 Robert Griesemer gri 11111 1 Robert Thompson abc NA Robert Abel 123","title":"\u4f8b\u5b50"},{"location":"download/","text":"Download csvtk is implemented in Go programming language, executable binary files for most popular operating system are freely available in release page. Current Version csvtk v0.19.1 csvtk : fix checking file existence. show friendly error message when giving empty field like csvtk cut -f a, b . csvtk summary : fix err of q1 and q3. #90 csvtk version : making checking update optional. Links: Tips run csvtk version to check update !!! run csvtk genautocomplete to update Bash completion !!! OS Arch File, \u4e2d\u56fd\u955c\u50cf Download Count Linux 32-bit csvtk_linux_386.tar.gz , \u4e2d\u56fd\u955c\u50cf Linux 64-bit csvtk_linux_amd64.tar.gz , \u4e2d\u56fd\u955c\u50cf OS X 32-bit csvtk_darwin_386.tar.gz , \u4e2d\u56fd\u955c\u50cf OS X 64-bit csvtk_darwin_amd64.tar.gz , \u4e2d\u56fd\u955c\u50cf Windows 32-bit csvtk_windows_386.exe.tar.gz , \u4e2d\u56fd\u955c\u50cf Windows 64-bit csvtk_windows_amd64.exe.tar.gz , \u4e2d\u56fd\u955c\u50cf Installation Download Page csvtk is implemented in Go programming language, executable binary files for most popular operating systems are freely available in release page. Method 1: Download binaries (latest stable/dev version) Just download compressed executable file of your operating system, and decompress it with tar -zxvf *.tar.gz command or other tools. And then: For Linux-like systems If you have root privilege simply copy it to /usr/local/bin : sudo cp csvtk /usr/local/bin/ Or copy to anywhere in the environment variable PATH : mkdir -p $HOME/bin/; cp csvtk $HOME/bin/ For windows , just copy csvtk.exe to C:\\WINDOWS\\system32 . Method 2: Install via conda (latest stable version) conda install -c bioconda csvtk Method 3: Install via homebrew (latest stable version) brew install brewsci/bio/csvtk Method 4: For Go developer (latest stable/dev version) go get -u github.com/shenwei356/csvtk/csvtk Method 5: For ArchLinux AUR users (may be not the latest) yaourt -S csvtk Bash-completion Note: The current version supports Bash only. This should work for *nix systems with Bash installed. Howto: run: csvtk genautocomplete create and edit ~/.bash_completion file if you don't have it. nano ~/.bash_completion add the following: for bcfile in ~/.bash_completion.d/* ; do . $bcfile done Previous Versions csvtk v0.19.0 new commands by @bsipos : watch : online monitoring and histogram of selected field. corr : calculate Pearson correlation between numeric columns. cat : stream file and report progress. csvtk split : fix bug of repeatedly output header line when number of output files exceed value of --buf-groups . #83 csvtk plot hist : new option --percentiles to add percentiles to histogram x label. #88 csvtk v0.18.2 csvtk replace/rename2/splitxlsx : fix flag conflicts with global flag -I since v0.18.0. csvtk replace/rename2 : removing shorthand flag -I for --key-capt-idx . csvtk splitxlsx : changing shorthand flag of --sheet-index from -I to -N . csvtk v0.18.1 csvtk sort : fix mutiple-key-sort containing natural order sorting. #79 csvtk xlsx2csv : reacts to global flags -t , -T , -D and -E . #78 csvtk v0.18.0 csvtk : add new flag --ignore-illegal-row to skip illegal rows. #72 csvtk summary : add more textual/numeric operations. #64 csvtk sort : fix bug for sorting by columns with empty values. #70 csvtk grep : add new flag --delete-matched to delete a pattern right after being matched, this keeps the firstly matched data and speedups when using regular expressions. #77 csvtk v0.17.0 new command: csvtk add-header and csvtk del-header for adding/deleting column names. [#62] csvtk v0.16.0 new command: csvtk csv2json : convert CSV to JSON format. remove comand: csvtk stats2 . new command csvtk summary : summary statistics of selected digital fields (groupby group fields), usage and examples . #59 csvtk replace : add flag --nr-width : minimum width for {nr} in flag -r/--replacement. e.g., formating \"1\" to \"001\" by --nr-width 3 (default 1) csvtk rename2/replace : add flag -A, --kv-file-all-left-columns-as-value , for treating all columns except 1th one as value for kv-file with more than 2 columns. #56 csvtk v0.15.0 csvtk : add global flag -E/--ignore-empty-row to skip empty row. #50 csvtk mutate2 : add flag -s/--digits-as-string for not converting big digits into scientific notation. #46 csvtk sort : add support for sorting in natural order. #49 csvtk v0.14.0 csvtk : supporting multi-line fields by replacing multicorecsv with standard library encoding/csv , while losing support for metaline which was supported since v0.7.0 . It also gain a little speedup. csvtk sample : add flag -n/--line-number to print line number as the first column (\"n\") csvtk filter2 : fix bug when column names start with digits, e.g., 1000g2015aug ( #44 ) csvtk rename2 : add support for similar repalecement symbols {kv} and {nr} in csvtk replace csvtk v0.13.0 new command concat for concatenating CSV/TSV files by rows #38 csvtk : add support for environment variables for frequently used global flags #39 CSVTK_T for flag -t/--tabs CSVTK_H for flag -H/--no-header-row mutate2 : add support for eval expression WITHOUT column index symbol, so we can add some string constants #37 pretty : better support for files with duplicated column names csvtk v0.12.0 new command collapse : collapsing one field with selected fields as keys freq : keeping orignal order of keys by default split : performance improvement add option -G/--out-gzip for forcing output gzipped file csvtk v0.11.0 add command split to split CSV/TSV into multiple files according to column values add command splitxlxs to split XLSX sheet into multiple sheets according to column values csvtk , automatically check BOM (byte-order mark) and discard it csvtk v0.10.0 add subcommand xlsx2csv to convert XLSX to CSV format grep , filter , filter2 : add flag -n/--line-number to print line-number as the first column cut : add flag -i/--ignore-case to ignore case of column name csvtk v0.9.1 csvtk replace : fix bug when replacing with key-value pairs brought in v0.8.0 csvtk v0.9.0 add subcommand csvtk mutate2 : create new column from selected fields by awk-like artithmetic/string expressions add new command genautocomplete to generate shell autocompletion script! csvtk v0.8.0 new command csvtk gather for gathering columns into key-value pairs . csvtk sort : support sorting by user-defined order . fix bug of unselecting field : wrongly reporting error of fields not existing. affected commands: cut , filter , fitler2 , freq , grep , inter , mutate , rename , rename2 , replace , stats2 , uniq . update help message of flag -F/--fuzzy-fields . update help message of global flag -t , which overrides both -d and -D . If you want other delimiter for tabular input, use -t $'\\t' -D \"delimiter\" . csvtk v0.7.1 csvtk plot box and csvtk plot line : fix bugs for special cases of input compile with go1.8.1 csvtk v0.7.0 fig bug of \"stricter field checking\" in v0.6.0 and v0.6.1 when using flag -F/--fuzzy-fields csvtk pretty and csvtk csv2md : add attention that these commands treat the first row as header line and require them to be unique. csvtk stat renamed to csvtk stats , old name is still available as an alias. csvtk stat2 renamed to csvtk stats2 , old name is still available as an alias. issues/13 seamlessly support for data with meta line of separator declaration used by MS Excel . csvtk v0.6.1 csvtk cut : minor bug: panic when no fields given. i.e., csvtk cut . All relevant commands have been fixed. csvtk v0.6.0 csvtk grep : large performance improvement by discarding goroutine (multiple threads), and keeping output in order of input . Better column name checking and stricter field checking, fields out of range are not ignored now . Affected commands include cut , filter , freq , grep , inter , mutate , rename , rename2 , replace , stat2 , and uniq . New command: csvtk filter2 , filtering rows by artithmetic/string expressions like awk . csvtk v0.5.0 csvtk cut : delete flag -n/--names , move it to a new command csvtk headers new command: csvtk headers new command: csvtk head new command: csvtk sample csvtk v0.4.6 csvtk grep : fix result highlight when flag -v is on. csvtk v0.4.5 csvtk join : support the 2nd or later files with entries with same ID. csvtk v0.4.4 add command csvtk freq : frequencies of selected fields add lots of examples in usage page csvtk v0.4.3 improvement of using experience: flag -n is not required anymore when flag -H in csvtk mutate csvtk v0.4.2 fix highlight bug of csvtk grep : if the pattern matches multiple parts, the text will be wrongly edited. changes: disable highlight when pattern file given. change the default output of all ploting commands to STDOUT, now you can pipe the image to \"display\" command of Imagemagic. csvtk v0.4.1 Nothing changed. Just fix the links due to inappropriate deployment of v0.4.0 csvtk v0.4.0 add flag for csvtk replace : -K ( --keep-key ) keep the key as value when no value found for the key. This is open in default in previous versions. csvtk v0.3.9 fix bug: header row incomplete in csvtk sort result csvtk v0.3.8.1 fix bug of flag parsing library pflag , detail . The bug affected the csvtk grep -r -p , when value of -p contain \"[\" and \"]\" at the beginning or end, they are wrongly parsed. csvtk v0.3.8 new feature: csvtk cut supports ordered fields output. e.g., csvtk cut -f 2,1 outputs the 2nd column in front of 1th column. new commands: csvtk plot can plot three types of plots by subcommands: csvtk plot hist : histogram csvtk plot box : boxplot csvtk plot line : line plot and scatter plot csvtk v0.3.7 fix a serious bug of using negative field of column name, e.g. -f \"-id\" csvtk v0.3.6 csvtk replace support replacement symbols {nr} (record number) and {kv} (corresponding value of the key ($1) by key-value file) csvtk v0.3.5.2 add flag --fill for csvtk join , so we can fill the unmatched data fix typo csvtk v0.3.5.1 fix minor bug of reading lines ending with \\r\\n from a dependency package csvtk v0.3.5 fix minor bug of csv2md add subcommand version which could check for update csvtk v0.3.4 fix bug of csvtk replace that head row should not be edited. csvtk v0.3.3 fix bug of csvtk grep -t -P csvtk v0.3.2 fix bug of inter csvtk v0.3.1 add support of search multiple fields for grep csvtk v0.3 add subcommand csv2md csvtk v0.2.9 add more flags to subcommand pretty fix bug of csvtk cut -n add subcommand filter csvtk v0.2.8 add subcommand pretty -- convert CSV to readable aligned table csvtk v0.2.7 fix highlight failing in windows csvtk v0.2.6 fix one error message of grep highlight matched fields in result of grep csvtk v0.2.5 fix bug of stat that failed to considerate files with header row add subcommand stat2 - summary of selected number fields make the output of stat prettier csvtk v0.2.4 fix bug of handling comment lines add some notes before using csvtk csvtk v0.2.3 add flag --colnames to cut flag -f ( --fields ) of join supports single value now csvtk v0.2.2 add flag --keep-unmathed to join csvtk v0.2 finish almost functions csvtk v0.2.1 fix bug of mutate /** * RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS. * LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables */ /* var disqus_config = function () { this.page.url = PAGE_URL; // Replace PAGE_URL with your page's canonical URL variable this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable }; */ (function() { // DON'T EDIT BELOW THIS LINE var d = document, s = d.createElement('script'); s.src = '//csvtk.disqus.com/embed.js'; s.setAttribute('data-timestamp', +new Date()); (d.head || d.body).appendChild(s); })(); Please enable JavaScript to view the comments powered by Disqus.","title":"Download"},{"location":"download/#download","text":"csvtk is implemented in Go programming language, executable binary files for most popular operating system are freely available in release page.","title":"Download"},{"location":"download/#current-version","text":"csvtk v0.19.1 csvtk : fix checking file existence. show friendly error message when giving empty field like csvtk cut -f a, b . csvtk summary : fix err of q1 and q3. #90 csvtk version : making checking update optional. Links: Tips run csvtk version to check update !!! run csvtk genautocomplete to update Bash completion !!! OS Arch File, \u4e2d\u56fd\u955c\u50cf Download Count Linux 32-bit csvtk_linux_386.tar.gz , \u4e2d\u56fd\u955c\u50cf Linux 64-bit csvtk_linux_amd64.tar.gz , \u4e2d\u56fd\u955c\u50cf OS X 32-bit csvtk_darwin_386.tar.gz , \u4e2d\u56fd\u955c\u50cf OS X 64-bit csvtk_darwin_amd64.tar.gz , \u4e2d\u56fd\u955c\u50cf Windows 32-bit csvtk_windows_386.exe.tar.gz , \u4e2d\u56fd\u955c\u50cf Windows 64-bit csvtk_windows_amd64.exe.tar.gz , \u4e2d\u56fd\u955c\u50cf","title":"Current Version"},{"location":"download/#installation","text":"Download Page csvtk is implemented in Go programming language, executable binary files for most popular operating systems are freely available in release page.","title":"Installation"},{"location":"download/#method-1-download-binaries-latest-stabledev-version","text":"Just download compressed executable file of your operating system, and decompress it with tar -zxvf *.tar.gz command or other tools. And then: For Linux-like systems If you have root privilege simply copy it to /usr/local/bin : sudo cp csvtk /usr/local/bin/ Or copy to anywhere in the environment variable PATH : mkdir -p $HOME/bin/; cp csvtk $HOME/bin/ For windows , just copy csvtk.exe to C:\\WINDOWS\\system32 .","title":"Method 1: Download binaries (latest stable/dev version)"},{"location":"download/#method-2-install-via-conda-latest-stable-version","text":"conda install -c bioconda csvtk","title":"Method 2: Install via conda (latest stable version)"},{"location":"download/#method-3-install-via-homebrew-latest-stable-version","text":"brew install brewsci/bio/csvtk","title":"Method 3: Install via homebrew  (latest stable version)"},{"location":"download/#method-4-for-go-developer-latest-stabledev-version","text":"go get -u github.com/shenwei356/csvtk/csvtk","title":"Method 4: For Go developer (latest stable/dev version)"},{"location":"download/#method-5-for-archlinux-aur-users-may-be-not-the-latest","text":"yaourt -S csvtk","title":"Method 5: For ArchLinux AUR users (may be not the latest)"},{"location":"download/#bash-completion","text":"Note: The current version supports Bash only. This should work for *nix systems with Bash installed. Howto: run: csvtk genautocomplete create and edit ~/.bash_completion file if you don't have it. nano ~/.bash_completion add the following: for bcfile in ~/.bash_completion.d/* ; do . $bcfile done","title":"Bash-completion"},{"location":"download/#previous-versions","text":"csvtk v0.19.0 new commands by @bsipos : watch : online monitoring and histogram of selected field. corr : calculate Pearson correlation between numeric columns. cat : stream file and report progress. csvtk split : fix bug of repeatedly output header line when number of output files exceed value of --buf-groups . #83 csvtk plot hist : new option --percentiles to add percentiles to histogram x label. #88 csvtk v0.18.2 csvtk replace/rename2/splitxlsx : fix flag conflicts with global flag -I since v0.18.0. csvtk replace/rename2 : removing shorthand flag -I for --key-capt-idx . csvtk splitxlsx : changing shorthand flag of --sheet-index from -I to -N . csvtk v0.18.1 csvtk sort : fix mutiple-key-sort containing natural order sorting. #79 csvtk xlsx2csv : reacts to global flags -t , -T , -D and -E . #78 csvtk v0.18.0 csvtk : add new flag --ignore-illegal-row to skip illegal rows. #72 csvtk summary : add more textual/numeric operations. #64 csvtk sort : fix bug for sorting by columns with empty values. #70 csvtk grep : add new flag --delete-matched to delete a pattern right after being matched, this keeps the firstly matched data and speedups when using regular expressions. #77 csvtk v0.17.0 new command: csvtk add-header and csvtk del-header for adding/deleting column names. [#62] csvtk v0.16.0 new command: csvtk csv2json : convert CSV to JSON format. remove comand: csvtk stats2 . new command csvtk summary : summary statistics of selected digital fields (groupby group fields), usage and examples . #59 csvtk replace : add flag --nr-width : minimum width for {nr} in flag -r/--replacement. e.g., formating \"1\" to \"001\" by --nr-width 3 (default 1) csvtk rename2/replace : add flag -A, --kv-file-all-left-columns-as-value , for treating all columns except 1th one as value for kv-file with more than 2 columns. #56 csvtk v0.15.0 csvtk : add global flag -E/--ignore-empty-row to skip empty row. #50 csvtk mutate2 : add flag -s/--digits-as-string for not converting big digits into scientific notation. #46 csvtk sort : add support for sorting in natural order. #49 csvtk v0.14.0 csvtk : supporting multi-line fields by replacing multicorecsv with standard library encoding/csv , while losing support for metaline which was supported since v0.7.0 . It also gain a little speedup. csvtk sample : add flag -n/--line-number to print line number as the first column (\"n\") csvtk filter2 : fix bug when column names start with digits, e.g., 1000g2015aug ( #44 ) csvtk rename2 : add support for similar repalecement symbols {kv} and {nr} in csvtk replace csvtk v0.13.0 new command concat for concatenating CSV/TSV files by rows #38 csvtk : add support for environment variables for frequently used global flags #39 CSVTK_T for flag -t/--tabs CSVTK_H for flag -H/--no-header-row mutate2 : add support for eval expression WITHOUT column index symbol, so we can add some string constants #37 pretty : better support for files with duplicated column names csvtk v0.12.0 new command collapse : collapsing one field with selected fields as keys freq : keeping orignal order of keys by default split : performance improvement add option -G/--out-gzip for forcing output gzipped file csvtk v0.11.0 add command split to split CSV/TSV into multiple files according to column values add command splitxlxs to split XLSX sheet into multiple sheets according to column values csvtk , automatically check BOM (byte-order mark) and discard it csvtk v0.10.0 add subcommand xlsx2csv to convert XLSX to CSV format grep , filter , filter2 : add flag -n/--line-number to print line-number as the first column cut : add flag -i/--ignore-case to ignore case of column name csvtk v0.9.1 csvtk replace : fix bug when replacing with key-value pairs brought in v0.8.0 csvtk v0.9.0 add subcommand csvtk mutate2 : create new column from selected fields by awk-like artithmetic/string expressions add new command genautocomplete to generate shell autocompletion script! csvtk v0.8.0 new command csvtk gather for gathering columns into key-value pairs . csvtk sort : support sorting by user-defined order . fix bug of unselecting field : wrongly reporting error of fields not existing. affected commands: cut , filter , fitler2 , freq , grep , inter , mutate , rename , rename2 , replace , stats2 , uniq . update help message of flag -F/--fuzzy-fields . update help message of global flag -t , which overrides both -d and -D . If you want other delimiter for tabular input, use -t $'\\t' -D \"delimiter\" . csvtk v0.7.1 csvtk plot box and csvtk plot line : fix bugs for special cases of input compile with go1.8.1 csvtk v0.7.0 fig bug of \"stricter field checking\" in v0.6.0 and v0.6.1 when using flag -F/--fuzzy-fields csvtk pretty and csvtk csv2md : add attention that these commands treat the first row as header line and require them to be unique. csvtk stat renamed to csvtk stats , old name is still available as an alias. csvtk stat2 renamed to csvtk stats2 , old name is still available as an alias. issues/13 seamlessly support for data with meta line of separator declaration used by MS Excel . csvtk v0.6.1 csvtk cut : minor bug: panic when no fields given. i.e., csvtk cut . All relevant commands have been fixed. csvtk v0.6.0 csvtk grep : large performance improvement by discarding goroutine (multiple threads), and keeping output in order of input . Better column name checking and stricter field checking, fields out of range are not ignored now . Affected commands include cut , filter , freq , grep , inter , mutate , rename , rename2 , replace , stat2 , and uniq . New command: csvtk filter2 , filtering rows by artithmetic/string expressions like awk . csvtk v0.5.0 csvtk cut : delete flag -n/--names , move it to a new command csvtk headers new command: csvtk headers new command: csvtk head new command: csvtk sample csvtk v0.4.6 csvtk grep : fix result highlight when flag -v is on. csvtk v0.4.5 csvtk join : support the 2nd or later files with entries with same ID. csvtk v0.4.4 add command csvtk freq : frequencies of selected fields add lots of examples in usage page csvtk v0.4.3 improvement of using experience: flag -n is not required anymore when flag -H in csvtk mutate csvtk v0.4.2 fix highlight bug of csvtk grep : if the pattern matches multiple parts, the text will be wrongly edited. changes: disable highlight when pattern file given. change the default output of all ploting commands to STDOUT, now you can pipe the image to \"display\" command of Imagemagic. csvtk v0.4.1 Nothing changed. Just fix the links due to inappropriate deployment of v0.4.0 csvtk v0.4.0 add flag for csvtk replace : -K ( --keep-key ) keep the key as value when no value found for the key. This is open in default in previous versions. csvtk v0.3.9 fix bug: header row incomplete in csvtk sort result csvtk v0.3.8.1 fix bug of flag parsing library pflag , detail . The bug affected the csvtk grep -r -p , when value of -p contain \"[\" and \"]\" at the beginning or end, they are wrongly parsed. csvtk v0.3.8 new feature: csvtk cut supports ordered fields output. e.g., csvtk cut -f 2,1 outputs the 2nd column in front of 1th column. new commands: csvtk plot can plot three types of plots by subcommands: csvtk plot hist : histogram csvtk plot box : boxplot csvtk plot line : line plot and scatter plot csvtk v0.3.7 fix a serious bug of using negative field of column name, e.g. -f \"-id\" csvtk v0.3.6 csvtk replace support replacement symbols {nr} (record number) and {kv} (corresponding value of the key ($1) by key-value file) csvtk v0.3.5.2 add flag --fill for csvtk join , so we can fill the unmatched data fix typo csvtk v0.3.5.1 fix minor bug of reading lines ending with \\r\\n from a dependency package csvtk v0.3.5 fix minor bug of csv2md add subcommand version which could check for update csvtk v0.3.4 fix bug of csvtk replace that head row should not be edited. csvtk v0.3.3 fix bug of csvtk grep -t -P csvtk v0.3.2 fix bug of inter csvtk v0.3.1 add support of search multiple fields for grep csvtk v0.3 add subcommand csv2md csvtk v0.2.9 add more flags to subcommand pretty fix bug of csvtk cut -n add subcommand filter csvtk v0.2.8 add subcommand pretty -- convert CSV to readable aligned table csvtk v0.2.7 fix highlight failing in windows csvtk v0.2.6 fix one error message of grep highlight matched fields in result of grep csvtk v0.2.5 fix bug of stat that failed to considerate files with header row add subcommand stat2 - summary of selected number fields make the output of stat prettier csvtk v0.2.4 fix bug of handling comment lines add some notes before using csvtk csvtk v0.2.3 add flag --colnames to cut flag -f ( --fields ) of join supports single value now csvtk v0.2.2 add flag --keep-unmathed to join csvtk v0.2 finish almost functions csvtk v0.2.1 fix bug of mutate /** * RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS. * LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables */ /* var disqus_config = function () { this.page.url = PAGE_URL; // Replace PAGE_URL with your page's canonical URL variable this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable }; */ (function() { // DON'T EDIT BELOW THIS LINE var d = document, s = d.createElement('script'); s.src = '//csvtk.disqus.com/embed.js'; s.setAttribute('data-timestamp', +new Date()); (d.head || d.body).appendChild(s); })(); Please enable JavaScript to view the comments powered by Disqus.","title":"Previous Versions"},{"location":"tutorial/","text":"Tutorial Analyzing OTU table Data Here is a mock OTU table from 16S rRNA sequencing result. Columns are sample IDs in format of \"GROUP.ID\" $ cat otu_table.csv Taxonomy,A.1,A.2,A.3,B.1,B.2,B.3,C.1,C.2 Proteobacteria,.13,.29,.13,.16,.13,.22,.30,.23 Firmicutes,.42,.06,.49,.41,.55,.41,.32,.38 Bacteroidetes,.19,.62,.12,.33,.16,.29,.34,.35 Deferribacteres,.17,.00,.24,.01,.01,.01,.01,.01 What a mess! Let's make it prettier! $ csvtk pretty otu_table.csv Taxonomy A.1 A.2 A.3 B.1 B.2 B.3 C.1 C.2 Proteobacteria .13 .29 .13 .16 .13 .22 .30 .23 Firmicutes .42 .06 .49 .41 .55 .41 .32 .38 Bacteroidetes .19 .62 .12 .33 .16 .29 .34 .35 Deferribacteres .17 .00 .24 .01 .01 .01 .01 .01 Steps Counting $ csvtk stat otu_table.csv file num_cols num_rows otu_table.csv 9 4 Column names $ csvtk headers otu_table.csv # otu_table.csv 1 Taxonomy 2 A.1 3 A.2 4 A.3 5 B.1 6 B.2 7 B.3 8 C.1 9 C.2 Convert to tab-delimited table $ csvtk csv2tab otu_table.csv Taxonomy A.1 A.2 A.3 B.1 B.2 B.3 C.1 C.2 Proteobacteria .13 .29 .13 .16 .13 .22 .30 .23 Firmicutes .42 .06 .49 .41 .55 .41 .32 .38 Bacteroidetes .19 .62 .12 .33 .16 .29 .34 .35 Deferribacteres .17 .00 .24 .01 .01 .01 .01 .01 Extract data of group A and B and save to file -o otu_table.gAB.csv $ csvtk cut -F -f \"Taxonomy,A.*,B.*\" otu_table.csv -o otu_table.gAB.csv $ csvtk pretty otu_table.gAB.csv Taxonomy A.1 A.2 A.3 B.1 B.2 B.3 Proteobacteria .13 .29 .13 .16 .13 .22 Firmicutes .42 .06 .49 .41 .55 .41 Bacteroidetes .19 .62 .12 .33 .16 .29 Deferribacteres .17 .00 .24 .01 .01 .01 Search some rows by fields. Matched parts will be highlighted as red $ csvtk grep -f Taxonomy -r -p \"tes\" otu_table.gAB.csv -T Result: Transpose $ csvtk transpose otu_table.gAB.csv -o otu_table.gAB.t.csv $ csvtk pretty otu_table.gAB.t.csv Taxonomy Proteobacteria Firmicutes Bacteroidetes Deferribacteres A.1 .13 .42 .19 .17 A.2 .29 .06 .62 .00 A.3 .13 .49 .12 .24 B.1 .16 .41 .33 .01 B.2 .13 .55 .16 .01 B.3 .22 .41 .29 .01 Rename name of the first column $ csvtk rename -f 1 -n \"sample\" otu_table.gAB.t.csv -o otu_table.gAB.t.r.csv $ csvtk pretty otu_table.gAB.t.r.csv sample Proteobacteria Firmicutes Bacteroidetes Deferribacteres A.1 .13 .42 .19 .17 A.2 .29 .06 .62 .00 A.3 .13 .49 .12 .24 B.1 .16 .41 .33 .01 B.2 .13 .55 .16 .01 B.3 .22 .41 .29 .01 Add group column $ csvtk mutate -p \"(.+?)\\.\" -n group otu_table.gAB.t.r.csv -o otu_table2.csv $ csvtk pretty otu_table2.csv sample Proteobacteria Firmicutes Bacteroidetes Deferribacteres group A.1 .13 .42 .19 .17 A A.2 .29 .06 .62 .00 A A.3 .13 .49 .12 .24 A B.1 .16 .41 .33 .01 B B.2 .13 .55 .16 .01 B B.3 .22 .41 .29 .01 B Rename groups: $ csvtk replace -f group -p \"A\" -r \"Ctrl\" otu_table2.csv \\ | csvtk replace -f group -p \"B\" -r \"Treatment\" \\ > otu_table3.csv $ csvtk pretty -s \" \" otu_table3.csv sample Proteobacteria Firmicutes Bacteroidetes Deferribacteres group A.1 .13 .42 .19 .17 Ctrl A.2 .29 .06 .62 .00 Ctrl A.3 .13 .49 .12 .24 Ctrl B.1 .16 .41 .33 .01 Treatment B.2 .13 .55 .16 .01 Treatment B.3 .22 .41 .29 .01 Treatment Sort by abundance of Proteobacteria in descending order. $ csvtk sort -k Proteobacteria:nr otu_table3.csv \\ | csvtk pretty -s \" \" sample Proteobacteria Firmicutes Bacteroidetes Deferribacteres group A.2 .29 .06 .62 .00 Ctrl B.3 .22 .41 .29 .01 Treatment B.1 .16 .41 .33 .01 Treatment B.2 .13 .55 .16 .01 Treatment A.3 .13 .49 .12 .24 Ctrl A.1 .13 .42 .19 .17 Ctrl Sort by abundance of Proteobacteria in descending order and Firmicutes in ascending order $ csvtk sort -k Proteobacteria:nr -k Firmicutes:n otu_table3.csv \\ | csvtk pretty -s \" \" sample Proteobacteria Firmicutes Bacteroidetes Deferribacteres group A.2 .29 .06 .62 .00 Ctrl B.3 .22 .41 .29 .01 Treatment B.1 .16 .41 .33 .01 Treatment A.1 .13 .42 .19 .17 Ctrl A.3 .13 .49 .12 .24 Ctrl B.2 .13 .55 .16 .01 Treatment Filter samples with abundance greater than 0 in all taxons (columns except for sample and group, you can also use -f \"2-5>0\" ). $ cat otu_table3.csv \\ | csvtk filter -f \"2-5>0\" \\ | csvtk pretty -s \" \" sample Proteobacteria Firmicutes Bacteroidetes Deferribacteres group A.1 .13 .42 .19 .17 Ctrl A.3 .13 .49 .12 .24 Ctrl B.1 .16 .41 .33 .01 Treatment B.2 .13 .55 .16 .01 Treatment B.3 .22 .41 .29 .01 Treatment Most of the time, we may want to remove samples with abundance of 0 in all taxons. $ cat otu_table3.csv \\ | csvtk filter -f \"2-5>0\" --any \\ | csvtk pretty -s \" \" sample Proteobacteria Firmicutes Bacteroidetes Deferribacteres group A.1 .13 .42 .19 .17 Ctrl A.2 .29 .06 .62 .00 Ctrl A.3 .13 .49 .12 .24 Ctrl B.1 .16 .41 .33 .01 Treatment B.2 .13 .55 .16 .01 Treatment B.3 .22 .41 .29 .01 Treatment /** * RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS. * LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables */ /* var disqus_config = function () { this.page.url = PAGE_URL; // Replace PAGE_URL with your page's canonical URL variable this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable }; */ (function() { // DON'T EDIT BELOW THIS LINE var d = document, s = d.createElement('script'); s.src = '//csvtk.disqus.com/embed.js'; s.setAttribute('data-timestamp', +new Date()); (d.head || d.body).appendChild(s); })(); Please enable JavaScript to view the comments powered by Disqus.","title":"Tutorial"},{"location":"tutorial/#tutorial","text":"","title":"Tutorial"},{"location":"tutorial/#analyzing-otu-table","text":"","title":"Analyzing OTU table"},{"location":"tutorial/#data","text":"Here is a mock OTU table from 16S rRNA sequencing result. Columns are sample IDs in format of \"GROUP.ID\" $ cat otu_table.csv Taxonomy,A.1,A.2,A.3,B.1,B.2,B.3,C.1,C.2 Proteobacteria,.13,.29,.13,.16,.13,.22,.30,.23 Firmicutes,.42,.06,.49,.41,.55,.41,.32,.38 Bacteroidetes,.19,.62,.12,.33,.16,.29,.34,.35 Deferribacteres,.17,.00,.24,.01,.01,.01,.01,.01 What a mess! Let's make it prettier! $ csvtk pretty otu_table.csv Taxonomy A.1 A.2 A.3 B.1 B.2 B.3 C.1 C.2 Proteobacteria .13 .29 .13 .16 .13 .22 .30 .23 Firmicutes .42 .06 .49 .41 .55 .41 .32 .38 Bacteroidetes .19 .62 .12 .33 .16 .29 .34 .35 Deferribacteres .17 .00 .24 .01 .01 .01 .01 .01","title":"Data"},{"location":"tutorial/#steps","text":"Counting $ csvtk stat otu_table.csv file num_cols num_rows otu_table.csv 9 4 Column names $ csvtk headers otu_table.csv # otu_table.csv 1 Taxonomy 2 A.1 3 A.2 4 A.3 5 B.1 6 B.2 7 B.3 8 C.1 9 C.2 Convert to tab-delimited table $ csvtk csv2tab otu_table.csv Taxonomy A.1 A.2 A.3 B.1 B.2 B.3 C.1 C.2 Proteobacteria .13 .29 .13 .16 .13 .22 .30 .23 Firmicutes .42 .06 .49 .41 .55 .41 .32 .38 Bacteroidetes .19 .62 .12 .33 .16 .29 .34 .35 Deferribacteres .17 .00 .24 .01 .01 .01 .01 .01 Extract data of group A and B and save to file -o otu_table.gAB.csv $ csvtk cut -F -f \"Taxonomy,A.*,B.*\" otu_table.csv -o otu_table.gAB.csv $ csvtk pretty otu_table.gAB.csv Taxonomy A.1 A.2 A.3 B.1 B.2 B.3 Proteobacteria .13 .29 .13 .16 .13 .22 Firmicutes .42 .06 .49 .41 .55 .41 Bacteroidetes .19 .62 .12 .33 .16 .29 Deferribacteres .17 .00 .24 .01 .01 .01 Search some rows by fields. Matched parts will be highlighted as red $ csvtk grep -f Taxonomy -r -p \"tes\" otu_table.gAB.csv -T Result: Transpose $ csvtk transpose otu_table.gAB.csv -o otu_table.gAB.t.csv $ csvtk pretty otu_table.gAB.t.csv Taxonomy Proteobacteria Firmicutes Bacteroidetes Deferribacteres A.1 .13 .42 .19 .17 A.2 .29 .06 .62 .00 A.3 .13 .49 .12 .24 B.1 .16 .41 .33 .01 B.2 .13 .55 .16 .01 B.3 .22 .41 .29 .01 Rename name of the first column $ csvtk rename -f 1 -n \"sample\" otu_table.gAB.t.csv -o otu_table.gAB.t.r.csv $ csvtk pretty otu_table.gAB.t.r.csv sample Proteobacteria Firmicutes Bacteroidetes Deferribacteres A.1 .13 .42 .19 .17 A.2 .29 .06 .62 .00 A.3 .13 .49 .12 .24 B.1 .16 .41 .33 .01 B.2 .13 .55 .16 .01 B.3 .22 .41 .29 .01 Add group column $ csvtk mutate -p \"(.+?)\\.\" -n group otu_table.gAB.t.r.csv -o otu_table2.csv $ csvtk pretty otu_table2.csv sample Proteobacteria Firmicutes Bacteroidetes Deferribacteres group A.1 .13 .42 .19 .17 A A.2 .29 .06 .62 .00 A A.3 .13 .49 .12 .24 A B.1 .16 .41 .33 .01 B B.2 .13 .55 .16 .01 B B.3 .22 .41 .29 .01 B Rename groups: $ csvtk replace -f group -p \"A\" -r \"Ctrl\" otu_table2.csv \\ | csvtk replace -f group -p \"B\" -r \"Treatment\" \\ > otu_table3.csv $ csvtk pretty -s \" \" otu_table3.csv sample Proteobacteria Firmicutes Bacteroidetes Deferribacteres group A.1 .13 .42 .19 .17 Ctrl A.2 .29 .06 .62 .00 Ctrl A.3 .13 .49 .12 .24 Ctrl B.1 .16 .41 .33 .01 Treatment B.2 .13 .55 .16 .01 Treatment B.3 .22 .41 .29 .01 Treatment Sort by abundance of Proteobacteria in descending order. $ csvtk sort -k Proteobacteria:nr otu_table3.csv \\ | csvtk pretty -s \" \" sample Proteobacteria Firmicutes Bacteroidetes Deferribacteres group A.2 .29 .06 .62 .00 Ctrl B.3 .22 .41 .29 .01 Treatment B.1 .16 .41 .33 .01 Treatment B.2 .13 .55 .16 .01 Treatment A.3 .13 .49 .12 .24 Ctrl A.1 .13 .42 .19 .17 Ctrl Sort by abundance of Proteobacteria in descending order and Firmicutes in ascending order $ csvtk sort -k Proteobacteria:nr -k Firmicutes:n otu_table3.csv \\ | csvtk pretty -s \" \" sample Proteobacteria Firmicutes Bacteroidetes Deferribacteres group A.2 .29 .06 .62 .00 Ctrl B.3 .22 .41 .29 .01 Treatment B.1 .16 .41 .33 .01 Treatment A.1 .13 .42 .19 .17 Ctrl A.3 .13 .49 .12 .24 Ctrl B.2 .13 .55 .16 .01 Treatment Filter samples with abundance greater than 0 in all taxons (columns except for sample and group, you can also use -f \"2-5>0\" ). $ cat otu_table3.csv \\ | csvtk filter -f \"2-5>0\" \\ | csvtk pretty -s \" \" sample Proteobacteria Firmicutes Bacteroidetes Deferribacteres group A.1 .13 .42 .19 .17 Ctrl A.3 .13 .49 .12 .24 Ctrl B.1 .16 .41 .33 .01 Treatment B.2 .13 .55 .16 .01 Treatment B.3 .22 .41 .29 .01 Treatment Most of the time, we may want to remove samples with abundance of 0 in all taxons. $ cat otu_table3.csv \\ | csvtk filter -f \"2-5>0\" --any \\ | csvtk pretty -s \" \" sample Proteobacteria Firmicutes Bacteroidetes Deferribacteres group A.1 .13 .42 .19 .17 Ctrl A.2 .29 .06 .62 .00 Ctrl A.3 .13 .49 .12 .24 Ctrl B.1 .16 .41 .33 .01 Treatment B.2 .13 .55 .16 .01 Treatment B.3 .22 .41 .29 .01 Treatment /** * RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS. * LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables */ /* var disqus_config = function () { this.page.url = PAGE_URL; // Replace PAGE_URL with your page's canonical URL variable this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable }; */ (function() { // DON'T EDIT BELOW THIS LINE var d = document, s = d.createElement('script'); s.src = '//csvtk.disqus.com/embed.js'; s.setAttribute('data-timestamp', +new Date()); (d.head || d.body).appendChild(s); })(); Please enable JavaScript to view the comments powered by Disqus.","title":"Steps"},{"location":"usage/","text":"Usage and Examples Before use Attention The CSV parser requires all the lines have same number of fields/columns. Even lines with spaces will cause error. Use '-I/--ignore-illegal-row' to skip these lines if neccessary. By default, csvtk thinks your files have header row, if not, switch flag -H on. Column names better be unique. By default, lines starting with # will be ignored, if the header row starts with # , please assign flag -C another rare symbol, e.g. '$' . By default, csvtk handles CSV files, use flag -t for tab-delimited files. If \" exists in tab-delimited files, use flag -l . Do not mix use digital fields and column names. Table of Contents csvtk Information headers dim summary corr watch Format conversion pretty transpose csv2md csv2json xlsx2csv Set operations head concat sample cut grep uniq freq inter filter filter2 join split splitxlsx collapse Edit add-header del-header rename rename2 replace mutate mutate2 gather Ordering sort Ploting plot plot hist plot box plot line Misc cat genautocomplete csvtk Usage csvtk -- a cross-platform, efficient and practical CSV/TSV toolkit Version: 0.19.1 Author: Wei Shen <shenwei356@gmail.com> Documents : http://shenwei356.github.io/csvtk Source code: https://github.com/shenwei356/csvtk Attention: 1. The CSV parser requires all the lines have same number of fields/columns. Even lines with spaces will cause error. Use '-I/--ignore-illegal-row' to skip these lines if neccessary. 2. By default, csvtk thinks your files have header row, if not, switch flag \"-H\" on. 3. Column names better be unique. 4. By default, lines starting with \"#\" will be ignored, if the header row starts with \"#\", please assign flag \"-C\" another rare symbol, e.g. '$'. 5. By default, csvtk handles CSV files, use flag \"-t\" for tab-delimited files. 6. If \" exists in tab-delimited files, use flag \"-l\". 7. Do not mix use digital fields and column names. Environment variables for frequently used global flags - \"CSVTK_T\" for flag \"-t/--tabs\" - \"CSVTK_H\" for flag \"-H/--no-header-row\" Usage: csvtk [command] Available Commands: add-header add column names cat stream file to stdout and report progress on stderr collapse collapse one field with selected fields as keys concat concatenate CSV/TSV files by rows corr calculate Pearson correlation between two columns csv2json convert CSV to JSON format csv2md convert CSV to markdown format csv2tab convert CSV to tabular format cut select parts of fields del-header delete column names dim dimensions of CSV file filter filter rows by values of selected fields with arithmetic expression filter2 filter rows by awk-like artithmetic/string expressions freq frequencies of selected fields gather gather columns into key-value pairs genautocomplete generate shell autocompletion script grep grep data by selected fields with patterns/regular expressions head print first N records headers print headers help Help about any command inter intersection of multiple files join join multiple CSV files by selected fields mutate create new column from selected fields by regular expression mutate2 create new column from selected fields by awk-like artithmetic/string expressions plot plot common figures pretty convert CSV to readable aligned table rename rename column names rename2 rename column names by regular expression replace replace data of selected fields by regular expression sample sampling by proportion sort sort by selected fields space2tab convert space delimited format to CSV split split CSV/TSV into multiple files according to column values splitxlsx split XLSX sheet into multiple sheets according to column values summary summary statistics of selected digital fields (groupby group fields) tab2csv convert tabular format to CSV transpose transpose CSV data uniq unique data without sorting version print version information and check for update watch monitor the specified fields xlsx2csv convert XLSX to CSV format Flags: -c, --chunk-size int chunk size of CSV reader (default 50) -C, --comment-char string lines starting with commment-character will be ignored. if your header row starts with '#', please assign \"-C\" another rare symbol, e.g. '$' (default \"#\") -d, --delimiter string delimiting character of the input CSV file (default \",\") -h, --help help for csvtk -E, --ignore-empty-row ignore empty rows -I, --ignore-illegal-row ignore illegal rows -l, --lazy-quotes if given, a quote may appear in an unquoted field and a non-doubled quote may appear in a quoted field -H, --no-header-row specifies that the input CSV file does not have header row -j, --num-cpus int number of CPUs to use (default value depends on your computer) (default 16) -D, --out-delimiter string delimiting character of the output CSV file, e.g., -D $'\\t' for tab (default \",\") -o, --out-file string out file (\"-\" for stdout, suffix .gz for gzipped out) (default \"-\") -T, --out-tabs specifies that the output is delimited with tabs. Overrides \"-D\" -t, --tabs specifies that the input CSV file is delimited with tabs. Overrides \"-d\" and \"-D\" headers Usage print headers Usage: csvtk headers [flags] Examples $ csvtk headers testdata/*.csv # testdata/1.csv 1 name 2 attr # testdata/2.csv 1 name 2 major # testdata/3.csv 1 id 2 name 3 hobby dim Usage dimensions of CSV file Usage: csvtk dim [flags] Aliases: dim, size, stats, stat Flags: -h, --help help for dim Examples with header row $ cat testdata/names.csv id,first_name,last_name,username 11,\"Rob\",\"Pike\",rob 2,Ken,Thompson,ken 4,\"Robert\",\"Griesemer\",\"gri\" 1,\"Robert\",\"Thompson\",\"abc\" NA,\"Robert\",\"Abel\",\"123\" $ cat testdata/names.csv | csvtk size file num_cols num_rows - 4 5 no header row $ cat testdata/digitals.tsv 4 5 6 1 2 3 7 8 0 8 1,000 4 $ cat testdata/digitals.tsv \\ | csvtk size -t -H file num_cols num_rows - 3 4 summary Usage summary statistics of selected digital fields (groupby group fields) Attention: 1. Do not mix use digital fields and column names. Available operations: # numeric/statistical operations # provided by github.com/gonum/stat and github.com/gonum/floats countn (count of digits), min, max, sum, mean, stdev, variance, median, q1, q2, q3, entropy (Shannon entropy), prod (product of the elements) # textual/numeric operations count, first, last, rand, unique, collapse, countunique Usage: csvtk summary [flags] Flags: -n, --decimal-width int limit floats to N decimal points (default 2) -f, --fields strings operations on these fields. e.g -f 1:count,1:sum or -f colA:mean. available operations: collapse, count, countn, countunique, entropy, first, last, max, mean, median, min, prod, q1, q2, q3, rand, stdev, sum, uniq, variance -g, --groups string group via fields. e.g -f 1,2 or -f columnA,columnB -h, --help help for summary -i, --ignore-non-digits ignore non-digital values like \"NA\" or \"N/A\" -S, --rand-seed int rand seed for operation \"rand\" (default 11) -s, --separater string separater for collapsed data (default \"; \") Examples data $ cat testdata/digitals2.csv f1,f2,f3,f4,f5 foo,bar,xyz,1,0 foo,bar2,xyz,1.5,-1 foo,bar2,xyz,3,2 foo,bar,xyz,5,3 foo,bar2,xyz,N/A,4 bar,xyz,abc,NA,2 bar,xyz,abc2,1,-1 bar,xyz,abc,2,0 bar,xyz,abc,1,5 bar,xyz,abc,3,100 bar,xyz2,abc3,2,3 bar,xyz2,abc3,2,1 use flag -i/--ignore-non-digits $ cat testdata/digitals2.csv \\ | csvtk summary -f f4:sum [ERRO] column 4 has non-digital data: N/A, you can use flag -i/--ignore-non-digits to skip these data $ cat testdata/digitals2.csv \\ | csvtk summary -f f4:sum -i f4:sum 21.50 multiple fields suported $ cat testdata/digitals2.csv \\ | csvtk summary -f f4:sum,f5:sum -i f4:sum,f5:sum 21.50,118.00 using fields instead of colname is still supported $ cat testdata/digitals2.csv \\ | csvtk summary -f 4:sum,5:sum -i f4:sum,f5:sum 21.50,118.00 but remember not mixing use digital fields and column names $ cat testdata/digitals2.csv \\ | csvtk summary -f f4:sum,5:sum -i [ERRO] column \"5\" not existed in file: - $ cat testdata/digitals2.csv \\ | csvtk summary -f 4:sum,f5:sum -i [ERRO] fail to parse digital field: f5, you may mix use digital fields and column names groupby $ cat testdata/digitals2.csv \\ | csvtk summary -i -f f4:sum,f5:sum -g f1,f2 \\ | csvtk pretty f1 f2 f4:sum f5:sum bar xyz 7.00 106.00 bar xyz2 4.00 4.00 foo bar 6.00 3.00 foo bar2 4.50 5.00 for data without header line $ cat testdata/digitals2.csv | sed 1d \\ | csvtk summary -H -i -f 4:sum,5:sum -g 1,2 \\ | csvtk pretty bar xyz 7.00 106.00 bar xyz2 4.00 4.00 foo bar 6.00 3.00 foo bar2 4.50 5.00 numeric/statistical operations $ cat testdata/digitals2.csv \\ | csvtk summary -i -g f1 -f f4:countn,f4:mean,f4:stdev,f4:q1,f4:q2,f4:mean,f4:q3,f4:min,f4:max \\ | csvtk pretty f1 f4:countn f4:mean f4:stdev f4:q1 f4:q2 f4:mean f4:q3 f4:min f4:max bar 6.00 1.83 0.75 1.00 2.00 1.83 2.00 1.00 3.00 foo 4.00 2.62 1.80 1.25 2.25 2.62 4.00 1.00 5.00 textual/numeric operations $ cat testdata/digitals2.csv \\ | csvtk summary -i -g f1 -f f2:count,f2:first,f2:last,f2:rand,f2:collapse,f2:uniq,f2:countunique \\ | csvtk pretty f1 f2:count f2:first f2:last f2:rand f2:collapse f2:uniq f2:countunique bar 7 xyz xyz2 xyz2 xyz; xyz; xyz; xyz; xyz; xyz2; xyz2 xyz2; xyz 2 foo 5 bar bar2 bar2 bar; bar2; bar2; bar; bar2 bar; bar2 2 mixed operations $ cat testdata/digitals2.csv \\ | csvtk summary -i -g f1 -f f4:collapse,f4:max \\ | csvtk pretty f1 f4:collapse f4:max bar NA; 1; 2; 1; 3; 2; 2 3.00 foo 1; 1.5; 3; 5; N/A 5.00 count and countn (count of digits) $ cat testdata/digitals2.csv \\ | csvtk summary -f f4:count,f4:countn -i \\ | csvtk pretty f4:count f4:countn 12 10 # details: $ cat testdata/digitals2.csv \\ | csvtk summary -f f4:count,f4:countn,f4:collapse -i -g f1 \\ | csvtk pretty f1 f4:count f4:countn f4:collapse bar 7 6 NA; 1; 2; 1; 3; 2; 2 foo 5 4 1; 1.5; 3; 5; N/A watch Usage monitor the specified fields Usage: csvtk watch [flags] Flags: -B, --bins int number of histogram bins (default -1) -W, --delay int sleep this many seconds after plotting (default 1) -y, --dump print histogram data to stderr instead of plotting -f, --field string field to watch -h, --help help for watch -O, --image string save histogram to this PDF/image file -L, --log log10(x+1) transform numeric values -x, --pass passthrough mode (forward input to output) -p, --print-freq int print/report after this many records (-1 for print after EOF) (default -1) -Q, --quiet supress all plotting to stderr -R, --reset reset histogram after every report Examples Read whole file, plot histogram of field on the terminal and PDF csvtk -t watch -O hist.pdf -f MyField input.tsv Monitor a TSV stream, print histogram every 1000 records cat input.tsv | csvtk -t watch -f MyField -p 1000 - Monitor a TSV stream, print histogram every 1000 records, hang forever for updates tail -f +0 input.tsv | csvtk -t watch -f MyField -p 1000 - corr Usage calculate Pearson correlation between two columns Usage: csvtk corr [flags] Flags: -f, --fields string comma separated fields -h, --help help for corr -i, --ignore_nan Ignore non-numeric fields to avoid returning NaN -L, --log Calcute correlations on Log10 transformed data -x, --pass passthrough mode (forward input to output) Examples Calculate pairwise correlations between field, ignore non-numeric values csvtk -t corr -i -f 1,Foo,Bar input.tsv pretty Usage convert CSV to readable aligned table Attention: pretty treats the first row as header line and requires them to be unique Usage: csvtk pretty [flags] Flags: -r, --align-right align right -h, --help help for pretty -W, --max-width int max width -w, --min-width int min width -s, --separator string fields/columns separator (default \" \") Examples: default $ csvtk pretty testdata/names.csv id first_name last_name username 11 Rob Pike rob 2 Ken Thompson ken 4 Robert Griesemer gri 1 Robert Thompson abc NA Robert Abel 123 align right $ csvtk pretty testdata/names.csv -r id first_name last_name username 11 Rob Pike rob 2 Ken Thompson ken 4 Robert Griesemer gri 1 Robert Thompson abc NA Robert Abel 123 custom separator $ csvtk pretty testdata/names.csv -s \" | \" id | first_name | last_name | username 11 | Rob | Pike | rob 2 | Ken | Thompson | ken 4 | Robert | Griesemer | gri 1 | Robert | Thompson | abc NA | Robert | Abel | 123 transpose Usage transpose CSV data Usage: csvtk transpose [flags] Examples $ cat testdata/digitals.tsv 4 5 6 1 2 3 7 8 0 8 1,000 4 $ csvtk transpose -t testdata/digitals.tsv 4 1 7 8 5 2 8 1,000 6 3 0 4 csv2json Usage convert CSV to JSON format Usage: csvtk csv2json [flags] Flags: -h, --help help for csv2json -i, --indent string indent. if given blank, output json in one line. (default \" \") -k, --key string output json as an array of objects keyed by a given filed rather than as a list. e.g -k 1 or -k columnA Examples test data $ cat data.csv ID,room,name 3,G13,Simon 5,103,Anna default operation $ cat data.csv | csvtk csv2json [ { \"ID\": \"3\", \"room\": \"G13\", \"name\": \"Simon\" }, { \"ID\": \"5\", \"room\": \"103\", \"name\": \"Anna\" } ] change indent $ cat data.csv | csvtk csv2json -i \" \" [ { \"ID\": \"3\", \"room\": \"G13\", \"name\": \"Simon\" }, { \"ID\": \"5\", \"room\": \"103\", \"name\": \"Anna\" } ] change indent 2) $ cat data.csv | csvtk csv2json -i \"\" [{\"ID\":\"3\",\"room\":\"G13\",\"name\":\"Simon\"},{\"ID\":\"5\",\"room\":\"103\",\"name\":\"Anna\"}] output json as an array of objects keyed by a given filed rather than as a list. $ cat data.csv | csvtk csv2json -k ID { \"3\": { \"ID\": \"3\", \"room\": \"G13\", \"name\": \"Simon\" }, \"5\": { \"ID\": \"5\", \"room\": \"103\", \"name\": \"Anna\" } } for CSV without header row $ cat data.csv | csvtk csv2json -H [ [ \"ID\", \"room\", \"name\" ], [ \"3\", \"G13\", \"Simon\" ], [ \"5\", \"103\", \"Anna\" ] ] for CSV without header row 2) $ cat data.csv | csvtk csv2json -H -k 1 { \"ID\": [ \"ID\", \"room\", \"name\" ], \"3\": [ \"3\", \"G13\", \"Simon\" ], \"5\": [ \"5\", \"103\", \"Anna\" ] } csv2md Usage convert CSV to markdown format Attention: csv2md treats the first row as header line and requires them to be unique Usage: csvtk csv2md [flags] Flags: -a, --alignments string comma separated alignments. e.g. -a l,c,c,c or -a c (default \"l\") -w, --min-width int min width (at least 3) (default 3) Examples give single alignment symbol $ cat testdata/names.csv | csvtk csv2md -a left id |first_name|last_name|username :--|:---------|:--------|:------- 11 |Rob |Pike |rob 2 |Ken |Thompson |ken 4 |Robert |Griesemer|gri 1 |Robert |Thompson |abc NA |Robert |Abel |12 result: id first_name last_name username 11 Rob Pike rob 2 Ken Thompson ken 4 Robert Griesemer gri 1 Robert Thompson abc NA Robert Abel 12 give alignment symbols of all fields $ cat testdata/names.csv | csvtk csv2md -a c,l,l,l id |first_name|last_name|username :-:|:---------|:--------|:------- 11 |Rob |Pike |rob 2 |Ken |Thompson |ken 4 |Robert |Griesemer|gri 1 |Robert |Thompson |abc NA |Robert |Abel |123 result id first_name last_name username 11 Rob Pike rob 2 Ken Thompson ken 4 Robert Griesemer gri 1 Robert Thompson abc NA Robert Abel 123 xlsx2csv Usage convert XLSX to CSV format Usage: csvtk xlsx2csv [flags] Flags: -h, --help help for xlsx2csv -a, --list-sheets list all sheets -i, --sheet-index int Nth sheet to retrieve (default 1) -n, --sheet-name string sheet to retrieve Examples list all sheets $ csvtk xlsx2csv ../testdata/accounts.xlsx -a index sheet 1 names 2 phones 3 region retrieve sheet by index $ csvtk xlsx2csv ../testdata/accounts.xlsx -i 3 name,region ken,nowhere gri,somewhere shenwei,another Thompson,there retrieve sheet by name $ csvtk xlsx2sv ../testdata/accounts.xlsx -n region name,region ken,nowhere gri,somewhere shenwei,another Thompson,there head Usage print first N records Usage: csvtk head [flags] Flags: -n, --number int print first N records (default 10) Examples with header line $ csvtk head -n 2 testdata/1.csv name,attr foo,cool bar,handsome no header line $ csvtk head -H -n 2 testdata/1.csv name,attr foo,cool concat Usage concatenate CSV/TSV files by rows Note that the second and later files are concatenated to the first one, so only columns match that of the first files kept. Usage: csvtk concat [flags] Flags: -h, --help help for concat -i, --ignore-case ignore case (column name) -k, --keep-unmatched keep blanks even if no any data of a file matches -u, --unmatched-repl string replacement for unmatched data Examples data $ csvtk pretty names.csv id first_name last_name username 11 Rob Pike rob 2 Ken Thompson ken 4 Robert Griesemer gri 1 Robert Thompson abc NA Robert Abel 123 $ csvtk pretty names.reorder.csv last_name username id first_name Pike rob 11 Rob Thompson ken 2 Ken Griesemer gri 4 Robert Thompson abc 1 Robert Abel 123 NA Robert $ csvtk pretty names.with-unmatched-colname.csv id2 First_name Last_name Username col 22 Rob33 Pike222 rob111 abc 44 Ken33 Thompson22 ken111 def simple one $ csvtk concat names.csv names.reorder.csv \\ | csvtk pretty id first_name last_name username 11 Rob Pike rob 2 Ken Thompson ken 4 Robert Griesemer gri 1 Robert Thompson abc NA Robert Abel 123 11 Rob Pike rob 2 Ken Thompson ken 4 Robert Griesemer gri 1 Robert Thompson abc NA Robert Abel 123 data with unmatched column names, and ignoring cases $ csvtk concat names.csv names.with-unmatched-colname.csv -i \\ | csvtk pretty id first_name last_name username 11 Rob Pike rob 2 Ken Thompson ken 4 Robert Griesemer gri 1 Robert Thompson abc NA Robert Abel 123 Rob33 Pike222 rob111 Ken33 Thompson22 ken111 $ csvtk concat names.csv names.with-unmatched-colname.csv -i -u Unmached \\ | csvtk pretty id first_name last_name username 11 Rob Pike rob 2 Ken Thompson ken 4 Robert Griesemer gri 1 Robert Thompson abc NA Robert Abel 123 Unmached Rob33 Pike222 rob111 Unmached Ken33 Thompson22 ken111 Sometimes data of one file does not matche any column, they are discared by default. But you can keep them using flag -k/--keep-unmatched $ csvtk concat names.with-unmatched-colname.csv names.csv \\ | csvtk pretty id2 First_name Last_name Username col 22 Rob33 Pike222 rob111 abc 44 Ken33 Thompson22 ken111 def $ csvtk concat names.with-unmatched-colname.csv names.csv -u -k NA \\ | csvtk pretty id2 First_name Last_name Username col 22 Rob33 Pike222 rob111 abc 44 Ken33 Thompson22 ken111 def NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA sample Usage sampling by proportion Usage: csvtk sample [flags] Flags: -h, --help help for sample -n, --line-number print line number as the first column (\"n\") -p, --proportion float sample by proportion -s, --rand-seed int rand seed (default 11) Examples $ seq 100 | csvtk sample -H -p 0.5 | wc -l 46 $ seq 100 | csvtk sample -H -p 0.5 | wc -l 46 $ seq 100 | csvtk sample -H -p 0.1 | wc -l 10 $ seq 100 | csvtk sample -H -p 0.05 -n 50,50 52,52 65,65 cut Usage select parts of fields Usage: csvtk cut [flags] Flags: -f, --fields string select only these fields. e.g -f 1,2 or -f columnA,columnB, or -f -columnA for unselect columnA -F, --fuzzy-fields using fuzzy fields, e.g., -F -f \"*name\" or -F -f \"id123*\" -h, --help help for cut -i, --ignore-case ignore case (column name) Examples data: $ cat testdata/names.csv id,first_name,last_name,username 11,\"Rob\",\"Pike\",rob 2,Ken,Thompson,ken 4,\"Robert\",\"Griesemer\",\"gri\" 1,\"Robert\",\"Thompson\",\"abc\" NA,\"Robert\",\"Abel\",\"123\" Select columns by column index: csvtk cut -f 1,2 $ cat testdata/names.csv \\ | csvtk cut -f 1,2 id,first_name 11,Rob 2,Ken 4,Robert 1,Robert NA,Robert Select columns by column names: csvtk cut -f first_name,username $ cat testdata/names.csv \\ | csvtk cut -f first_name,username first_name,username Rob,rob Ken,ken Robert,gri Robert,abc Robert,123 Unselect : select 3+ columns: csvtk cut -f -1,-2 $ cat testdata/names.csv \\ | csvtk cut -f -1,-2 last_name,username Pike,rob Thompson,ken Griesemer,gri Thompson,abc Abel,123 select columns except first_name : csvtk cut -f -first_name $ cat testdata/names.csv \\ | csvtk cut -f -first_name id,last_name,username 11,Pike,rob 2,Thompson,ken 4,Griesemer,gri 1,Thompson,abc NA,Abel,123 Fuzzy fields using wildcard character, csvtk cut -F -f \"*_name,username\" $ cat testdata/names.csv \\ | csvtk cut -F -f \"*_name,username\" first_name,last_name,username Rob,Pike,rob Ken,Thompson,ken Robert,Griesemer,gri Robert,Thompson,abc Robert,Abel,123 All fields: csvtk cut -F -f \"*\" (only works when all colnames are unique) $ cat testdata/names.csv \\ | csvtk cut -F -f \"*\" id,first_name,last_name,username 11,Rob,Pike,rob 2,Ken,Thompson,ken 4,Robert,Griesemer,gri 1,Robert,Thompson,abc NA,Robert,Abel,123 Field ranges: csvtk cut -f 2-4 for column 2,3,4 $ cat testdata/names.csv \\ | csvtk cut -f 2-4 first_name,last_name,username Rob,Pike,rob Ken,Thompson,ken Robert,Griesemer,gri Robert,Thompson,abc Robert,Abel,123 csvtk cut -f -3--1 for discarding column 1,2,3 $ cat testdata/names.csv \\ | csvtk cut -f -3--1 username rob ken gri abc 123 uniq Usage unique data without sorting Usage: csvtk uniq [flags] Flags: -f, --fields string select only these fields. e.g -f 1,2 or -f columnA,columnB (default \"1\") -F, --fuzzy-fields using fuzzy fields, e.g., -F -f \"*name\" or -F -f \"id123*\" -i, --ignore-case ignore case Examples: data: $ cat testdata/names.csv id,first_name,last_name,username 11,\"Rob\",\"Pike\",rob 2,Ken,Thompson,ken 4,\"Robert\",\"Griesemer\",\"gri\" 1,\"Robert\",\"Thompson\",\"abc\" NA,\"Robert\",\"Abel\",\"123\" unique first_name (it removes rows with duplicated first_name) $ cat testdata/names.csv \\ | csvtk uniq -f first_name id,first_name,last_name,username 11,Rob,Pike,rob 2,Ken,Thompson,ken 4,Robert,Griesemer,gri unique first_name, a more common way $ cat testdata/names.csv \\ | csvtk cut -f first_name \\ | csvtk uniq -f 1 first_name Rob Ken Robert freq Usage frequencies of selected fields Usage: csvtk freq [flags] Flags: -f, --fields string select only these fields. e.g -f 1,2 or -f columnA,columnB (default \"1\") -F, --fuzzy-fields using fuzzy fields, e.g., -F -f \"*name\" or -F -f \"id123*\" -i, --ignore-case ignore case -r, --reverse reverse order while sorting -n, --sort-by-freq sort by frequency -k, --sort-by-key sort by key Examples one filed $ cat testdata/names.csv \\ | csvtk freq -f first_name | csvtk pretty first_name frequency Ken 1 Rob 1 Robert 3 sort by frequency. you can also use csvtk sort with more sorting options $ cat testdata/names.csv \\ | csvtk freq -f first_name -n -r \\ | csvtk pretty first_name frequency Robert 3 Ken 1 Rob 1 sorty by key $ cat testdata/names.csv \\ | csvtk freq -f first_name -k \\ | csvtk pretty first_name frequency Ken 1 Rob 1 Robert 3 multiple fields $ cat testdata/names.csv \\ | csvtk freq -f first_name,last_name \\ | csvtk pretty first_name last_name frequency Robert Abel 1 Ken Thompson 1 Rob Pike 1 Robert Thompson 1 Robert Griesemer 1 data without header row $ cat testdata/ testdata/digitals.tsv \\ | csvtk -t -H freq -f 1 8 1 1 1 4 1 7 1 inter Usage intersection of multiple files Attention: 1. fields in all files should be the same, if not, extracting to another file using \"csvtk cut\". Usage: csvtk inter [flags] Flags: -f, --fields string select only these fields. e.g -f 1,2 or -f columnA,columnB (default \"1\") -F, --fuzzy-fields using fuzzy fields, e.g., -F -f \"*name\" or -F -f \"id123*\" -i, --ignore-case ignore case Examples: $ cat testdata/phones.csv username,phone gri,11111 rob,12345 ken,22222 shenwei,999999 $ cat testdata/region.csv name,region ken,nowhere gri,somewhere shenwei,another Thompson,there $ csvtk inter testdata/phones.csv testdata/region.csv username gri ken shenwei grep Usage grep data by selected fields with patterns/regular expressions Usage: csvtk grep [flags] Flags: --delete-matched delete a pattern right after being matched, this keeps the firstly matched data and speedups when using regular expressions -f, --fields string comma separated key fields, column name or index. e.g. -f 1-3 or -f id,id2 or -F -f \"group*\" (default \"1\") -F, --fuzzy-fields using fuzzy fields, e.g., -F -f \"*name\" or -F -f \"id123*\" -h, --help help for grep -i, --ignore-case ignore case -v, --invert invert match -n, --line-number print line number as the first column (\"n\") -N, --no-highlight no highlight -p, --pattern strings query pattern (multiple values supported) -P, --pattern-file string pattern files (one pattern per line) -r, --use-regexp patterns are regular expression --verbose verbose output Examples Matched parts will be highlight . By exact keys $ cat testdata/names.csv \\ | csvtk grep -f last_name -p Pike -p Abel \\ | csvtk pretty id first_name last_name username 11 Rob Pike rob NA Robert Abel 123 # another form of multiple keys $ csvtk grep -f last_name -p Pike,Abel,Tom By regular expression: csvtk grep -f first_name -r -p Rob $ cat testdata/names.csv \\ | csvtk grep -f first_name -r -p Rob \\ | csvtk pretty id first_name last_name username 11 Rob Pike rob 4 Robert Griesemer gri 1 Robert Thompson abc NA Robert Abel 123 By pattern list $ csvtk grep -f first_name -P name_list.txt Remore rows containing any missing data (NA): $ csvtk grep -F -f \"*\" -r -p \"^$\" -v Show line number $ cat names.csv \\ | csvtk pretty id first_name last_name username 11 Rob Pike rob 2 Ken Thompson ken 4 Robert Griesemer gri 1 Robert Thompson abc NA Robert Abel 123 $ cat names.csv \\ | csvtk grep -f first_name -r -i -p rob -n \\ | csvtk pretty n id first_name last_name username 1 11 Rob Pike rob 3 4 Robert Griesemer gri 4 1 Robert Thompson abc 5 NA Robert Abel 123 filter Usage filter rows by values of selected fields with arithmetic expression Usage: csvtk filter [flags] Flags: --any print record if any of the field satisfy the condition -f, --filter string filter condition. e.g. -f \"age>12\" or -f \"1,3<=2\" or -F -f \"c*!=0\" -F, --fuzzy-fields using fuzzy fields, e.g., -F -f \"*name\" or -F -f \"id123*\" -h, --help help for filter -n, --line-number print line number as the first column (\"n\") Examples single field $ cat testdata/names.csv id,first_name,last_name,username 11,\"Rob\",\"Pike\",rob 2,Ken,Thompson,ken 4,\"Robert\",\"Griesemer\",\"gri\" 1,\"Robert\",\"Thompson\",\"abc\" NA,\"Robert\",\"Abel\",\"123\" $ cat testdata/names.csv \\ | csvtk filter -f \"id>0\" \\ | csvtk pretty id first_name last_name username 11 Rob Pike rob 2 Ken Thompson ken 4 Robert Griesemer gri 1 Robert Thompson abc multiple fields $ cat testdata/digitals.tsv 4 5 6 1 2 3 7 8 0 8 1,000 4 $ cat testdata/digitals.tsv \\ | csvtk -t -H filter -f \"1-3>0\" 4 5 6 1 2 3 8 1,000 4 using --any to print record if any of the field satisfy the condition $ cat testdata/digitals.tsv \\ | csvtk -t -H filter -f \"1-3>0\" --any 4 5 6 1 2 3 7 8 0 8 1,000 4 fuzzy fields $ cat testdata/names.csv \\ | csvtk filter -F -f \"i*!=0\" id,first_name,last_name,username 11,Rob,Pike,rob 2,Ken,Thompson,ken 4,Robert,Griesemer,gri 1,Robert,Thompson,abc filter2 Usage filter rows by awk-like artithmetic/string expressions The artithmetic/string expression is supported by: https://github.com/Knetic/govaluate Supported operators and types: Modifiers: + - / * & | ^ ** % >> << Comparators: > >= < <= == != =~ !~ Logical ops: || && Numeric constants, as 64-bit floating point (12345.678) String constants (single quotes: 'foobar') Date constants (single quotes) Boolean constants: true false Parenthesis to control order of evaluation ( ) Arrays (anything separated by , within parenthesis: (1, 2, 'foo')) Prefixes: ! - ~ Ternary conditional: ? : Null coalescence: ?? Usage: csvtk filter2 [flags] Flags: -f, --filter string awk-like filter condition. e.g. '$age>12' or '$1 > $3' or '$name==\"abc\"' or '$1 % 2 == 0' -h, --help help for filter2 -n, --line-number print line number as the first column (\"n\") Examples: filter rows with id greater than 3: $ cat testdata/names.csv id,first_name,last_name,username 11,\"Rob\",\"Pike\",rob 2,Ken,Thompson,ken 4,\"Robert\",\"Griesemer\",\"gri\" 1,\"Robert\",\"Thompson\",\"abc\" NA,\"Robert\",\"Abel\",\"123\" $ cat testdata/names.csv \\ | csvtk filter2 -f '$id > 3' id,first_name,last_name,username 11,Rob,Pike,rob 4,Robert,Griesemer,gri arithmetic and string expressions $ cat testdata/names.csv \\ | csvtk filter2 -f '$id > 3 || $username==\"ken\"' id,first_name,last_name,username 11,Rob,Pike,rob 2,Ken,Thompson,ken 4,Robert,Griesemer,gri More arithmetic expressions $ cat testdata/digitals.tsv 4 5 6 1 2 3 7 8 0 8 1,000 4 $ cat testdata/digitals.tsv \\ | csvtk filter2 -H -t -f '$1 > 2 && $2 % 2 == 0' 7 8 0 8 1,000 4 # comparison between fields and support $ cat testdata/digitals.tsv \\ | csvtk filter2 -H -t -f '$2 <= $3 || ( $1 / $2 > 0.5 )' 4 5 6 1 2 3 7 8 0 join Usage join 2nd and later files to the first file by selected fields. Multiple keys supported, but the orders are ignored. Usage: csvtk join [flags] Flags: -f, --fields string Semicolon separated key fields of all files, if given one, we think all the files have the same key columns. Fields of different files should be separated by \";\", e.g -f \"1;2\" or -f \"A,B;C,D\" or -f id (default \"1\") --fill string fill content for unmatched data -F, --fuzzy-fields using fuzzy fields, e.g., -F -f \"*name\" or -F -f \"id123*\" -i, --ignore-case ignore case -k, --keep-unmatched keep unmatched data of the first file Examples: data $ cat testdata/phones.csv username,phone gri,11111 rob,12345 ken,22222 shenwei,999999 $ cat testdata/region.csv name,region ken,nowhere gri,somewhere shenwei,another Thompson,there All files have same key column: csvtk join -f id file1.csv file2.csv $ csvtk join -f 1 testdata/phones.csv testdata/region.csv username,phone,region gri,11111,somewhere ken,22222,nowhere shenwei,999999,another keep unmatched $ csvtk join -f 1 testdata/phones.csv testdata/region.csv --keep-unmatched username,phone,region gri,11111,somewhere rob,12345, ken,22222,nowhere shenwei,999999,another keep unmatched and fill with something $ csvtk join -f 1 testdata/phones.csv testdata/region.csv --keep-unmatched --fill NA username,phone,region gri,11111,somewhere rob,12345,NA ken,22222,nowhere shenwei,999999,another Files have different key columns: csvtk join -f \"username;username;name\" testdata/names.csv phone.csv adress.csv -k . Note that fields are separated with ; not , . $ csvtk join -f \"username;name\" testdata/phones.csv testdata/region.csv username,phone,region gri,11111,somewhere ken,22222,nowhere shenwei,999999,another The 2nd or later files have entries with same ID: $ cat testdata/1.csv name,attr foo,cool bar,handsome bob,beutiful $ cat testdata/2.csv name,major bar,bioinformatics bob,microbiology bob,computer science $ cat testdata/3.csv id,name,hobby 1,bar,baseball 2,bob,basketball 3,foo,football 4,wei,programming $ csvtk join testdata/1.csv testdata/2.csv \\ | csvtk pretty name attr major bar handsome bioinformatics bob beutiful microbiology bob beutiful computer science $ csvtk join testdata/{1,2,3}.csv -f name -k \\ | csvtk pretty name attr major id hobby foo cool 3 football bar handsome bioinformatics 1 baseball bob beutiful microbiology 2 basketball bob beutiful computer science 2 basketball $ csvtk join testdata/{3,1,2}.csv -f name -k \\ | csvtk pretty id name hobby attr major 1 bar baseball handsome bioinformatics 2 bob basketball beutiful computer science 2 bob basketball beutiful computer science 3 foo football cool 4 wei programming split Usage split CSV/TSV into multiple files according to column values Note: 1. flag -o/--out-file can specify out directory for splitted files Usage: csvtk split [flags] Flags: -g, --buf-groups int buffering N groups before writing to file (default 100) -b, --buf-rows int buffering N rows for every group before writing to file (default 100000) -f, --fields string comma separated key fields, column name or index. e.g. -f 1-3 or -f id,id2 or -F -f \"group*\" (default \"1\") -F, --fuzzy-fields using fuzzy fields, e.g., -F -f \"*name\" or -F -f \"id123*\" -h, --help help for split -i, --ignore-case ignore case -G, --out-gzip force output gzipped file Examples Test data $ cat names.csv id,first_name,last_name,username 11,\"Rob\",\"Pike\",rob 2,Ken,Thompson,ken 4,\"Robert\",\"Griesemer\",\"gri\" 1,\"Robert\",\"Thompson\",\"abc\" NA,\"Robert\",\"Abel\",\"123\" split according to first_name $ csvtk split names.csv -f first_name $ ls *.csv names.csv names-Ken.csv names-Rob.csv names-Robert.csv $ cat names-Ken.csv id,first_name,last_name,username 2,Ken,Thompson,ken $ cat names-Rob.csv id,first_name,last_name,username 11,Rob,Pike,rob $ cat names-Robert.csv id,first_name,last_name,username 4,Robert,Griesemer,gri 1,Robert,Thompson,abc NA,Robert,Abel,123 split according to first_name and last_name $ csvtk split names.csv -f first_name,last_name $ ls *.csv names.csv names-Robert-Abel.csv names-Robert-Thompson.csv names-Ken-Thompson.csv names-Robert-Griesemer.csv names-Rob-Pike.csv flag -o/--out-file can specify out directory for splitted files $ seq 10000 | csvtk split -H -o result $ ls result/*.csv | wc -l 10000 extreme example 1: lots (1M) of rows in groups $ yes 2 | head -n 10000000 | gzip -c > t.gz $ memusg -t csvtk -H split t.gz elapsed time: 7.959s peak rss: 35.7 MB # check $ zcat t-2.gz | wc -l 10000000 $ zcat t-2.gz | md5sum f194afd7cecf645c0e3cce50c9bc526e - $ zcat t.gz | md5sum f194afd7cecf645c0e3cce50c9bc526e - extreme example 2: lots (10K) of groups $ seq 10000 | gzip -c > t2.gz $ memusg -t csvtk -H split t2.gz -o t2 elapsed time: 20.856s peak rss: 23.77 MB # check $ ls t2/*.gz | wc -l 10000 $ zcat t2/*.gz | sort -k 1,1n | md5sum 72d4ff27a28afbc066d5804999d5a504 - $ zcat t2.gz | md5sum 72d4ff27a28afbc066d5804999d5a504 - splitxlsx Usage split XLSX sheet into multiple sheets according to column values Strengths: Sheet properties are remained unchanged. Weakness : Complicated sheet structures are not well supported, e.g., 1. merged cells 2. more than one header row Usage: csvtk splitxlsx [flags] Flags: -f, --fields string comma separated key fields, column name or index. e.g. -f 1-3 or -f id,id2 or -F -f \"group*\" (default \"1\") -F, --fuzzy-fields using fuzzy fields, e.g., -F -f \"*name\" or -F -f \"id123*\" -h, --help help for splitxlsx -i, --ignore-case ignore case (cell value) -a, --list-sheets list all sheets -N, --sheet-index int Nth sheet to retrieve (default 1) -n, --sheet-name string sheet to retrieve Examples example data # list all sheets $ csvtk xlsx2csv -a accounts.xlsx index sheet 1 names 2 phones 3 region # data of sheet \"names\" $ csvtk xlsx2csv accounts.xlsx | csvtk pretty id first_name last_name username 11 Rob Pike rob 2 Ken Thompson ken 4 Robert Griesemer gri 1 Robert Thompson abc NA Robert Abel 123 split sheet \"names\" according to first_name $ csvtk splitxlsx accounts.xlsx -n names -f first_name $ ls accounts.* accounts.split.xlsx accounts.xlsx $ csvtk splitxlsx -a accounts.split.xlsx index sheet 1 names 2 phones 3 region 4 Rob 5 Ken 6 Robert $ csvtk xlsx2csv accounts.split.xlsx -n Rob \\ | csvtk pretty id first_name last_name username 11 Rob Pike rob $ csvtk xlsx2csv accounts.split.xlsx -n Robert \\ | csvtk pretty id first_name last_name username 4 Robert Griesemer gri 1 Robert Thompson abc NA Robert Abel 123 collapse Usage collapse one field with selected fields as keys Usage: csvtk collapse [flags] Flags: -f, --fields string key fields. e.g -f 1,2 or -f columnA,columnB (default \"1\") -F, --fuzzy-fields using fuzzy fields (only for key fields), e.g., -F -f \"*name\" or -F -f \"id123*\" -h, --help help for collapse -i, --ignore-case ignore case -s, --separater string separater for collapsed data (default \"; \") -v, --vfield string value field examples data $ csvtk pretty teachers.csv lab teacher class computational biology Tom Bioinformatics computational biology Tom Statistics computational biology Rob Bioinformatics sequencing center Jerry Bioinformatics sequencing center Nick Molecular Biology sequencing center Nick Microbiology List teachers for every lab/class. uniq is used to deduplicate items. $ cat teachers.csv \\ | csvtk uniq -f lab,teacher \\ | csvtk collapse -f lab -v teacher \\ | csvtk pretty lab teacher computational biology Tom; Rob sequencing center Jerry; Nick $ cat teachers.csv \\ | csvtk uniq -f class,teacher \\ | csvtk collapse -f class -v teacher -s \", \" \\ | csvtk pretty class teacher Statistics Tom Bioinformatics Tom, Rob, Jerry Molecular Biology Nick Microbiology Nick Multiple key fields supported $ cat teachers.csv \\ | csvtk collapse -f teacher,lab -v class \\ | csvtk pretty teacher lab class Tom computational biology Bioinformatics; Statistics Rob computational biology Bioinformatics Jerry sequencing center Bioinformatics Nick sequencing center Molecular Biology; Microbiology add-header Usage add column names Usage: csvtk add-header [flags] Flags: -h, --help help for add-header -n, --names strings column names to add, in CSV format Examples: No new colnames given: $ seq 3 | csvtk mutate -H \\ | csvtk add-header [WARN] colnames not given, c1, c2, c3... will be used c1,c2 1,1 2,2 3,3 Adding new colnames: $ seq 3 | csvtk mutate -H \\ | csvtk add-header -n a,b a,b 1,1 2,2 3,3 $ seq 3 | csvtk mutate -H \\ | csvtk add-header -n a -n b a,b 1,1 2,2 3,3 $ seq 3 | csvtk mutate -H -t \\ | csvtk add-header -t -n a,b a b 1 1 2 2 3 3 del-header Usage delete column names Usage: csvtk del-header [flags] Flags: -h, --help help for del-header Examples: $ seq 3 | csvtk add-header c1 1 2 3 $ seq 3 | csvtk add-header | csvtk del-header 1 2 3 $ seq 3 | csvtk del-header -H 1 2 3 rename Usage rename column names Usage: csvtk rename [flags] Flags: -f, --fields string select only these fields. e.g -f 1,2 or -f columnA,columnB -F, --fuzzy-fields using fuzzy fields, e.g., -F -f \"*name\" or -F -f \"id123*\" -n, --names string comma separated new names Examples: Setting new names: csvtk rename -f A,B -n a,b or csvtk rename -f 1-3 -n a,b,c $ cat testdata/phones.csv username,phone gri,11111 rob,12345 ken,22222 shenwei,999999 $ cat testdata/phones.csv \\ | csvtk rename -f 1-2 -n \u59d3\u540d,\u7535\u8bdd \\ | csvtk pretty \u59d3\u540d \u7535\u8bdd gri 11111 rob 12345 ken 22222 shenwei 999999 rename2 Usage rename column names by regular expression Special replacement symbols: {nr} ascending number, starting from 1 {kv} Corresponding value of the key (captured variable $n) by key-value file, n can be specified by flag --key-capt-idx (default: 1) Usage: csvtk rename2 [flags] Flags: -f, --fields string select only these fields. e.g -f 1,2 or -f columnA,columnB -F, --fuzzy-fields using fuzzy fields, e.g., -F -f \"*name\" or -F -f \"id123*\" -h, --help help for rename2 -i, --ignore-case ignore case -K, --keep-key keep the key as value when no value found for the key --key-capt-idx int capture variable index of key (1-based) (default 1) --key-miss-repl string replacement for key with no corresponding value -k, --kv-file string tab-delimited key-value file for replacing key with value when using \"{kv}\" in -r (--replacement) -p, --pattern string search regular expression -r, --replacement string renamement. supporting capture variables. e.g. $1 represents the text of the first submatch. ATTENTION: use SINGLE quote NOT double quotes in *nix OS or use the \\ escape character. Ascending number is also supported by \"{nr}\".use ${1} instead of $1 when {kv} given! Examples: Add suffix to all column names. $ cat testdata/phones.csv username,phone gri,11111 rob,12345 ken,22222 shenwei,999999 $ cat testdata/phones.csv \\ | csvtk rename2 -F -f \"*\" -p \"(.*)\" -r 'prefix_${1}_suffix' prefix_username_suffix,prefix_phone_suffix gri,11111 rob,12345 ken,22222 shenwei,999999 supporting {kv} and {nr} in csvtk replace . e.g., replace barcode with sample name. $ cat barcodes.tsv Sample Barcode sc1 CCTAGATTAAT sc2 GAAGACTTGGT sc3 GAAGCAGTATG sc4 GGTAACCTGAC sc5 ATAGTTCTCGT $ cat table.tsv gene ATAGTTCTCGT GAAGCAGTATG GAAGACTTGGT AAAAAAAAAA gene1 0 0 3 0 gen1e2 0 0 0 0 # note that, we must arrange the order of barcodes.tsv to KEY-VALUE $ csvtk cut -t -f 2,1 barcodes.tsv Barcode Sample CCTAGATTAAT sc1 GAAGACTTGGT sc2 GAAGCAGTATG sc3 GGTAACCTGAC sc4 ATAGTTCTCGT sc5 # here we go!!!! $ csvtk rename2 -t -k <(csvtk cut -t -f 2,1 barcodes.tsv) \\ -f -1 -p '(.+)' -r '{kv}' --key-miss-repl unknown table.tsv gene sc5 sc3 sc2 unknown gene1 0 0 3 0 gen1e2 0 0 0 0 {nr} , incase you need this $ echo \"a,b,c,d\" \\ | csvtk rename2 -p '(.+)' -r 'col_{nr}' -f -1 --start-num 2 a,col_2,col_3,col_4 replace Usage replace data of selected fields by regular expression Note that the replacement supports capture variables. e.g. $1 represents the text of the first submatch. ATTENTION: use SINGLE quote NOT double quotes in *nix OS. Examples: Adding space to all bases. csvtk replace -p \"(.)\" -r '$1 ' -s Or use the \\ escape character. csvtk replace -p \"(.)\" -r \"\\$1 \" -s more on: http://shenwei356.github.io/csvtk/usage/#replace Special replacement symbols: {nr} Record number, starting from 1 {kv} Corresponding value of the key (captured variable $n) by key-value file, n can be specified by flag --key-capt-idx (default: 1) Usage: csvtk replace [flags] Flags: -f, --fields string select only these fields. e.g -f 1,2 or -f columnA,columnB (default \"1\") -F, --fuzzy-fields using fuzzy fields, e.g., -F -f \"*name\" or -F -f \"id123*\" -i, --ignore-case ignore case -K, --keep-key keep the key as value when no value found for the key --key-capt-idx int capture variable index of key (1-based) (default 1) --key-miss-repl string replacement for key with no corresponding value -k, --kv-file string tab-delimited key-value file for replacing key with value when using \"{kv}\" in -r (--replacement) -p, --pattern string search regular expression -r, --replacement string replacement. supporting capture variables. e.g. $1 represents the text of the first submatch. ATTENTION: for *nix OS, use SINGLE quote NOT double quotes or use the \\ escape character. Record number is also supported by \"{nr}\".use ${1} instead of $1 when {kv} given! Examples remove Chinese charactors $ csvtk replace -F -f \"*_name\" -p \"\\p{Han}+\" -r \"\" replace by key-value files $ cat data.tsv name id A ID001 B ID002 C ID004 $ cat alias.tsv 001 Tom 002 Bob 003 Jim $ csvtk replace -t -f 2 -p \"ID(.+)\" -r \"N: {nr}, alias: {kv}\" -k alias.tsv data.tsv [INFO] read key-value file: alias.tsv [INFO] 3 pairs of key-value loaded name id A N: 1, alias: Tom B N: 2, alias: Bob C N: 3, alias: 004 mutate Usage create new column from selected fields by regular expression Usage: csvtk mutate [flags] Flags: -f, --fields string select only these fields. e.g -f 1,2 or -f columnA,columnB (default \"1\") -i, --ignore-case ignore case --na for unmatched data, use blank instead of original data -n, --name string new column name -p, --pattern string search regular expression with capture bracket. e.g. (default \"^(.+)$\") Examples By default, copy a column: csvtk mutate -f id -n newname Extract prefix of data as group name using regular expression (get \"A\" from \"A.1\" as group name): csvtk mutate -f sample -n group -p \"^(.+?)\\.\" get the first letter as new column $ cat testdata/phones.csv username,phone gri,11111 rob,12345 ken,22222 shenwei,999999 $ cat testdata/phones.csv \\ | csvtk mutate -f username -p \"^(\\w)\" -n first_letter username,phone,first_letter gri,11111,g rob,12345,r ken,22222,k shenwei,999999,s mutate2 Usage create new column from selected fields by awk-like artithmetic/string expressions The artithmetic/string expression is supported by: https://github.com/Knetic/govaluate Supported operators and types: Modifiers: + - / * & | ^ ** % >> << Comparators: > >= < <= == != =~ !~ Logical ops: || && Numeric constants, as 64-bit floating point (12345.678) String constants (single quotes: 'foobar') Date constants (single quotes) Boolean constants: true false Parenthesis to control order of evaluation ( ) Arrays (anything separated by , within parenthesis: (1, 2, 'foo')) Prefixes: ! - ~ Ternary conditional: ? : Null coalescence: ?? Usage: csvtk mutate2 [flags] Flags: -L, --digits int number of digits after the dot (default 2) -s, --digits-as-string treate digits as string to avoid converting big digits into scientific notation -e, --expression string arithmetic/string expressions. e.g. \"'string'\", '\"abc\"', ' $a + \"-\" + $b ', '$1 + $2', '$a / $b', ' $1 > 100 ? \"big\" : \"small\" ' -h, --help help for mutate2 -n, --name string new column name Example Constants $ cat testdata/digitals.tsv \\ | csvtk mutate2 -t -H -e \" 'abc' \" 4 5 6 abc 1 2 3 abc 7 8 0 abc 8 1,000 4 abc $ val=123 \\ && cat testdata/digitals.tsv \\ | csvtk mutate2 -t -H -e \" $val \" 4 5 6 123 1 2 3 123 7 8 0 123 8 1,000 4 123 String concatenation $ cat testdata/names.csv \\ | csvtk mutate2 -n full_name -e ' $first_name + \" \" + $last_name ' \\ | csvtk pretty id first_name last_name username full_name 11 Rob Pike rob Rob Pike 2 Ken Thompson ken Ken Thompson 4 Robert Griesemer gri Robert Griesemer 1 Robert Thompson abc Robert Thompson NA Robert Abel 123 Robert Abel Math $ cat testdata/digitals.tsv | csvtk mutate2 -t -H -e '$1 + $3' -L 0 4 5 6 10 1 2 3 4 7 8 0 7 8 1,000 4 12 Bool $ cat testdata/digitals.tsv | csvtk mutate2 -t -H -e '$1 > 5' 4 5 6 false 1 2 3 false 7 8 0 true 8 1,000 4 true Ternary conditional $ cat testdata/digitals.tsv | csvtk mutate2 -t -H -e '$1 > 5 ? \"big\" : \"small\" ' 4 5 6 small 1 2 3 small 7 8 0 big 8 1,000 4 big gather Usage gather columns into key-value pairs Usage: csvtk gather [flags] Flags: -f, --fields string fields for gathering. e.g -f 1,2 or -f columnA,columnB, or -f -columnA for unselect columnA -F, --fuzzy-fields using fuzzy fields, e.g., -F -f \"*name\" or -F -f \"id123*\" -k, --key string name of key column to create in output -v, --value string name of value column to create in output Examples: $ cat testdata/names.csv id,first_name,last_name,username 11,\"Rob\",\"Pike\",rob 2,Ken,Thompson,ken 4,\"Robert\",\"Griesemer\",\"gri\" 1,\"Robert\",\"Thompson\",\"abc\" NA,\"Robert\",\"Abel\",\"123 $ cat testdata/names.csv \\ | csvtk gather -k item -v value -f -1 id,item,value 11,first_name,Rob 11,last_name,Pike 11,username,rob 2,first_name,Ken 2,last_name,Thompson 2,username,ken 4,first_name,Robert 4,last_name,Griesemer 4,username,gri 1,first_name,Robert 1,last_name,Thompson 1,username,abc NA,first_name,Robert NA,last_name,Abel NA,username,123 sort Usage sort by selected fields Usage: csvtk sort [flags] Flags: -h, --help help for sort -i, --ignore-case ignore-case -k, --keys strings keys (multiple values supported). sort type supported, \"N\" for natural order, \"n\" for number, \"u\" for user-defined order and \"r\" for reverse. e.g., \"-k 1\" or \"-k A:r\" or \"\"-k 1:nr -k 2\" (default [1]) -L, --levels strings user-defined level file (one level per line, multiple values supported). format: <field>:<level-file>. e.g., \"-k name:u -L name:level.txt\" Examples data $ cat testdata/names.csv id,first_name,last_name,username 11,\"Rob\",\"Pike\",rob 2,Ken,Thompson,ken 4,\"Robert\",\"Griesemer\",\"gri\" 1,\"Robert\",\"Thompson\",\"abc\" NA,\"Robert\",\"Abel\",\"123\" By single column : csvtk sort -k 1 or csvtk sort -k last_name in alphabetical order $ cat testdata/names.csv \\ | csvtk sort -k first_name id,first_name,last_name,username 2,Ken,Thompson,ken 11,Rob,Pike,rob NA,Robert,Abel,123 1,Robert,Thompson,abc 4,Robert,Griesemer,gri in reversed alphabetical order ( key:r ) $ cat testdata/names.csv \\ | csvtk sort -k first_name:r id,first_name,last_name,username NA,Robert,Abel,123 1,Robert,Thompson,abc 4,Robert,Griesemer,gri 11,Rob,Pike,rob 2,Ken,Thompson,ken in numerical order ( key:n ) $ cat testdata/names.csv \\ | csvtk sort -k id:n id,first_name,last_name,username NA,Robert,Abel,123 1,Robert,Thompson,abc 2,Ken,Thompson,ken 4,Robert,Griesemer,gri 11,Rob,Pike,rob in natural order ( key:N ) $ cat testdata/names.csv | csvtk sort -k id:N id,first_name,last_name,username 1,Robert,Thompson,abc 2,Ken,Thompson,ken 4,Robert,Griesemer,gri 11,Rob,Pike,rob NA,Robert,Abel,123 in natural order ( key:N ), a bioinformatics example $ echo \"X,Y,1,10,2,M,11,1_c,Un_g,1_g\" | csvtk transpose X Y 1 10 2 M 11 1_c Un_g 1_g $ echo \"X,Y,1,10,2,M,11,1_c,Un_g,1_g\" \\ | csvtk transpose \\ | csvtk sort -H -k 1:N 1 1_c 1_g 2 10 11 M Un_g X Y By multiple columns: csvtk sort -k 1,2 or csvtk sort -k 1 -k 2 or csvtk sort -k last_name,age # by first_name and then last_name $ cat testdata/names.csv | csvtk sort -k first_name -k last_name id,first_name,last_name,username 2,Ken,Thompson,ken 11,Rob,Pike,rob NA,Robert,Abel,123 4,Robert,Griesemer,gri 1,Robert,Thompson,abc # by first_name and then ID $ cat testdata/names.csv | csvtk sort -k first_name -k id:n id,first_name,last_name,username 2,Ken,Thompson,ken 11,Rob,Pike,rob NA,Robert,Abel,123 1,Robert,Thompson,abc 4,Robert,Griesemer,gri By user-defined order # user-defined order/level $ cat testdata/size_level.txt tiny mini small medium big # original data $ cat testdata/size.csv id,size 1,Huge 2,Tiny 3,Big 4,Small 5,Medium $ csvtk sort -k 2:u -i -L 2:testdata/size_level.txt testdata/size.csv id,size 2,Tiny 4,Small 5,Medium 3,Big 1,Huge plot Usage plot common figures Notes: 1. Output file can be set by flag -o/--out-file. 2. File format is determined by the out file suffix. Supported formats: eps, jpg|jpeg, pdf, png, svg, and tif|tiff 3. If flag -o/--out-file not set (default), image is written to stdout, you can display the image by pipping to \"display\" command of Imagemagic or just redirect to file. Usage: csvtk plot [command] Available Commands: box plot boxplot hist plot histogram line line plot and scatter plot Flags: --axis-width float axis width (default 1.5) -f, --data-field string column index or column name of data (default \"1\") --format string image format for stdout when flag -o/--out-file not given. available values: eps, jpg|jpeg, pdf, png, svg, and tif|tiff. (default \"png\") -g, --group-field string column index or column name of group --height float Figure height (default 4.5) --label-size int label font size (default 14) --tick-width float axis tick width (default 1.5) --title string Figure title --title-size int title font size (default 16) --width float Figure width (default 6) --x-max string maximum value of X axis --x-min string minimum value of X axis --xlab string x label text --y-max string maximum value of Y axis --y-min string minimum value of Y axis --ylab string y label text Note that most of the flags of plot are global flags of the subcommands hist , box and line Notes of image output Output file can be set by flag -o/--out-file. File format is determined by the out file suffix. Supported formats: eps, jpg|jpeg, pdf, png, svg, and tif|tiff If flag -o/--out-file not set (default), image is written to stdout, you can display the image by pipping to display command of Imagemagic or just redirect to file. plot hist Usage plot histogram Notes: 1. Output file can be set by flag -o/--out-file. 2. File format is determined by the out file suffix. Supported formats: eps, jpg|jpeg, pdf, png, svg, and tif|tiff 3. If flag -o/--out-file not set (default), image is written to stdout, you can display the image by pipping to \"display\" command of Imagemagic or just redirect to file. Usage: csvtk plot hist [flags] Flags: --bins int number of bins (default 50) --color-index int color index, 1-7 (default 1) Examples example data $ zcat testdata/grouped_data.tsv.gz | head -n 5 | csvtk -t pretty Group Length GC Content Group A 97 57.73 Group A 95 49.47 Group A 97 49.48 Group A 100 51.00 plot histogram with data of the second column: $ csvtk -t plot hist testdata/grouped_data.tsv.gz -f 2 \\ --title Histogram -o histogram.png You can also write image to stdout and pipe to \"display\" command of Imagemagic: $ csvtk -t plot hist testdata/grouped_data.tsv.gz -f 2 | display plot box Usage plot boxplot Notes: 1. Output file can be set by flag -o/--out-file. 2. File format is determined by the out file suffix. Supported formats: eps, jpg|jpeg, pdf, png, svg, and tif|tiff 3. If flag -o/--out-file not set (default), image is written to stdout, you can display the image by pipping to \"display\" command of Imagemagic or just redirect to file. Usage: csvtk plot box [flags] Flags: --box-width float box width --horiz horize box plot Examples plot boxplot with data of the \"GC Content\" (third) column, group information is the \"Group\" column. csvtk -t plot box testdata/grouped_data.tsv.gz -g \"Group\" -f \"GC Content\" \\ --width 3 --title \"Box plot\" \\ > boxplot.png plot horiz boxplot with data of the \"Length\" (second) column, group information is the \"Group\" column. $ csvtk -t plot box testdata/grouped_data.tsv.gz -g \"Group\" -f \"Length\" \\ --height 3 --width 5 --horiz --title \"Horiz box plot\" \\ > boxplot2.png` plot line Usage line plot and scatter plot Notes: 1. Output file can be set by flag -o/--out-file. 2. File format is determined by the out file suffix. Supported formats: eps, jpg|jpeg, pdf, png, svg, and tif|tiff 3. If flag -o/--out-file not set (default), image is written to stdout, you can display the image by pipping to \"display\" command of Imagemagic or just redirect to file. Usage: csvtk plot line [flags] Flags: -x, --data-field-x string column index or column name of X for command line -y, --data-field-y string column index or column name of Y for command line --legend-left locate legend along the left edge of the plot --legend-top locate legend along the top edge of the plot --line-width float line width (default 1.5) --point-size float point size (default 3) --scatter only plot points Examples example data $ head -n 5 testdata/xy.tsv Group X Y A 0 1 A 1 1.3 A 1.5 1.5 A 2.0 2 plot line plot with X-Y data $ csvtk -t plot line testdata/xy.tsv -x X -y Y -g Group \\ --title \"Line plot\" \\ > lineplot.png plot scatter $ csvtk -t plot line testdata/xy.tsv -x X -y Y -g Group \\ --title \"Scatter\" --scatter \\ > lineplot.png cat Usage stream file to stdout and report progress on stderr Usage: csvtk cat [flags] Flags: -b, --buffsize int buffer size (default 8192) -h, --help help for cat -L, --lines count lines instead of bytes -p, --print-freq int print frequency (-1 for print after parsing) (default 1) -s, --total int expected total bytes/lines (default -1) Examples Stream file, report progress in bytes csvtk cat file.tsv Stream file from stdin, report progress in lines tac input.tsv | csvtk cat -L -s `wc -l < input.tsv` - genautocomplete Usage generate shell autocompletion script Note: The current version supports Bash only. This should work for *nix systems with Bash installed. Howto: 1. run: csvtk genautocomplete 2. create and edit ~/.bash_completion file if you don't have it. nano ~/.bash_completion add the following: for bcfile in ~/.bash_completion.d/* ; do . $bcfile done Usage: csvtk genautocomplete [flags] Flags: --file string autocompletion file (default \"/home/shenwei/.bash_completion.d/csvtk.sh\") -h, --help help for genautocomplete --type string autocompletion type (currently only bash supported) (default \"bash\") /** * RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS. * LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables */ /* var disqus_config = function () { this.page.url = PAGE_URL; // Replace PAGE_URL with your page's canonical URL variable this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable }; */ (function() { // DON'T EDIT BELOW THIS LINE var d = document, s = d.createElement('script'); s.src = '//csvtk.disqus.com/embed.js'; s.setAttribute('data-timestamp', +new Date()); (d.head || d.body).appendChild(s); })(); Please enable JavaScript to view the comments powered by Disqus.","title":"Usage"},{"location":"usage/#usage-and-examples","text":"","title":"Usage and Examples"},{"location":"usage/#before-use","text":"Attention The CSV parser requires all the lines have same number of fields/columns. Even lines with spaces will cause error. Use '-I/--ignore-illegal-row' to skip these lines if neccessary. By default, csvtk thinks your files have header row, if not, switch flag -H on. Column names better be unique. By default, lines starting with # will be ignored, if the header row starts with # , please assign flag -C another rare symbol, e.g. '$' . By default, csvtk handles CSV files, use flag -t for tab-delimited files. If \" exists in tab-delimited files, use flag -l . Do not mix use digital fields and column names.","title":"Before use"},{"location":"usage/#table-of-contents","text":"csvtk Information headers dim summary corr watch Format conversion pretty transpose csv2md csv2json xlsx2csv Set operations head concat sample cut grep uniq freq inter filter filter2 join split splitxlsx collapse Edit add-header del-header rename rename2 replace mutate mutate2 gather Ordering sort Ploting plot plot hist plot box plot line Misc cat genautocomplete","title":"Table of Contents"},{"location":"usage/#csvtk","text":"Usage csvtk -- a cross-platform, efficient and practical CSV/TSV toolkit Version: 0.19.1 Author: Wei Shen <shenwei356@gmail.com> Documents : http://shenwei356.github.io/csvtk Source code: https://github.com/shenwei356/csvtk Attention: 1. The CSV parser requires all the lines have same number of fields/columns. Even lines with spaces will cause error. Use '-I/--ignore-illegal-row' to skip these lines if neccessary. 2. By default, csvtk thinks your files have header row, if not, switch flag \"-H\" on. 3. Column names better be unique. 4. By default, lines starting with \"#\" will be ignored, if the header row starts with \"#\", please assign flag \"-C\" another rare symbol, e.g. '$'. 5. By default, csvtk handles CSV files, use flag \"-t\" for tab-delimited files. 6. If \" exists in tab-delimited files, use flag \"-l\". 7. Do not mix use digital fields and column names. Environment variables for frequently used global flags - \"CSVTK_T\" for flag \"-t/--tabs\" - \"CSVTK_H\" for flag \"-H/--no-header-row\" Usage: csvtk [command] Available Commands: add-header add column names cat stream file to stdout and report progress on stderr collapse collapse one field with selected fields as keys concat concatenate CSV/TSV files by rows corr calculate Pearson correlation between two columns csv2json convert CSV to JSON format csv2md convert CSV to markdown format csv2tab convert CSV to tabular format cut select parts of fields del-header delete column names dim dimensions of CSV file filter filter rows by values of selected fields with arithmetic expression filter2 filter rows by awk-like artithmetic/string expressions freq frequencies of selected fields gather gather columns into key-value pairs genautocomplete generate shell autocompletion script grep grep data by selected fields with patterns/regular expressions head print first N records headers print headers help Help about any command inter intersection of multiple files join join multiple CSV files by selected fields mutate create new column from selected fields by regular expression mutate2 create new column from selected fields by awk-like artithmetic/string expressions plot plot common figures pretty convert CSV to readable aligned table rename rename column names rename2 rename column names by regular expression replace replace data of selected fields by regular expression sample sampling by proportion sort sort by selected fields space2tab convert space delimited format to CSV split split CSV/TSV into multiple files according to column values splitxlsx split XLSX sheet into multiple sheets according to column values summary summary statistics of selected digital fields (groupby group fields) tab2csv convert tabular format to CSV transpose transpose CSV data uniq unique data without sorting version print version information and check for update watch monitor the specified fields xlsx2csv convert XLSX to CSV format Flags: -c, --chunk-size int chunk size of CSV reader (default 50) -C, --comment-char string lines starting with commment-character will be ignored. if your header row starts with '#', please assign \"-C\" another rare symbol, e.g. '$' (default \"#\") -d, --delimiter string delimiting character of the input CSV file (default \",\") -h, --help help for csvtk -E, --ignore-empty-row ignore empty rows -I, --ignore-illegal-row ignore illegal rows -l, --lazy-quotes if given, a quote may appear in an unquoted field and a non-doubled quote may appear in a quoted field -H, --no-header-row specifies that the input CSV file does not have header row -j, --num-cpus int number of CPUs to use (default value depends on your computer) (default 16) -D, --out-delimiter string delimiting character of the output CSV file, e.g., -D $'\\t' for tab (default \",\") -o, --out-file string out file (\"-\" for stdout, suffix .gz for gzipped out) (default \"-\") -T, --out-tabs specifies that the output is delimited with tabs. Overrides \"-D\" -t, --tabs specifies that the input CSV file is delimited with tabs. Overrides \"-d\" and \"-D\"","title":"csvtk"},{"location":"usage/#headers","text":"Usage print headers Usage: csvtk headers [flags] Examples $ csvtk headers testdata/*.csv # testdata/1.csv 1 name 2 attr # testdata/2.csv 1 name 2 major # testdata/3.csv 1 id 2 name 3 hobby","title":"headers"},{"location":"usage/#dim","text":"Usage dimensions of CSV file Usage: csvtk dim [flags] Aliases: dim, size, stats, stat Flags: -h, --help help for dim Examples with header row $ cat testdata/names.csv id,first_name,last_name,username 11,\"Rob\",\"Pike\",rob 2,Ken,Thompson,ken 4,\"Robert\",\"Griesemer\",\"gri\" 1,\"Robert\",\"Thompson\",\"abc\" NA,\"Robert\",\"Abel\",\"123\" $ cat testdata/names.csv | csvtk size file num_cols num_rows - 4 5 no header row $ cat testdata/digitals.tsv 4 5 6 1 2 3 7 8 0 8 1,000 4 $ cat testdata/digitals.tsv \\ | csvtk size -t -H file num_cols num_rows - 3 4","title":"dim"},{"location":"usage/#summary","text":"Usage summary statistics of selected digital fields (groupby group fields) Attention: 1. Do not mix use digital fields and column names. Available operations: # numeric/statistical operations # provided by github.com/gonum/stat and github.com/gonum/floats countn (count of digits), min, max, sum, mean, stdev, variance, median, q1, q2, q3, entropy (Shannon entropy), prod (product of the elements) # textual/numeric operations count, first, last, rand, unique, collapse, countunique Usage: csvtk summary [flags] Flags: -n, --decimal-width int limit floats to N decimal points (default 2) -f, --fields strings operations on these fields. e.g -f 1:count,1:sum or -f colA:mean. available operations: collapse, count, countn, countunique, entropy, first, last, max, mean, median, min, prod, q1, q2, q3, rand, stdev, sum, uniq, variance -g, --groups string group via fields. e.g -f 1,2 or -f columnA,columnB -h, --help help for summary -i, --ignore-non-digits ignore non-digital values like \"NA\" or \"N/A\" -S, --rand-seed int rand seed for operation \"rand\" (default 11) -s, --separater string separater for collapsed data (default \"; \") Examples data $ cat testdata/digitals2.csv f1,f2,f3,f4,f5 foo,bar,xyz,1,0 foo,bar2,xyz,1.5,-1 foo,bar2,xyz,3,2 foo,bar,xyz,5,3 foo,bar2,xyz,N/A,4 bar,xyz,abc,NA,2 bar,xyz,abc2,1,-1 bar,xyz,abc,2,0 bar,xyz,abc,1,5 bar,xyz,abc,3,100 bar,xyz2,abc3,2,3 bar,xyz2,abc3,2,1 use flag -i/--ignore-non-digits $ cat testdata/digitals2.csv \\ | csvtk summary -f f4:sum [ERRO] column 4 has non-digital data: N/A, you can use flag -i/--ignore-non-digits to skip these data $ cat testdata/digitals2.csv \\ | csvtk summary -f f4:sum -i f4:sum 21.50 multiple fields suported $ cat testdata/digitals2.csv \\ | csvtk summary -f f4:sum,f5:sum -i f4:sum,f5:sum 21.50,118.00 using fields instead of colname is still supported $ cat testdata/digitals2.csv \\ | csvtk summary -f 4:sum,5:sum -i f4:sum,f5:sum 21.50,118.00 but remember not mixing use digital fields and column names $ cat testdata/digitals2.csv \\ | csvtk summary -f f4:sum,5:sum -i [ERRO] column \"5\" not existed in file: - $ cat testdata/digitals2.csv \\ | csvtk summary -f 4:sum,f5:sum -i [ERRO] fail to parse digital field: f5, you may mix use digital fields and column names groupby $ cat testdata/digitals2.csv \\ | csvtk summary -i -f f4:sum,f5:sum -g f1,f2 \\ | csvtk pretty f1 f2 f4:sum f5:sum bar xyz 7.00 106.00 bar xyz2 4.00 4.00 foo bar 6.00 3.00 foo bar2 4.50 5.00 for data without header line $ cat testdata/digitals2.csv | sed 1d \\ | csvtk summary -H -i -f 4:sum,5:sum -g 1,2 \\ | csvtk pretty bar xyz 7.00 106.00 bar xyz2 4.00 4.00 foo bar 6.00 3.00 foo bar2 4.50 5.00 numeric/statistical operations $ cat testdata/digitals2.csv \\ | csvtk summary -i -g f1 -f f4:countn,f4:mean,f4:stdev,f4:q1,f4:q2,f4:mean,f4:q3,f4:min,f4:max \\ | csvtk pretty f1 f4:countn f4:mean f4:stdev f4:q1 f4:q2 f4:mean f4:q3 f4:min f4:max bar 6.00 1.83 0.75 1.00 2.00 1.83 2.00 1.00 3.00 foo 4.00 2.62 1.80 1.25 2.25 2.62 4.00 1.00 5.00 textual/numeric operations $ cat testdata/digitals2.csv \\ | csvtk summary -i -g f1 -f f2:count,f2:first,f2:last,f2:rand,f2:collapse,f2:uniq,f2:countunique \\ | csvtk pretty f1 f2:count f2:first f2:last f2:rand f2:collapse f2:uniq f2:countunique bar 7 xyz xyz2 xyz2 xyz; xyz; xyz; xyz; xyz; xyz2; xyz2 xyz2; xyz 2 foo 5 bar bar2 bar2 bar; bar2; bar2; bar; bar2 bar; bar2 2 mixed operations $ cat testdata/digitals2.csv \\ | csvtk summary -i -g f1 -f f4:collapse,f4:max \\ | csvtk pretty f1 f4:collapse f4:max bar NA; 1; 2; 1; 3; 2; 2 3.00 foo 1; 1.5; 3; 5; N/A 5.00 count and countn (count of digits) $ cat testdata/digitals2.csv \\ | csvtk summary -f f4:count,f4:countn -i \\ | csvtk pretty f4:count f4:countn 12 10 # details: $ cat testdata/digitals2.csv \\ | csvtk summary -f f4:count,f4:countn,f4:collapse -i -g f1 \\ | csvtk pretty f1 f4:count f4:countn f4:collapse bar 7 6 NA; 1; 2; 1; 3; 2; 2 foo 5 4 1; 1.5; 3; 5; N/A","title":"summary"},{"location":"usage/#watch","text":"Usage monitor the specified fields Usage: csvtk watch [flags] Flags: -B, --bins int number of histogram bins (default -1) -W, --delay int sleep this many seconds after plotting (default 1) -y, --dump print histogram data to stderr instead of plotting -f, --field string field to watch -h, --help help for watch -O, --image string save histogram to this PDF/image file -L, --log log10(x+1) transform numeric values -x, --pass passthrough mode (forward input to output) -p, --print-freq int print/report after this many records (-1 for print after EOF) (default -1) -Q, --quiet supress all plotting to stderr -R, --reset reset histogram after every report Examples Read whole file, plot histogram of field on the terminal and PDF csvtk -t watch -O hist.pdf -f MyField input.tsv Monitor a TSV stream, print histogram every 1000 records cat input.tsv | csvtk -t watch -f MyField -p 1000 - Monitor a TSV stream, print histogram every 1000 records, hang forever for updates tail -f +0 input.tsv | csvtk -t watch -f MyField -p 1000 -","title":"watch"},{"location":"usage/#corr","text":"Usage calculate Pearson correlation between two columns Usage: csvtk corr [flags] Flags: -f, --fields string comma separated fields -h, --help help for corr -i, --ignore_nan Ignore non-numeric fields to avoid returning NaN -L, --log Calcute correlations on Log10 transformed data -x, --pass passthrough mode (forward input to output) Examples Calculate pairwise correlations between field, ignore non-numeric values csvtk -t corr -i -f 1,Foo,Bar input.tsv","title":"corr"},{"location":"usage/#pretty","text":"Usage convert CSV to readable aligned table Attention: pretty treats the first row as header line and requires them to be unique Usage: csvtk pretty [flags] Flags: -r, --align-right align right -h, --help help for pretty -W, --max-width int max width -w, --min-width int min width -s, --separator string fields/columns separator (default \" \") Examples: default $ csvtk pretty testdata/names.csv id first_name last_name username 11 Rob Pike rob 2 Ken Thompson ken 4 Robert Griesemer gri 1 Robert Thompson abc NA Robert Abel 123 align right $ csvtk pretty testdata/names.csv -r id first_name last_name username 11 Rob Pike rob 2 Ken Thompson ken 4 Robert Griesemer gri 1 Robert Thompson abc NA Robert Abel 123 custom separator $ csvtk pretty testdata/names.csv -s \" | \" id | first_name | last_name | username 11 | Rob | Pike | rob 2 | Ken | Thompson | ken 4 | Robert | Griesemer | gri 1 | Robert | Thompson | abc NA | Robert | Abel | 123","title":"pretty"},{"location":"usage/#transpose","text":"Usage transpose CSV data Usage: csvtk transpose [flags] Examples $ cat testdata/digitals.tsv 4 5 6 1 2 3 7 8 0 8 1,000 4 $ csvtk transpose -t testdata/digitals.tsv 4 1 7 8 5 2 8 1,000 6 3 0 4","title":"transpose"},{"location":"usage/#csv2json","text":"Usage convert CSV to JSON format Usage: csvtk csv2json [flags] Flags: -h, --help help for csv2json -i, --indent string indent. if given blank, output json in one line. (default \" \") -k, --key string output json as an array of objects keyed by a given filed rather than as a list. e.g -k 1 or -k columnA Examples test data $ cat data.csv ID,room,name 3,G13,Simon 5,103,Anna default operation $ cat data.csv | csvtk csv2json [ { \"ID\": \"3\", \"room\": \"G13\", \"name\": \"Simon\" }, { \"ID\": \"5\", \"room\": \"103\", \"name\": \"Anna\" } ] change indent $ cat data.csv | csvtk csv2json -i \" \" [ { \"ID\": \"3\", \"room\": \"G13\", \"name\": \"Simon\" }, { \"ID\": \"5\", \"room\": \"103\", \"name\": \"Anna\" } ] change indent 2) $ cat data.csv | csvtk csv2json -i \"\" [{\"ID\":\"3\",\"room\":\"G13\",\"name\":\"Simon\"},{\"ID\":\"5\",\"room\":\"103\",\"name\":\"Anna\"}] output json as an array of objects keyed by a given filed rather than as a list. $ cat data.csv | csvtk csv2json -k ID { \"3\": { \"ID\": \"3\", \"room\": \"G13\", \"name\": \"Simon\" }, \"5\": { \"ID\": \"5\", \"room\": \"103\", \"name\": \"Anna\" } } for CSV without header row $ cat data.csv | csvtk csv2json -H [ [ \"ID\", \"room\", \"name\" ], [ \"3\", \"G13\", \"Simon\" ], [ \"5\", \"103\", \"Anna\" ] ] for CSV without header row 2) $ cat data.csv | csvtk csv2json -H -k 1 { \"ID\": [ \"ID\", \"room\", \"name\" ], \"3\": [ \"3\", \"G13\", \"Simon\" ], \"5\": [ \"5\", \"103\", \"Anna\" ] }","title":"csv2json"},{"location":"usage/#csv2md","text":"Usage convert CSV to markdown format Attention: csv2md treats the first row as header line and requires them to be unique Usage: csvtk csv2md [flags] Flags: -a, --alignments string comma separated alignments. e.g. -a l,c,c,c or -a c (default \"l\") -w, --min-width int min width (at least 3) (default 3) Examples give single alignment symbol $ cat testdata/names.csv | csvtk csv2md -a left id |first_name|last_name|username :--|:---------|:--------|:------- 11 |Rob |Pike |rob 2 |Ken |Thompson |ken 4 |Robert |Griesemer|gri 1 |Robert |Thompson |abc NA |Robert |Abel |12 result: id first_name last_name username 11 Rob Pike rob 2 Ken Thompson ken 4 Robert Griesemer gri 1 Robert Thompson abc NA Robert Abel 12 give alignment symbols of all fields $ cat testdata/names.csv | csvtk csv2md -a c,l,l,l id |first_name|last_name|username :-:|:---------|:--------|:------- 11 |Rob |Pike |rob 2 |Ken |Thompson |ken 4 |Robert |Griesemer|gri 1 |Robert |Thompson |abc NA |Robert |Abel |123 result id first_name last_name username 11 Rob Pike rob 2 Ken Thompson ken 4 Robert Griesemer gri 1 Robert Thompson abc NA Robert Abel 123","title":"csv2md"},{"location":"usage/#xlsx2csv","text":"Usage convert XLSX to CSV format Usage: csvtk xlsx2csv [flags] Flags: -h, --help help for xlsx2csv -a, --list-sheets list all sheets -i, --sheet-index int Nth sheet to retrieve (default 1) -n, --sheet-name string sheet to retrieve Examples list all sheets $ csvtk xlsx2csv ../testdata/accounts.xlsx -a index sheet 1 names 2 phones 3 region retrieve sheet by index $ csvtk xlsx2csv ../testdata/accounts.xlsx -i 3 name,region ken,nowhere gri,somewhere shenwei,another Thompson,there retrieve sheet by name $ csvtk xlsx2sv ../testdata/accounts.xlsx -n region name,region ken,nowhere gri,somewhere shenwei,another Thompson,there","title":"xlsx2csv"},{"location":"usage/#head","text":"Usage print first N records Usage: csvtk head [flags] Flags: -n, --number int print first N records (default 10) Examples with header line $ csvtk head -n 2 testdata/1.csv name,attr foo,cool bar,handsome no header line $ csvtk head -H -n 2 testdata/1.csv name,attr foo,cool","title":"head"},{"location":"usage/#concat","text":"Usage concatenate CSV/TSV files by rows Note that the second and later files are concatenated to the first one, so only columns match that of the first files kept. Usage: csvtk concat [flags] Flags: -h, --help help for concat -i, --ignore-case ignore case (column name) -k, --keep-unmatched keep blanks even if no any data of a file matches -u, --unmatched-repl string replacement for unmatched data Examples data $ csvtk pretty names.csv id first_name last_name username 11 Rob Pike rob 2 Ken Thompson ken 4 Robert Griesemer gri 1 Robert Thompson abc NA Robert Abel 123 $ csvtk pretty names.reorder.csv last_name username id first_name Pike rob 11 Rob Thompson ken 2 Ken Griesemer gri 4 Robert Thompson abc 1 Robert Abel 123 NA Robert $ csvtk pretty names.with-unmatched-colname.csv id2 First_name Last_name Username col 22 Rob33 Pike222 rob111 abc 44 Ken33 Thompson22 ken111 def simple one $ csvtk concat names.csv names.reorder.csv \\ | csvtk pretty id first_name last_name username 11 Rob Pike rob 2 Ken Thompson ken 4 Robert Griesemer gri 1 Robert Thompson abc NA Robert Abel 123 11 Rob Pike rob 2 Ken Thompson ken 4 Robert Griesemer gri 1 Robert Thompson abc NA Robert Abel 123 data with unmatched column names, and ignoring cases $ csvtk concat names.csv names.with-unmatched-colname.csv -i \\ | csvtk pretty id first_name last_name username 11 Rob Pike rob 2 Ken Thompson ken 4 Robert Griesemer gri 1 Robert Thompson abc NA Robert Abel 123 Rob33 Pike222 rob111 Ken33 Thompson22 ken111 $ csvtk concat names.csv names.with-unmatched-colname.csv -i -u Unmached \\ | csvtk pretty id first_name last_name username 11 Rob Pike rob 2 Ken Thompson ken 4 Robert Griesemer gri 1 Robert Thompson abc NA Robert Abel 123 Unmached Rob33 Pike222 rob111 Unmached Ken33 Thompson22 ken111 Sometimes data of one file does not matche any column, they are discared by default. But you can keep them using flag -k/--keep-unmatched $ csvtk concat names.with-unmatched-colname.csv names.csv \\ | csvtk pretty id2 First_name Last_name Username col 22 Rob33 Pike222 rob111 abc 44 Ken33 Thompson22 ken111 def $ csvtk concat names.with-unmatched-colname.csv names.csv -u -k NA \\ | csvtk pretty id2 First_name Last_name Username col 22 Rob33 Pike222 rob111 abc 44 Ken33 Thompson22 ken111 def NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA","title":"concat"},{"location":"usage/#sample","text":"Usage sampling by proportion Usage: csvtk sample [flags] Flags: -h, --help help for sample -n, --line-number print line number as the first column (\"n\") -p, --proportion float sample by proportion -s, --rand-seed int rand seed (default 11) Examples $ seq 100 | csvtk sample -H -p 0.5 | wc -l 46 $ seq 100 | csvtk sample -H -p 0.5 | wc -l 46 $ seq 100 | csvtk sample -H -p 0.1 | wc -l 10 $ seq 100 | csvtk sample -H -p 0.05 -n 50,50 52,52 65,65","title":"sample"},{"location":"usage/#cut","text":"Usage select parts of fields Usage: csvtk cut [flags] Flags: -f, --fields string select only these fields. e.g -f 1,2 or -f columnA,columnB, or -f -columnA for unselect columnA -F, --fuzzy-fields using fuzzy fields, e.g., -F -f \"*name\" or -F -f \"id123*\" -h, --help help for cut -i, --ignore-case ignore case (column name) Examples data: $ cat testdata/names.csv id,first_name,last_name,username 11,\"Rob\",\"Pike\",rob 2,Ken,Thompson,ken 4,\"Robert\",\"Griesemer\",\"gri\" 1,\"Robert\",\"Thompson\",\"abc\" NA,\"Robert\",\"Abel\",\"123\" Select columns by column index: csvtk cut -f 1,2 $ cat testdata/names.csv \\ | csvtk cut -f 1,2 id,first_name 11,Rob 2,Ken 4,Robert 1,Robert NA,Robert Select columns by column names: csvtk cut -f first_name,username $ cat testdata/names.csv \\ | csvtk cut -f first_name,username first_name,username Rob,rob Ken,ken Robert,gri Robert,abc Robert,123 Unselect : select 3+ columns: csvtk cut -f -1,-2 $ cat testdata/names.csv \\ | csvtk cut -f -1,-2 last_name,username Pike,rob Thompson,ken Griesemer,gri Thompson,abc Abel,123 select columns except first_name : csvtk cut -f -first_name $ cat testdata/names.csv \\ | csvtk cut -f -first_name id,last_name,username 11,Pike,rob 2,Thompson,ken 4,Griesemer,gri 1,Thompson,abc NA,Abel,123 Fuzzy fields using wildcard character, csvtk cut -F -f \"*_name,username\" $ cat testdata/names.csv \\ | csvtk cut -F -f \"*_name,username\" first_name,last_name,username Rob,Pike,rob Ken,Thompson,ken Robert,Griesemer,gri Robert,Thompson,abc Robert,Abel,123 All fields: csvtk cut -F -f \"*\" (only works when all colnames are unique) $ cat testdata/names.csv \\ | csvtk cut -F -f \"*\" id,first_name,last_name,username 11,Rob,Pike,rob 2,Ken,Thompson,ken 4,Robert,Griesemer,gri 1,Robert,Thompson,abc NA,Robert,Abel,123 Field ranges: csvtk cut -f 2-4 for column 2,3,4 $ cat testdata/names.csv \\ | csvtk cut -f 2-4 first_name,last_name,username Rob,Pike,rob Ken,Thompson,ken Robert,Griesemer,gri Robert,Thompson,abc Robert,Abel,123 csvtk cut -f -3--1 for discarding column 1,2,3 $ cat testdata/names.csv \\ | csvtk cut -f -3--1 username rob ken gri abc 123","title":"cut"},{"location":"usage/#uniq","text":"Usage unique data without sorting Usage: csvtk uniq [flags] Flags: -f, --fields string select only these fields. e.g -f 1,2 or -f columnA,columnB (default \"1\") -F, --fuzzy-fields using fuzzy fields, e.g., -F -f \"*name\" or -F -f \"id123*\" -i, --ignore-case ignore case Examples: data: $ cat testdata/names.csv id,first_name,last_name,username 11,\"Rob\",\"Pike\",rob 2,Ken,Thompson,ken 4,\"Robert\",\"Griesemer\",\"gri\" 1,\"Robert\",\"Thompson\",\"abc\" NA,\"Robert\",\"Abel\",\"123\" unique first_name (it removes rows with duplicated first_name) $ cat testdata/names.csv \\ | csvtk uniq -f first_name id,first_name,last_name,username 11,Rob,Pike,rob 2,Ken,Thompson,ken 4,Robert,Griesemer,gri unique first_name, a more common way $ cat testdata/names.csv \\ | csvtk cut -f first_name \\ | csvtk uniq -f 1 first_name Rob Ken Robert","title":"uniq"},{"location":"usage/#freq","text":"Usage frequencies of selected fields Usage: csvtk freq [flags] Flags: -f, --fields string select only these fields. e.g -f 1,2 or -f columnA,columnB (default \"1\") -F, --fuzzy-fields using fuzzy fields, e.g., -F -f \"*name\" or -F -f \"id123*\" -i, --ignore-case ignore case -r, --reverse reverse order while sorting -n, --sort-by-freq sort by frequency -k, --sort-by-key sort by key Examples one filed $ cat testdata/names.csv \\ | csvtk freq -f first_name | csvtk pretty first_name frequency Ken 1 Rob 1 Robert 3 sort by frequency. you can also use csvtk sort with more sorting options $ cat testdata/names.csv \\ | csvtk freq -f first_name -n -r \\ | csvtk pretty first_name frequency Robert 3 Ken 1 Rob 1 sorty by key $ cat testdata/names.csv \\ | csvtk freq -f first_name -k \\ | csvtk pretty first_name frequency Ken 1 Rob 1 Robert 3 multiple fields $ cat testdata/names.csv \\ | csvtk freq -f first_name,last_name \\ | csvtk pretty first_name last_name frequency Robert Abel 1 Ken Thompson 1 Rob Pike 1 Robert Thompson 1 Robert Griesemer 1 data without header row $ cat testdata/ testdata/digitals.tsv \\ | csvtk -t -H freq -f 1 8 1 1 1 4 1 7 1","title":"freq"},{"location":"usage/#inter","text":"Usage intersection of multiple files Attention: 1. fields in all files should be the same, if not, extracting to another file using \"csvtk cut\". Usage: csvtk inter [flags] Flags: -f, --fields string select only these fields. e.g -f 1,2 or -f columnA,columnB (default \"1\") -F, --fuzzy-fields using fuzzy fields, e.g., -F -f \"*name\" or -F -f \"id123*\" -i, --ignore-case ignore case Examples: $ cat testdata/phones.csv username,phone gri,11111 rob,12345 ken,22222 shenwei,999999 $ cat testdata/region.csv name,region ken,nowhere gri,somewhere shenwei,another Thompson,there $ csvtk inter testdata/phones.csv testdata/region.csv username gri ken shenwei","title":"inter"},{"location":"usage/#grep","text":"Usage grep data by selected fields with patterns/regular expressions Usage: csvtk grep [flags] Flags: --delete-matched delete a pattern right after being matched, this keeps the firstly matched data and speedups when using regular expressions -f, --fields string comma separated key fields, column name or index. e.g. -f 1-3 or -f id,id2 or -F -f \"group*\" (default \"1\") -F, --fuzzy-fields using fuzzy fields, e.g., -F -f \"*name\" or -F -f \"id123*\" -h, --help help for grep -i, --ignore-case ignore case -v, --invert invert match -n, --line-number print line number as the first column (\"n\") -N, --no-highlight no highlight -p, --pattern strings query pattern (multiple values supported) -P, --pattern-file string pattern files (one pattern per line) -r, --use-regexp patterns are regular expression --verbose verbose output Examples Matched parts will be highlight . By exact keys $ cat testdata/names.csv \\ | csvtk grep -f last_name -p Pike -p Abel \\ | csvtk pretty id first_name last_name username 11 Rob Pike rob NA Robert Abel 123 # another form of multiple keys $ csvtk grep -f last_name -p Pike,Abel,Tom By regular expression: csvtk grep -f first_name -r -p Rob $ cat testdata/names.csv \\ | csvtk grep -f first_name -r -p Rob \\ | csvtk pretty id first_name last_name username 11 Rob Pike rob 4 Robert Griesemer gri 1 Robert Thompson abc NA Robert Abel 123 By pattern list $ csvtk grep -f first_name -P name_list.txt Remore rows containing any missing data (NA): $ csvtk grep -F -f \"*\" -r -p \"^$\" -v Show line number $ cat names.csv \\ | csvtk pretty id first_name last_name username 11 Rob Pike rob 2 Ken Thompson ken 4 Robert Griesemer gri 1 Robert Thompson abc NA Robert Abel 123 $ cat names.csv \\ | csvtk grep -f first_name -r -i -p rob -n \\ | csvtk pretty n id first_name last_name username 1 11 Rob Pike rob 3 4 Robert Griesemer gri 4 1 Robert Thompson abc 5 NA Robert Abel 123","title":"grep"},{"location":"usage/#filter","text":"Usage filter rows by values of selected fields with arithmetic expression Usage: csvtk filter [flags] Flags: --any print record if any of the field satisfy the condition -f, --filter string filter condition. e.g. -f \"age>12\" or -f \"1,3<=2\" or -F -f \"c*!=0\" -F, --fuzzy-fields using fuzzy fields, e.g., -F -f \"*name\" or -F -f \"id123*\" -h, --help help for filter -n, --line-number print line number as the first column (\"n\") Examples single field $ cat testdata/names.csv id,first_name,last_name,username 11,\"Rob\",\"Pike\",rob 2,Ken,Thompson,ken 4,\"Robert\",\"Griesemer\",\"gri\" 1,\"Robert\",\"Thompson\",\"abc\" NA,\"Robert\",\"Abel\",\"123\" $ cat testdata/names.csv \\ | csvtk filter -f \"id>0\" \\ | csvtk pretty id first_name last_name username 11 Rob Pike rob 2 Ken Thompson ken 4 Robert Griesemer gri 1 Robert Thompson abc multiple fields $ cat testdata/digitals.tsv 4 5 6 1 2 3 7 8 0 8 1,000 4 $ cat testdata/digitals.tsv \\ | csvtk -t -H filter -f \"1-3>0\" 4 5 6 1 2 3 8 1,000 4 using --any to print record if any of the field satisfy the condition $ cat testdata/digitals.tsv \\ | csvtk -t -H filter -f \"1-3>0\" --any 4 5 6 1 2 3 7 8 0 8 1,000 4 fuzzy fields $ cat testdata/names.csv \\ | csvtk filter -F -f \"i*!=0\" id,first_name,last_name,username 11,Rob,Pike,rob 2,Ken,Thompson,ken 4,Robert,Griesemer,gri 1,Robert,Thompson,abc","title":"filter"},{"location":"usage/#filter2","text":"Usage filter rows by awk-like artithmetic/string expressions The artithmetic/string expression is supported by: https://github.com/Knetic/govaluate Supported operators and types: Modifiers: + - / * & | ^ ** % >> << Comparators: > >= < <= == != =~ !~ Logical ops: || && Numeric constants, as 64-bit floating point (12345.678) String constants (single quotes: 'foobar') Date constants (single quotes) Boolean constants: true false Parenthesis to control order of evaluation ( ) Arrays (anything separated by , within parenthesis: (1, 2, 'foo')) Prefixes: ! - ~ Ternary conditional: ? : Null coalescence: ?? Usage: csvtk filter2 [flags] Flags: -f, --filter string awk-like filter condition. e.g. '$age>12' or '$1 > $3' or '$name==\"abc\"' or '$1 % 2 == 0' -h, --help help for filter2 -n, --line-number print line number as the first column (\"n\") Examples: filter rows with id greater than 3: $ cat testdata/names.csv id,first_name,last_name,username 11,\"Rob\",\"Pike\",rob 2,Ken,Thompson,ken 4,\"Robert\",\"Griesemer\",\"gri\" 1,\"Robert\",\"Thompson\",\"abc\" NA,\"Robert\",\"Abel\",\"123\" $ cat testdata/names.csv \\ | csvtk filter2 -f '$id > 3' id,first_name,last_name,username 11,Rob,Pike,rob 4,Robert,Griesemer,gri arithmetic and string expressions $ cat testdata/names.csv \\ | csvtk filter2 -f '$id > 3 || $username==\"ken\"' id,first_name,last_name,username 11,Rob,Pike,rob 2,Ken,Thompson,ken 4,Robert,Griesemer,gri More arithmetic expressions $ cat testdata/digitals.tsv 4 5 6 1 2 3 7 8 0 8 1,000 4 $ cat testdata/digitals.tsv \\ | csvtk filter2 -H -t -f '$1 > 2 && $2 % 2 == 0' 7 8 0 8 1,000 4 # comparison between fields and support $ cat testdata/digitals.tsv \\ | csvtk filter2 -H -t -f '$2 <= $3 || ( $1 / $2 > 0.5 )' 4 5 6 1 2 3 7 8 0","title":"filter2"},{"location":"usage/#join","text":"Usage join 2nd and later files to the first file by selected fields. Multiple keys supported, but the orders are ignored. Usage: csvtk join [flags] Flags: -f, --fields string Semicolon separated key fields of all files, if given one, we think all the files have the same key columns. Fields of different files should be separated by \";\", e.g -f \"1;2\" or -f \"A,B;C,D\" or -f id (default \"1\") --fill string fill content for unmatched data -F, --fuzzy-fields using fuzzy fields, e.g., -F -f \"*name\" or -F -f \"id123*\" -i, --ignore-case ignore case -k, --keep-unmatched keep unmatched data of the first file Examples: data $ cat testdata/phones.csv username,phone gri,11111 rob,12345 ken,22222 shenwei,999999 $ cat testdata/region.csv name,region ken,nowhere gri,somewhere shenwei,another Thompson,there All files have same key column: csvtk join -f id file1.csv file2.csv $ csvtk join -f 1 testdata/phones.csv testdata/region.csv username,phone,region gri,11111,somewhere ken,22222,nowhere shenwei,999999,another keep unmatched $ csvtk join -f 1 testdata/phones.csv testdata/region.csv --keep-unmatched username,phone,region gri,11111,somewhere rob,12345, ken,22222,nowhere shenwei,999999,another keep unmatched and fill with something $ csvtk join -f 1 testdata/phones.csv testdata/region.csv --keep-unmatched --fill NA username,phone,region gri,11111,somewhere rob,12345,NA ken,22222,nowhere shenwei,999999,another Files have different key columns: csvtk join -f \"username;username;name\" testdata/names.csv phone.csv adress.csv -k . Note that fields are separated with ; not , . $ csvtk join -f \"username;name\" testdata/phones.csv testdata/region.csv username,phone,region gri,11111,somewhere ken,22222,nowhere shenwei,999999,another The 2nd or later files have entries with same ID: $ cat testdata/1.csv name,attr foo,cool bar,handsome bob,beutiful $ cat testdata/2.csv name,major bar,bioinformatics bob,microbiology bob,computer science $ cat testdata/3.csv id,name,hobby 1,bar,baseball 2,bob,basketball 3,foo,football 4,wei,programming $ csvtk join testdata/1.csv testdata/2.csv \\ | csvtk pretty name attr major bar handsome bioinformatics bob beutiful microbiology bob beutiful computer science $ csvtk join testdata/{1,2,3}.csv -f name -k \\ | csvtk pretty name attr major id hobby foo cool 3 football bar handsome bioinformatics 1 baseball bob beutiful microbiology 2 basketball bob beutiful computer science 2 basketball $ csvtk join testdata/{3,1,2}.csv -f name -k \\ | csvtk pretty id name hobby attr major 1 bar baseball handsome bioinformatics 2 bob basketball beutiful computer science 2 bob basketball beutiful computer science 3 foo football cool 4 wei programming","title":"join"},{"location":"usage/#split","text":"Usage split CSV/TSV into multiple files according to column values Note: 1. flag -o/--out-file can specify out directory for splitted files Usage: csvtk split [flags] Flags: -g, --buf-groups int buffering N groups before writing to file (default 100) -b, --buf-rows int buffering N rows for every group before writing to file (default 100000) -f, --fields string comma separated key fields, column name or index. e.g. -f 1-3 or -f id,id2 or -F -f \"group*\" (default \"1\") -F, --fuzzy-fields using fuzzy fields, e.g., -F -f \"*name\" or -F -f \"id123*\" -h, --help help for split -i, --ignore-case ignore case -G, --out-gzip force output gzipped file Examples Test data $ cat names.csv id,first_name,last_name,username 11,\"Rob\",\"Pike\",rob 2,Ken,Thompson,ken 4,\"Robert\",\"Griesemer\",\"gri\" 1,\"Robert\",\"Thompson\",\"abc\" NA,\"Robert\",\"Abel\",\"123\" split according to first_name $ csvtk split names.csv -f first_name $ ls *.csv names.csv names-Ken.csv names-Rob.csv names-Robert.csv $ cat names-Ken.csv id,first_name,last_name,username 2,Ken,Thompson,ken $ cat names-Rob.csv id,first_name,last_name,username 11,Rob,Pike,rob $ cat names-Robert.csv id,first_name,last_name,username 4,Robert,Griesemer,gri 1,Robert,Thompson,abc NA,Robert,Abel,123 split according to first_name and last_name $ csvtk split names.csv -f first_name,last_name $ ls *.csv names.csv names-Robert-Abel.csv names-Robert-Thompson.csv names-Ken-Thompson.csv names-Robert-Griesemer.csv names-Rob-Pike.csv flag -o/--out-file can specify out directory for splitted files $ seq 10000 | csvtk split -H -o result $ ls result/*.csv | wc -l 10000 extreme example 1: lots (1M) of rows in groups $ yes 2 | head -n 10000000 | gzip -c > t.gz $ memusg -t csvtk -H split t.gz elapsed time: 7.959s peak rss: 35.7 MB # check $ zcat t-2.gz | wc -l 10000000 $ zcat t-2.gz | md5sum f194afd7cecf645c0e3cce50c9bc526e - $ zcat t.gz | md5sum f194afd7cecf645c0e3cce50c9bc526e - extreme example 2: lots (10K) of groups $ seq 10000 | gzip -c > t2.gz $ memusg -t csvtk -H split t2.gz -o t2 elapsed time: 20.856s peak rss: 23.77 MB # check $ ls t2/*.gz | wc -l 10000 $ zcat t2/*.gz | sort -k 1,1n | md5sum 72d4ff27a28afbc066d5804999d5a504 - $ zcat t2.gz | md5sum 72d4ff27a28afbc066d5804999d5a504 -","title":"split"},{"location":"usage/#splitxlsx","text":"Usage split XLSX sheet into multiple sheets according to column values Strengths: Sheet properties are remained unchanged. Weakness : Complicated sheet structures are not well supported, e.g., 1. merged cells 2. more than one header row Usage: csvtk splitxlsx [flags] Flags: -f, --fields string comma separated key fields, column name or index. e.g. -f 1-3 or -f id,id2 or -F -f \"group*\" (default \"1\") -F, --fuzzy-fields using fuzzy fields, e.g., -F -f \"*name\" or -F -f \"id123*\" -h, --help help for splitxlsx -i, --ignore-case ignore case (cell value) -a, --list-sheets list all sheets -N, --sheet-index int Nth sheet to retrieve (default 1) -n, --sheet-name string sheet to retrieve Examples example data # list all sheets $ csvtk xlsx2csv -a accounts.xlsx index sheet 1 names 2 phones 3 region # data of sheet \"names\" $ csvtk xlsx2csv accounts.xlsx | csvtk pretty id first_name last_name username 11 Rob Pike rob 2 Ken Thompson ken 4 Robert Griesemer gri 1 Robert Thompson abc NA Robert Abel 123 split sheet \"names\" according to first_name $ csvtk splitxlsx accounts.xlsx -n names -f first_name $ ls accounts.* accounts.split.xlsx accounts.xlsx $ csvtk splitxlsx -a accounts.split.xlsx index sheet 1 names 2 phones 3 region 4 Rob 5 Ken 6 Robert $ csvtk xlsx2csv accounts.split.xlsx -n Rob \\ | csvtk pretty id first_name last_name username 11 Rob Pike rob $ csvtk xlsx2csv accounts.split.xlsx -n Robert \\ | csvtk pretty id first_name last_name username 4 Robert Griesemer gri 1 Robert Thompson abc NA Robert Abel 123","title":"splitxlsx"},{"location":"usage/#collapse","text":"Usage collapse one field with selected fields as keys Usage: csvtk collapse [flags] Flags: -f, --fields string key fields. e.g -f 1,2 or -f columnA,columnB (default \"1\") -F, --fuzzy-fields using fuzzy fields (only for key fields), e.g., -F -f \"*name\" or -F -f \"id123*\" -h, --help help for collapse -i, --ignore-case ignore case -s, --separater string separater for collapsed data (default \"; \") -v, --vfield string value field examples data $ csvtk pretty teachers.csv lab teacher class computational biology Tom Bioinformatics computational biology Tom Statistics computational biology Rob Bioinformatics sequencing center Jerry Bioinformatics sequencing center Nick Molecular Biology sequencing center Nick Microbiology List teachers for every lab/class. uniq is used to deduplicate items. $ cat teachers.csv \\ | csvtk uniq -f lab,teacher \\ | csvtk collapse -f lab -v teacher \\ | csvtk pretty lab teacher computational biology Tom; Rob sequencing center Jerry; Nick $ cat teachers.csv \\ | csvtk uniq -f class,teacher \\ | csvtk collapse -f class -v teacher -s \", \" \\ | csvtk pretty class teacher Statistics Tom Bioinformatics Tom, Rob, Jerry Molecular Biology Nick Microbiology Nick Multiple key fields supported $ cat teachers.csv \\ | csvtk collapse -f teacher,lab -v class \\ | csvtk pretty teacher lab class Tom computational biology Bioinformatics; Statistics Rob computational biology Bioinformatics Jerry sequencing center Bioinformatics Nick sequencing center Molecular Biology; Microbiology","title":"collapse"},{"location":"usage/#add-header","text":"Usage add column names Usage: csvtk add-header [flags] Flags: -h, --help help for add-header -n, --names strings column names to add, in CSV format Examples: No new colnames given: $ seq 3 | csvtk mutate -H \\ | csvtk add-header [WARN] colnames not given, c1, c2, c3... will be used c1,c2 1,1 2,2 3,3 Adding new colnames: $ seq 3 | csvtk mutate -H \\ | csvtk add-header -n a,b a,b 1,1 2,2 3,3 $ seq 3 | csvtk mutate -H \\ | csvtk add-header -n a -n b a,b 1,1 2,2 3,3 $ seq 3 | csvtk mutate -H -t \\ | csvtk add-header -t -n a,b a b 1 1 2 2 3 3","title":"add-header"},{"location":"usage/#del-header","text":"Usage delete column names Usage: csvtk del-header [flags] Flags: -h, --help help for del-header Examples: $ seq 3 | csvtk add-header c1 1 2 3 $ seq 3 | csvtk add-header | csvtk del-header 1 2 3 $ seq 3 | csvtk del-header -H 1 2 3","title":"del-header"},{"location":"usage/#rename","text":"Usage rename column names Usage: csvtk rename [flags] Flags: -f, --fields string select only these fields. e.g -f 1,2 or -f columnA,columnB -F, --fuzzy-fields using fuzzy fields, e.g., -F -f \"*name\" or -F -f \"id123*\" -n, --names string comma separated new names Examples: Setting new names: csvtk rename -f A,B -n a,b or csvtk rename -f 1-3 -n a,b,c $ cat testdata/phones.csv username,phone gri,11111 rob,12345 ken,22222 shenwei,999999 $ cat testdata/phones.csv \\ | csvtk rename -f 1-2 -n \u59d3\u540d,\u7535\u8bdd \\ | csvtk pretty \u59d3\u540d \u7535\u8bdd gri 11111 rob 12345 ken 22222 shenwei 999999","title":"rename"},{"location":"usage/#rename2","text":"Usage rename column names by regular expression Special replacement symbols: {nr} ascending number, starting from 1 {kv} Corresponding value of the key (captured variable $n) by key-value file, n can be specified by flag --key-capt-idx (default: 1) Usage: csvtk rename2 [flags] Flags: -f, --fields string select only these fields. e.g -f 1,2 or -f columnA,columnB -F, --fuzzy-fields using fuzzy fields, e.g., -F -f \"*name\" or -F -f \"id123*\" -h, --help help for rename2 -i, --ignore-case ignore case -K, --keep-key keep the key as value when no value found for the key --key-capt-idx int capture variable index of key (1-based) (default 1) --key-miss-repl string replacement for key with no corresponding value -k, --kv-file string tab-delimited key-value file for replacing key with value when using \"{kv}\" in -r (--replacement) -p, --pattern string search regular expression -r, --replacement string renamement. supporting capture variables. e.g. $1 represents the text of the first submatch. ATTENTION: use SINGLE quote NOT double quotes in *nix OS or use the \\ escape character. Ascending number is also supported by \"{nr}\".use ${1} instead of $1 when {kv} given! Examples: Add suffix to all column names. $ cat testdata/phones.csv username,phone gri,11111 rob,12345 ken,22222 shenwei,999999 $ cat testdata/phones.csv \\ | csvtk rename2 -F -f \"*\" -p \"(.*)\" -r 'prefix_${1}_suffix' prefix_username_suffix,prefix_phone_suffix gri,11111 rob,12345 ken,22222 shenwei,999999 supporting {kv} and {nr} in csvtk replace . e.g., replace barcode with sample name. $ cat barcodes.tsv Sample Barcode sc1 CCTAGATTAAT sc2 GAAGACTTGGT sc3 GAAGCAGTATG sc4 GGTAACCTGAC sc5 ATAGTTCTCGT $ cat table.tsv gene ATAGTTCTCGT GAAGCAGTATG GAAGACTTGGT AAAAAAAAAA gene1 0 0 3 0 gen1e2 0 0 0 0 # note that, we must arrange the order of barcodes.tsv to KEY-VALUE $ csvtk cut -t -f 2,1 barcodes.tsv Barcode Sample CCTAGATTAAT sc1 GAAGACTTGGT sc2 GAAGCAGTATG sc3 GGTAACCTGAC sc4 ATAGTTCTCGT sc5 # here we go!!!! $ csvtk rename2 -t -k <(csvtk cut -t -f 2,1 barcodes.tsv) \\ -f -1 -p '(.+)' -r '{kv}' --key-miss-repl unknown table.tsv gene sc5 sc3 sc2 unknown gene1 0 0 3 0 gen1e2 0 0 0 0 {nr} , incase you need this $ echo \"a,b,c,d\" \\ | csvtk rename2 -p '(.+)' -r 'col_{nr}' -f -1 --start-num 2 a,col_2,col_3,col_4","title":"rename2"},{"location":"usage/#replace","text":"Usage replace data of selected fields by regular expression Note that the replacement supports capture variables. e.g. $1 represents the text of the first submatch. ATTENTION: use SINGLE quote NOT double quotes in *nix OS. Examples: Adding space to all bases. csvtk replace -p \"(.)\" -r '$1 ' -s Or use the \\ escape character. csvtk replace -p \"(.)\" -r \"\\$1 \" -s more on: http://shenwei356.github.io/csvtk/usage/#replace Special replacement symbols: {nr} Record number, starting from 1 {kv} Corresponding value of the key (captured variable $n) by key-value file, n can be specified by flag --key-capt-idx (default: 1) Usage: csvtk replace [flags] Flags: -f, --fields string select only these fields. e.g -f 1,2 or -f columnA,columnB (default \"1\") -F, --fuzzy-fields using fuzzy fields, e.g., -F -f \"*name\" or -F -f \"id123*\" -i, --ignore-case ignore case -K, --keep-key keep the key as value when no value found for the key --key-capt-idx int capture variable index of key (1-based) (default 1) --key-miss-repl string replacement for key with no corresponding value -k, --kv-file string tab-delimited key-value file for replacing key with value when using \"{kv}\" in -r (--replacement) -p, --pattern string search regular expression -r, --replacement string replacement. supporting capture variables. e.g. $1 represents the text of the first submatch. ATTENTION: for *nix OS, use SINGLE quote NOT double quotes or use the \\ escape character. Record number is also supported by \"{nr}\".use ${1} instead of $1 when {kv} given! Examples remove Chinese charactors $ csvtk replace -F -f \"*_name\" -p \"\\p{Han}+\" -r \"\" replace by key-value files $ cat data.tsv name id A ID001 B ID002 C ID004 $ cat alias.tsv 001 Tom 002 Bob 003 Jim $ csvtk replace -t -f 2 -p \"ID(.+)\" -r \"N: {nr}, alias: {kv}\" -k alias.tsv data.tsv [INFO] read key-value file: alias.tsv [INFO] 3 pairs of key-value loaded name id A N: 1, alias: Tom B N: 2, alias: Bob C N: 3, alias: 004","title":"replace"},{"location":"usage/#mutate","text":"Usage create new column from selected fields by regular expression Usage: csvtk mutate [flags] Flags: -f, --fields string select only these fields. e.g -f 1,2 or -f columnA,columnB (default \"1\") -i, --ignore-case ignore case --na for unmatched data, use blank instead of original data -n, --name string new column name -p, --pattern string search regular expression with capture bracket. e.g. (default \"^(.+)$\") Examples By default, copy a column: csvtk mutate -f id -n newname Extract prefix of data as group name using regular expression (get \"A\" from \"A.1\" as group name): csvtk mutate -f sample -n group -p \"^(.+?)\\.\" get the first letter as new column $ cat testdata/phones.csv username,phone gri,11111 rob,12345 ken,22222 shenwei,999999 $ cat testdata/phones.csv \\ | csvtk mutate -f username -p \"^(\\w)\" -n first_letter username,phone,first_letter gri,11111,g rob,12345,r ken,22222,k shenwei,999999,s","title":"mutate"},{"location":"usage/#mutate2","text":"Usage create new column from selected fields by awk-like artithmetic/string expressions The artithmetic/string expression is supported by: https://github.com/Knetic/govaluate Supported operators and types: Modifiers: + - / * & | ^ ** % >> << Comparators: > >= < <= == != =~ !~ Logical ops: || && Numeric constants, as 64-bit floating point (12345.678) String constants (single quotes: 'foobar') Date constants (single quotes) Boolean constants: true false Parenthesis to control order of evaluation ( ) Arrays (anything separated by , within parenthesis: (1, 2, 'foo')) Prefixes: ! - ~ Ternary conditional: ? : Null coalescence: ?? Usage: csvtk mutate2 [flags] Flags: -L, --digits int number of digits after the dot (default 2) -s, --digits-as-string treate digits as string to avoid converting big digits into scientific notation -e, --expression string arithmetic/string expressions. e.g. \"'string'\", '\"abc\"', ' $a + \"-\" + $b ', '$1 + $2', '$a / $b', ' $1 > 100 ? \"big\" : \"small\" ' -h, --help help for mutate2 -n, --name string new column name Example Constants $ cat testdata/digitals.tsv \\ | csvtk mutate2 -t -H -e \" 'abc' \" 4 5 6 abc 1 2 3 abc 7 8 0 abc 8 1,000 4 abc $ val=123 \\ && cat testdata/digitals.tsv \\ | csvtk mutate2 -t -H -e \" $val \" 4 5 6 123 1 2 3 123 7 8 0 123 8 1,000 4 123 String concatenation $ cat testdata/names.csv \\ | csvtk mutate2 -n full_name -e ' $first_name + \" \" + $last_name ' \\ | csvtk pretty id first_name last_name username full_name 11 Rob Pike rob Rob Pike 2 Ken Thompson ken Ken Thompson 4 Robert Griesemer gri Robert Griesemer 1 Robert Thompson abc Robert Thompson NA Robert Abel 123 Robert Abel Math $ cat testdata/digitals.tsv | csvtk mutate2 -t -H -e '$1 + $3' -L 0 4 5 6 10 1 2 3 4 7 8 0 7 8 1,000 4 12 Bool $ cat testdata/digitals.tsv | csvtk mutate2 -t -H -e '$1 > 5' 4 5 6 false 1 2 3 false 7 8 0 true 8 1,000 4 true Ternary conditional $ cat testdata/digitals.tsv | csvtk mutate2 -t -H -e '$1 > 5 ? \"big\" : \"small\" ' 4 5 6 small 1 2 3 small 7 8 0 big 8 1,000 4 big","title":"mutate2"},{"location":"usage/#gather","text":"Usage gather columns into key-value pairs Usage: csvtk gather [flags] Flags: -f, --fields string fields for gathering. e.g -f 1,2 or -f columnA,columnB, or -f -columnA for unselect columnA -F, --fuzzy-fields using fuzzy fields, e.g., -F -f \"*name\" or -F -f \"id123*\" -k, --key string name of key column to create in output -v, --value string name of value column to create in output Examples: $ cat testdata/names.csv id,first_name,last_name,username 11,\"Rob\",\"Pike\",rob 2,Ken,Thompson,ken 4,\"Robert\",\"Griesemer\",\"gri\" 1,\"Robert\",\"Thompson\",\"abc\" NA,\"Robert\",\"Abel\",\"123 $ cat testdata/names.csv \\ | csvtk gather -k item -v value -f -1 id,item,value 11,first_name,Rob 11,last_name,Pike 11,username,rob 2,first_name,Ken 2,last_name,Thompson 2,username,ken 4,first_name,Robert 4,last_name,Griesemer 4,username,gri 1,first_name,Robert 1,last_name,Thompson 1,username,abc NA,first_name,Robert NA,last_name,Abel NA,username,123","title":"gather"},{"location":"usage/#sort","text":"Usage sort by selected fields Usage: csvtk sort [flags] Flags: -h, --help help for sort -i, --ignore-case ignore-case -k, --keys strings keys (multiple values supported). sort type supported, \"N\" for natural order, \"n\" for number, \"u\" for user-defined order and \"r\" for reverse. e.g., \"-k 1\" or \"-k A:r\" or \"\"-k 1:nr -k 2\" (default [1]) -L, --levels strings user-defined level file (one level per line, multiple values supported). format: <field>:<level-file>. e.g., \"-k name:u -L name:level.txt\" Examples data $ cat testdata/names.csv id,first_name,last_name,username 11,\"Rob\",\"Pike\",rob 2,Ken,Thompson,ken 4,\"Robert\",\"Griesemer\",\"gri\" 1,\"Robert\",\"Thompson\",\"abc\" NA,\"Robert\",\"Abel\",\"123\" By single column : csvtk sort -k 1 or csvtk sort -k last_name in alphabetical order $ cat testdata/names.csv \\ | csvtk sort -k first_name id,first_name,last_name,username 2,Ken,Thompson,ken 11,Rob,Pike,rob NA,Robert,Abel,123 1,Robert,Thompson,abc 4,Robert,Griesemer,gri in reversed alphabetical order ( key:r ) $ cat testdata/names.csv \\ | csvtk sort -k first_name:r id,first_name,last_name,username NA,Robert,Abel,123 1,Robert,Thompson,abc 4,Robert,Griesemer,gri 11,Rob,Pike,rob 2,Ken,Thompson,ken in numerical order ( key:n ) $ cat testdata/names.csv \\ | csvtk sort -k id:n id,first_name,last_name,username NA,Robert,Abel,123 1,Robert,Thompson,abc 2,Ken,Thompson,ken 4,Robert,Griesemer,gri 11,Rob,Pike,rob in natural order ( key:N ) $ cat testdata/names.csv | csvtk sort -k id:N id,first_name,last_name,username 1,Robert,Thompson,abc 2,Ken,Thompson,ken 4,Robert,Griesemer,gri 11,Rob,Pike,rob NA,Robert,Abel,123 in natural order ( key:N ), a bioinformatics example $ echo \"X,Y,1,10,2,M,11,1_c,Un_g,1_g\" | csvtk transpose X Y 1 10 2 M 11 1_c Un_g 1_g $ echo \"X,Y,1,10,2,M,11,1_c,Un_g,1_g\" \\ | csvtk transpose \\ | csvtk sort -H -k 1:N 1 1_c 1_g 2 10 11 M Un_g X Y By multiple columns: csvtk sort -k 1,2 or csvtk sort -k 1 -k 2 or csvtk sort -k last_name,age # by first_name and then last_name $ cat testdata/names.csv | csvtk sort -k first_name -k last_name id,first_name,last_name,username 2,Ken,Thompson,ken 11,Rob,Pike,rob NA,Robert,Abel,123 4,Robert,Griesemer,gri 1,Robert,Thompson,abc # by first_name and then ID $ cat testdata/names.csv | csvtk sort -k first_name -k id:n id,first_name,last_name,username 2,Ken,Thompson,ken 11,Rob,Pike,rob NA,Robert,Abel,123 1,Robert,Thompson,abc 4,Robert,Griesemer,gri By user-defined order # user-defined order/level $ cat testdata/size_level.txt tiny mini small medium big # original data $ cat testdata/size.csv id,size 1,Huge 2,Tiny 3,Big 4,Small 5,Medium $ csvtk sort -k 2:u -i -L 2:testdata/size_level.txt testdata/size.csv id,size 2,Tiny 4,Small 5,Medium 3,Big 1,Huge","title":"sort"},{"location":"usage/#plot","text":"Usage plot common figures Notes: 1. Output file can be set by flag -o/--out-file. 2. File format is determined by the out file suffix. Supported formats: eps, jpg|jpeg, pdf, png, svg, and tif|tiff 3. If flag -o/--out-file not set (default), image is written to stdout, you can display the image by pipping to \"display\" command of Imagemagic or just redirect to file. Usage: csvtk plot [command] Available Commands: box plot boxplot hist plot histogram line line plot and scatter plot Flags: --axis-width float axis width (default 1.5) -f, --data-field string column index or column name of data (default \"1\") --format string image format for stdout when flag -o/--out-file not given. available values: eps, jpg|jpeg, pdf, png, svg, and tif|tiff. (default \"png\") -g, --group-field string column index or column name of group --height float Figure height (default 4.5) --label-size int label font size (default 14) --tick-width float axis tick width (default 1.5) --title string Figure title --title-size int title font size (default 16) --width float Figure width (default 6) --x-max string maximum value of X axis --x-min string minimum value of X axis --xlab string x label text --y-max string maximum value of Y axis --y-min string minimum value of Y axis --ylab string y label text Note that most of the flags of plot are global flags of the subcommands hist , box and line Notes of image output Output file can be set by flag -o/--out-file. File format is determined by the out file suffix. Supported formats: eps, jpg|jpeg, pdf, png, svg, and tif|tiff If flag -o/--out-file not set (default), image is written to stdout, you can display the image by pipping to display command of Imagemagic or just redirect to file.","title":"plot"},{"location":"usage/#plot-hist","text":"Usage plot histogram Notes: 1. Output file can be set by flag -o/--out-file. 2. File format is determined by the out file suffix. Supported formats: eps, jpg|jpeg, pdf, png, svg, and tif|tiff 3. If flag -o/--out-file not set (default), image is written to stdout, you can display the image by pipping to \"display\" command of Imagemagic or just redirect to file. Usage: csvtk plot hist [flags] Flags: --bins int number of bins (default 50) --color-index int color index, 1-7 (default 1) Examples example data $ zcat testdata/grouped_data.tsv.gz | head -n 5 | csvtk -t pretty Group Length GC Content Group A 97 57.73 Group A 95 49.47 Group A 97 49.48 Group A 100 51.00 plot histogram with data of the second column: $ csvtk -t plot hist testdata/grouped_data.tsv.gz -f 2 \\ --title Histogram -o histogram.png You can also write image to stdout and pipe to \"display\" command of Imagemagic: $ csvtk -t plot hist testdata/grouped_data.tsv.gz -f 2 | display","title":"plot hist"},{"location":"usage/#plot-box","text":"Usage plot boxplot Notes: 1. Output file can be set by flag -o/--out-file. 2. File format is determined by the out file suffix. Supported formats: eps, jpg|jpeg, pdf, png, svg, and tif|tiff 3. If flag -o/--out-file not set (default), image is written to stdout, you can display the image by pipping to \"display\" command of Imagemagic or just redirect to file. Usage: csvtk plot box [flags] Flags: --box-width float box width --horiz horize box plot Examples plot boxplot with data of the \"GC Content\" (third) column, group information is the \"Group\" column. csvtk -t plot box testdata/grouped_data.tsv.gz -g \"Group\" -f \"GC Content\" \\ --width 3 --title \"Box plot\" \\ > boxplot.png plot horiz boxplot with data of the \"Length\" (second) column, group information is the \"Group\" column. $ csvtk -t plot box testdata/grouped_data.tsv.gz -g \"Group\" -f \"Length\" \\ --height 3 --width 5 --horiz --title \"Horiz box plot\" \\ > boxplot2.png`","title":"plot box"},{"location":"usage/#plot-line","text":"Usage line plot and scatter plot Notes: 1. Output file can be set by flag -o/--out-file. 2. File format is determined by the out file suffix. Supported formats: eps, jpg|jpeg, pdf, png, svg, and tif|tiff 3. If flag -o/--out-file not set (default), image is written to stdout, you can display the image by pipping to \"display\" command of Imagemagic or just redirect to file. Usage: csvtk plot line [flags] Flags: -x, --data-field-x string column index or column name of X for command line -y, --data-field-y string column index or column name of Y for command line --legend-left locate legend along the left edge of the plot --legend-top locate legend along the top edge of the plot --line-width float line width (default 1.5) --point-size float point size (default 3) --scatter only plot points Examples example data $ head -n 5 testdata/xy.tsv Group X Y A 0 1 A 1 1.3 A 1.5 1.5 A 2.0 2 plot line plot with X-Y data $ csvtk -t plot line testdata/xy.tsv -x X -y Y -g Group \\ --title \"Line plot\" \\ > lineplot.png plot scatter $ csvtk -t plot line testdata/xy.tsv -x X -y Y -g Group \\ --title \"Scatter\" --scatter \\ > lineplot.png","title":"plot line"},{"location":"usage/#cat","text":"Usage stream file to stdout and report progress on stderr Usage: csvtk cat [flags] Flags: -b, --buffsize int buffer size (default 8192) -h, --help help for cat -L, --lines count lines instead of bytes -p, --print-freq int print frequency (-1 for print after parsing) (default 1) -s, --total int expected total bytes/lines (default -1) Examples Stream file, report progress in bytes csvtk cat file.tsv Stream file from stdin, report progress in lines tac input.tsv | csvtk cat -L -s `wc -l < input.tsv` -","title":"cat"},{"location":"usage/#genautocomplete","text":"Usage generate shell autocompletion script Note: The current version supports Bash only. This should work for *nix systems with Bash installed. Howto: 1. run: csvtk genautocomplete 2. create and edit ~/.bash_completion file if you don't have it. nano ~/.bash_completion add the following: for bcfile in ~/.bash_completion.d/* ; do . $bcfile done Usage: csvtk genautocomplete [flags] Flags: --file string autocompletion file (default \"/home/shenwei/.bash_completion.d/csvtk.sh\") -h, --help help for genautocomplete --type string autocompletion type (currently only bash supported) (default \"bash\") /** * RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS. * LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables */ /* var disqus_config = function () { this.page.url = PAGE_URL; // Replace PAGE_URL with your page's canonical URL variable this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable }; */ (function() { // DON'T EDIT BELOW THIS LINE var d = document, s = d.createElement('script'); s.src = '//csvtk.disqus.com/embed.js'; s.setAttribute('data-timestamp', +new Date()); (d.head || d.body).appendChild(s); })(); Please enable JavaScript to view the comments powered by Disqus.","title":"genautocomplete"}]}